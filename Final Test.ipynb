{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "mount_file_id": "1vPve-0CzN8hRope9W1VEQFKoDLuWMzRl",
      "authorship_tag": "ABX9TyPzESgkuEXVD+g0Rz8z1J/P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharath-07/Smart-Traffic-Control-using-Raspberry-Pi/blob/master/Final%20Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTn19ao3XnZ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9275038b-1fe7-44e1-f5b8-73801dc9be45"
      },
      "source": [
        "! wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
        "! chmod +x Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
        "! bash ./Miniconda3-py37_4.8.2-Linux-x86_64.sh -b -f -p /usr/local\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "\n",
        "\n",
        "! conda install -c rdkit rdkit -y"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-10 14:03:03--  https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85055499 (81M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-py37_4.8.2-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-py37_4.8 100%[===================>]  81.12M   182MB/s    in 0.4s    \n",
            "\n",
            "2020-09-10 14:03:04 (182 MB/s) - ‘Miniconda3-py37_4.8.2-Linux-x86_64.sh’ saved [85055499/85055499]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.3.0=py37_0\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2019.11.28=py37_0\n",
            "    - cffi==1.14.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.8.2=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_0\n",
            "    - openssl==1.1.1d=h7b6447c_4\n",
            "    - pip==20.0.2=py37_1\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.6=h0371630_2\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_1\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==45.2.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.42.1=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.3.0-py37_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.11.28-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.0-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.8.2-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_4\n",
            "  pip                pkgs/main/linux-64::pip-20.0.2-py37_1\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h7b6447c_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.6-h0371630_2\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_1\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-45.2.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.14.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h7b6447c_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.42.1-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    blas-1.0                   |              mkl           6 KB\n",
            "    bzip2-1.0.8                |       h7b6447c_0          78 KB\n",
            "    ca-certificates-2020.7.22  |                0         125 KB\n",
            "    cairo-1.14.12              |       h8948797_3         906 KB\n",
            "    certifi-2020.6.20          |           py37_0         156 KB\n",
            "    conda-4.8.4                |           py37_0         2.9 MB\n",
            "    fontconfig-2.13.0          |       h9420a91_0         227 KB\n",
            "    freetype-2.10.2            |       h5ab3b9f_0         608 KB\n",
            "    glib-2.63.1                |       h5a9c865_0         2.9 MB\n",
            "    icu-58.2                   |       he6710b0_3        10.5 MB\n",
            "    intel-openmp-2020.2        |              254         786 KB\n",
            "    jpeg-9b                    |       h024ee3a_2         214 KB\n",
            "    libboost-1.67.0            |       h46d08c1_4        13.0 MB\n",
            "    libpng-1.6.37              |       hbc83047_0         278 KB\n",
            "    libtiff-4.1.0              |       h2733197_0         447 KB\n",
            "    libuuid-1.0.3              |       h1bed415_2          15 KB\n",
            "    libxcb-1.14                |       h7b6447c_0         505 KB\n",
            "    libxml2-2.9.9              |       hea5a465_1         1.6 MB\n",
            "    mkl-2020.2                 |              256       138.3 MB\n",
            "    mkl-service-2.3.0          |   py37he904b0f_0         218 KB\n",
            "    mkl_fft-1.1.0              |   py37h23d657b_0         143 KB\n",
            "    mkl_random-1.1.1           |   py37h0573a6f_0         322 KB\n",
            "    numpy-1.19.1               |   py37hbc911f0_0          21 KB\n",
            "    numpy-base-1.19.1          |   py37hfa32c7d_0         4.1 MB\n",
            "    olefile-0.46               |           py37_0          50 KB\n",
            "    openssl-1.1.1g             |       h7b6447c_0         2.5 MB\n",
            "    pandas-1.1.1               |   py37he6710b0_0         8.2 MB\n",
            "    pcre-8.44                  |       he6710b0_0         212 KB\n",
            "    pillow-7.1.2               |   py37hb39fc2d_0         603 KB\n",
            "    pixman-0.40.0              |       h7b6447c_0         370 KB\n",
            "    py-boost-1.67.0            |   py37h04863e7_4         278 KB\n",
            "    python-dateutil-2.8.1      |             py_0         215 KB\n",
            "    pytz-2020.1                |             py_0         184 KB\n",
            "    rdkit-2020.03.3.0          |   py37hc20afe1_1        24.8 MB  rdkit\n",
            "    zstd-1.3.7                 |       h0b5b093_0         401 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       215.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
            "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0\n",
            "  cairo              pkgs/main/linux-64::cairo-1.14.12-h8948797_3\n",
            "  fontconfig         pkgs/main/linux-64::fontconfig-2.13.0-h9420a91_0\n",
            "  freetype           pkgs/main/linux-64::freetype-2.10.2-h5ab3b9f_0\n",
            "  glib               pkgs/main/linux-64::glib-2.63.1-h5a9c865_0\n",
            "  icu                pkgs/main/linux-64::icu-58.2-he6710b0_3\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2020.2-254\n",
            "  jpeg               pkgs/main/linux-64::jpeg-9b-h024ee3a_2\n",
            "  libboost           pkgs/main/linux-64::libboost-1.67.0-h46d08c1_4\n",
            "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0\n",
            "  libtiff            pkgs/main/linux-64::libtiff-4.1.0-h2733197_0\n",
            "  libuuid            pkgs/main/linux-64::libuuid-1.0.3-h1bed415_2\n",
            "  libxcb             pkgs/main/linux-64::libxcb-1.14-h7b6447c_0\n",
            "  libxml2            pkgs/main/linux-64::libxml2-2.9.9-hea5a465_1\n",
            "  mkl                pkgs/main/linux-64::mkl-2020.2-256\n",
            "  mkl-service        pkgs/main/linux-64::mkl-service-2.3.0-py37he904b0f_0\n",
            "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.1.0-py37h23d657b_0\n",
            "  mkl_random         pkgs/main/linux-64::mkl_random-1.1.1-py37h0573a6f_0\n",
            "  numpy              pkgs/main/linux-64::numpy-1.19.1-py37hbc911f0_0\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.19.1-py37hfa32c7d_0\n",
            "  olefile            pkgs/main/linux-64::olefile-0.46-py37_0\n",
            "  pandas             pkgs/main/linux-64::pandas-1.1.1-py37he6710b0_0\n",
            "  pcre               pkgs/main/linux-64::pcre-8.44-he6710b0_0\n",
            "  pillow             pkgs/main/linux-64::pillow-7.1.2-py37hb39fc2d_0\n",
            "  pixman             pkgs/main/linux-64::pixman-0.40.0-h7b6447c_0\n",
            "  py-boost           pkgs/main/linux-64::py-boost-1.67.0-py37h04863e7_4\n",
            "  python-dateutil    pkgs/main/noarch::python-dateutil-2.8.1-py_0\n",
            "  pytz               pkgs/main/noarch::pytz-2020.1-py_0\n",
            "  rdkit              rdkit/linux-64::rdkit-2020.03.3.0-py37hc20afe1_1\n",
            "  zstd               pkgs/main/linux-64::zstd-1.3.7-h0b5b093_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                                2020.1.1-0 --> 2020.7.22-0\n",
            "  certifi                                 2019.11.28-py37_0 --> 2020.6.20-py37_0\n",
            "  conda                                        4.8.2-py37_0 --> 4.8.4-py37_0\n",
            "  openssl                                 1.1.1d-h7b6447c_4 --> 1.1.1g-h7b6447c_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "pillow-7.1.2         | 603 KB    | : 100% 1.0/1 [00:00<00:00,  6.80it/s]\n",
            "libxcb-1.14          | 505 KB    | : 100% 1.0/1 [00:00<00:00, 14.60it/s]\n",
            "mkl_fft-1.1.0        | 143 KB    | : 100% 1.0/1 [00:00<00:00, 22.74it/s]\n",
            "rdkit-2020.03.3.0    | 24.8 MB   | : 100% 1.0/1 [00:06<00:00,  6.50s/it]\n",
            "conda-4.8.4          | 2.9 MB    | : 100% 1.0/1 [00:00<00:00,  5.87it/s]\n",
            "numpy-base-1.19.1    | 4.1 MB    | : 100% 1.0/1 [00:00<00:00,  4.34it/s]\n",
            "zstd-1.3.7           | 401 KB    | : 100% 1.0/1 [00:00<00:00, 16.52it/s]\n",
            "icu-58.2             | 10.5 MB   | : 100% 1.0/1 [00:00<00:00,  2.06it/s]               \n",
            "libboost-1.67.0      | 13.0 MB   | : 100% 1.0/1 [00:01<00:00,  1.07it/s]              \n",
            "openssl-1.1.1g       | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  7.53it/s]\n",
            "cairo-1.14.12        | 906 KB    | : 100% 1.0/1 [00:00<00:00, 11.84it/s]\n",
            "libxml2-2.9.9        | 1.6 MB    | : 100% 1.0/1 [00:00<00:00,  8.84it/s]\n",
            "olefile-0.46         | 50 KB     | : 100% 1.0/1 [00:00<00:00, 21.09it/s]\n",
            "pytz-2020.1          | 184 KB    | : 100% 1.0/1 [00:00<00:00, 12.04it/s]\n",
            "python-dateutil-2.8. | 215 KB    | : 100% 1.0/1 [00:00<00:00, 19.35it/s]\n",
            "libpng-1.6.37        | 278 KB    | : 100% 1.0/1 [00:00<00:00, 14.26it/s]\n",
            "freetype-2.10.2      | 608 KB    | : 100% 1.0/1 [00:00<00:00, 10.19it/s]\n",
            "certifi-2020.6.20    | 156 KB    | : 100% 1.0/1 [00:00<00:00, 17.91it/s]\n",
            "intel-openmp-2020.2  | 786 KB    | : 100% 1.0/1 [00:00<00:00, 12.84it/s]\n",
            "pcre-8.44            | 212 KB    | : 100% 1.0/1 [00:00<00:00, 15.27it/s]\n",
            "glib-2.63.1          | 2.9 MB    | : 100% 1.0/1 [00:00<00:00,  6.37it/s]\n",
            "mkl-2020.2           | 138.3 MB  | : 100% 1.0/1 [00:04<00:00,  4.85s/it]               \n",
            "bzip2-1.0.8          | 78 KB     | : 100% 1.0/1 [00:00<00:00, 15.78it/s]\n",
            "numpy-1.19.1         | 21 KB     | : 100% 1.0/1 [00:00<00:00, 20.97it/s]\n",
            "mkl_random-1.1.1     | 322 KB    | : 100% 1.0/1 [00:06<00:00,  6.48s/it]\n",
            "fontconfig-2.13.0    | 227 KB    | : 100% 1.0/1 [00:00<00:00, 12.21it/s]\n",
            "mkl-service-2.3.0    | 218 KB    | : 100% 1.0/1 [00:00<00:00, 14.63it/s]\n",
            "pandas-1.1.1         | 8.2 MB    | : 100% 1.0/1 [00:00<00:00,  2.23it/s]\n",
            "py-boost-1.67.0      | 278 KB    | : 100% 1.0/1 [00:00<00:00, 13.96it/s]\n",
            "blas-1.0             | 6 KB      | : 100% 1.0/1 [00:00<00:00, 20.23it/s]\n",
            "pixman-0.40.0        | 370 KB    | : 100% 1.0/1 [00:00<00:00, 16.50it/s]\n",
            "libuuid-1.0.3        | 15 KB     | : 100% 1.0/1 [00:00<00:00, 19.54it/s]\n",
            "ca-certificates-2020 | 125 KB    | : 100% 1.0/1 [00:00<00:00, 18.23it/s]\n",
            "jpeg-9b              | 214 KB    | : 100% 1.0/1 [00:00<00:00, 16.67it/s]\n",
            "libtiff-4.1.0        | 447 KB    | : 100% 1.0/1 [00:00<00:00, 14.30it/s]\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sP469YRaIw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "648f1e5a-55f1-4648-d6a2-51e20301d430"
      },
      "source": [
        "!conda install pytorch torchvision cudatoolkit=10.0.130 -c pytorch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cudatoolkit=10.0.130\n",
            "    - pytorch\n",
            "    - torchvision\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    cudatoolkit-10.0.130       |                0       261.2 MB\n",
            "    ninja-1.10.1               |   py37hfd86e86_0         1.4 MB\n",
            "    pytorch-1.4.0              |py3.7_cuda10.0.130_cudnn7.6.3_0       422.7 MB  pytorch\n",
            "    torchvision-0.5.0          |       py37_cu100         9.1 MB  pytorch\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       694.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0\n",
            "  ninja              pkgs/main/linux-64::ninja-1.10.1-py37hfd86e86_0\n",
            "  pytorch            pytorch/linux-64::pytorch-1.4.0-py3.7_cuda10.0.130_cudnn7.6.3_0\n",
            "  torchvision        pytorch/linux-64::torchvision-0.5.0-py37_cu100\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "torchvision-0.5.0    | 9.1 MB    | : 100% 1.0/1 [00:02<00:00,  2.68s/it]               \n",
            "ninja-1.10.1         | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  4.37it/s]\n",
            "pytorch-1.4.0        | 422.7 MB  | : 100% 1.0/1 [01:07<00:00, 67.45s/it]               \n",
            "cudatoolkit-10.0.130 | 261.2 MB  | : 100% 1.0/1 [00:07<00:00,  8.00s/it]               \n",
            "Preparing transaction: | \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vYTaPMNalLB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87346b5c-4633-4596-a2c2-bbd5f5cb4c33"
      },
      "source": [
        "cd /content/drive/My Drive/mmdetection-master"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/mmdetection-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QfzZr8Maqjx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "1dd08736-80fb-4719-da22-24040df17faa"
      },
      "source": [
        "!pip install -r requirements/build.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cython\n",
            "  Downloading Cython-0.29.21-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from -r requirements/build.txt (line 3)) (1.19.1)\n",
            "Installing collected packages: cython\n",
            "Successfully installed cython-0.29.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmK7xDJVatmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "998833a4-a45a-4a52-b74f-9dec8797d268"
      },
      "source": [
        "!pip install \"git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-nk3p_5ma\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-nk3p_5ma\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/site-packages (from pycocotools==2.0) (45.2.0.post20200210)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/site-packages (from pycocotools==2.0) (0.29.21)\n",
            "Collecting matplotlib>=2.1.0\n",
            "  Downloading matplotlib-3.3.1-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (7.1.2)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2020.6.20)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 10.1 MB/s \n",
            "\u001b[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.19.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.14.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=273359 sha256=4d2218faf816492155e69fb5d10c2682e72a91be4532bbcc23b3662ebe43f4a7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-is80jdlt/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: cycler, kiwisolver, pyparsing, matplotlib, pycocotools\n",
            "Successfully installed cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.3.1 pycocotools-2.0 pyparsing-2.4.7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "kiwisolver",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGLH3eIqlE7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlZxGBhSawao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5fdb07c-5287-4490-fce1-816726bbb021"
      },
      "source": [
        "!pip install -v -e .  # or \"python setup.py develop\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Non-user install because site-packages writeable\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-ittbc_1f\n",
            "Created temporary directory: /tmp/pip-req-tracker-nt9s4epn\n",
            "Initialized build tracking at /tmp/pip-req-tracker-nt9s4epn\n",
            "Created build tracker: /tmp/pip-req-tracker-nt9s4epn\n",
            "Entered build tracker: /tmp/pip-req-tracker-nt9s4epn\n",
            "Created temporary directory: /tmp/pip-install-5ewyn4_f\n",
            "Obtaining file:///content/drive/My%20Drive/mmdetection-master\n",
            "  Added file:///content/drive/My%20Drive/mmdetection-master to build tracker '/tmp/pip-req-tracker-nt9s4epn'\n",
            "    Running setup.py (path:/content/drive/My Drive/mmdetection-master/setup.py) egg_info for package from file:///content/drive/My%20Drive/mmdetection-master\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    writing mmdet.egg-info/PKG-INFO\n",
            "    writing dependency_links to mmdet.egg-info/dependency_links.txt\n",
            "    writing requirements to mmdet.egg-info/requires.txt\n",
            "    writing top-level names to mmdet.egg-info/top_level.txt\n",
            "    reading manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "  Source in /content/drive/My Drive/mmdetection-master has version 2.3.0, which satisfies requirement mmdet==2.3.0 from file:///content/drive/My%20Drive/mmdetection-master\n",
            "  Removed mmdet==2.3.0 from file:///content/drive/My%20Drive/mmdetection-master from build tracker '/tmp/pip-req-tracker-nt9s4epn'\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (from mmdet==2.3.0) (3.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from mmdet==2.3.0) (1.19.1)\n",
            "Requirement already satisfied: pycocotools@ git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools from git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools in /usr/local/lib/python3.7/site-packages (from mmdet==2.3.0) (2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from mmdet==2.3.0) (1.14.0)\n",
            "1 location(s) to search for versions of terminaltables:\n",
            "* https://pypi.org/simple/terminaltables/\n",
            "Fetching project page and analyzing links: https://pypi.org/simple/terminaltables/\n",
            "Getting page https://pypi.org/simple/terminaltables/\n",
            "Found index url https://pypi.org/simple\n",
            "Looking up \"https://pypi.org/simple/terminaltables/\" in the cache\n",
            "Request header has \"max_age\" as 0, cache bypassed\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/terminaltables/ HTTP/1.1\" 200 1186\n",
            "Updating cache with response from \"https://pypi.org/simple/terminaltables/\"\n",
            "Caching due to etag\n",
            "  Found link https://files.pythonhosted.org/packages/ec/82/6390ba7f110622d27b02451aaa294dc4b3133b7661e464db9a116e977324/terminaltables-1.0.0.tar.gz#sha256=4c909a5ee4a3d028b2c977d996f8b8cd9724ce8e4d9d834d65e78a98f7965b54 (from https://pypi.org/simple/terminaltables/), version: 1.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/97/65/858bc3ea6cc60edc959ce427a94227932b5d9a95b0bce82f16071419885c/terminaltables-1.0.1.tar.gz#sha256=5548ac567d38d6ac88a5e0fec2d95f646249f37e1ef8fd2d17f8fcaefc6cf592 (from https://pypi.org/simple/terminaltables/), version: 1.0.1\n",
            "  Found link https://files.pythonhosted.org/packages/82/42/3f1140f6e538582fd514c765244662cca60885048cf610e7d00eaee8aeb1/terminaltables-1.0.2.tar.gz#sha256=cf97dd019af975cc64aa69aca435a43b0cffabb88df6f337c6b48de600c19f8e (from https://pypi.org/simple/terminaltables/), version: 1.0.2\n",
            "  Found link https://files.pythonhosted.org/packages/80/07/5663569dfd8fa4e4fa3cb645b70f4972e3d79d056b71da12df174668c145/terminaltables-1.1.0.tar.gz#sha256=94a15e1a295265d130de67e9c2efef9e1cad1e64dd6ae0b80882076581605f8c (from https://pypi.org/simple/terminaltables/), version: 1.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/0c/4a/9b80642ac2463908fe77c9dbe138c56902fbf5a5a95d07203c131ec9ba90/terminaltables-1.1.1.tar.gz#sha256=b02c516d6d521ce0fe6e2a2753268e86547bbccab6bfa7e269a0f51766283fab (from https://pypi.org/simple/terminaltables/), version: 1.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/a8/65/f9c6bcfb1f81acdfcd1f8d633c6752cfdcc04b5fade7638a2a8dc7a720de/terminaltables-1.2.0.tar.gz#sha256=fff4aa62f296038d1526a91856f0b3de1e3bce31cfd1c5148cc3f795c1d396bf (from https://pypi.org/simple/terminaltables/), version: 1.2.0\n",
            "  Found link https://files.pythonhosted.org/packages/3d/17/14aa6521b337be46c51dd7b31e7e617801e9f8db7f48583c767c02e0e72a/terminaltables-1.2.1.tar.gz#sha256=cf5f0fb6c6c3070d7af73537ded030858c122f253c87e7221f9a6da3782ce787 (from https://pypi.org/simple/terminaltables/), version: 1.2.1\n",
            "  Found link https://files.pythonhosted.org/packages/d0/8e/9403573ff8aebc09ee0aacd57885050f74bd9f48a85c0735d33cacfa2469/terminaltables-2.0.0.tar.gz#sha256=2e0a6688071f2a881f8fa4455a362457dcd2317e374609f1a09baffa998e7492 (from https://pypi.org/simple/terminaltables/), version: 2.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/10/da/9bbb21c1c2f9be4df2056b00b569689b9ece538ef39bf8db34be25f9e850/terminaltables-2.1.0.tar.gz#sha256=33b60f027964214f4ff5821f43958d03add81784f7c183d86a7ee8f010350cf5 (from https://pypi.org/simple/terminaltables/), version: 2.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/58/c9/f0c174c4e828365df3593c66ac32474cd994a8ec36fe19a798261c96c3bc/terminaltables-3.0.0.tar.gz#sha256=bd2504031f09f942a8f221266adc61aee04a0368d5de0dacb7a53e508af6a518 (from https://pypi.org/simple/terminaltables/), version: 3.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from https://pypi.org/simple/terminaltables/), version: 3.1.0\n",
            "Given no hashes to check 11 links for project 'terminaltables': discarding no candidates\n",
            "Using version 3.1.0 (newest of versions: 1.0.0, 1.0.1, 1.0.2, 1.1.0, 1.1.1, 1.2.0, 1.2.1, 2.0.0, 2.1.0, 3.0.0, 3.1.0)\n",
            "Collecting terminaltables\n",
            "  Created temporary directory: /tmp/pip-unpack-cm3s0rzv\n",
            "  Looking up \"https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\" in the cache\n",
            "  No cache entry available\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz HTTP/1.1\" 200 12478\n",
            "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
            "  Ignoring unknown cache-control directive: immutable\n",
            "  Updating cache with response from \"https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\"\n",
            "  Caching due to etag\n",
            "  Added terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.3.0) to build tracker '/tmp/pip-req-tracker-nt9s4epn'\n",
            "    Running setup.py (path:/tmp/pip-install-5ewyn4_f/terminaltables/setup.py) egg_info for package terminaltables\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-5ewyn4_f/terminaltables/pip-egg-info/terminaltables.egg-info\n",
            "    writing /tmp/pip-install-5ewyn4_f/terminaltables/pip-egg-info/terminaltables.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-5ewyn4_f/terminaltables/pip-egg-info/terminaltables.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-install-5ewyn4_f/terminaltables/pip-egg-info/terminaltables.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-5ewyn4_f/terminaltables/pip-egg-info/terminaltables.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-5ewyn4_f/terminaltables/pip-egg-info/terminaltables.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-install-5ewyn4_f/terminaltables/pip-egg-info/terminaltables.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-5ewyn4_f/terminaltables has version 3.1.0, which satisfies requirement terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.3.0)\n",
            "  Removed terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.3.0) from build tracker '/tmp/pip-req-tracker-nt9s4epn'\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib->mmdet==2.3.0) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/site-packages (from matplotlib->mmdet==2.3.0) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib->mmdet==2.3.0) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib->mmdet==2.3.0) (0.10.0)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/site-packages (from matplotlib->mmdet==2.3.0) (2020.6.20)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib->mmdet==2.3.0) (1.2.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/site-packages (from pycocotools@ git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools->mmdet==2.3.0) (0.29.21)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/site-packages (from pycocotools@ git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools->mmdet==2.3.0) (45.2.0.post20200210)\n",
            "Building wheels for collected packages: terminaltables\n",
            "  Created temporary directory: /tmp/pip-wheel-lrki21cl\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-lrki21cl\n",
            "  Running command /usr/local/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-5ewyn4_f/terminaltables/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-5ewyn4_f/terminaltables/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-lrki21cl\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/terminaltables\n",
            "  copying terminaltables/base_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/ascii_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/terminal_io.py -> build/lib/terminaltables\n",
            "  copying terminaltables/other_tables.py -> build/lib/terminaltables\n",
            "  copying terminaltables/width_and_alignment.py -> build/lib/terminaltables\n",
            "  copying terminaltables/__init__.py -> build/lib/terminaltables\n",
            "  copying terminaltables/github_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/build.py -> build/lib/terminaltables\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/base_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/ascii_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/terminal_io.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/other_tables.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/width_and_alignment.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/__init__.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/github_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/build.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing terminaltables.egg-info/PKG-INFO\n",
            "  writing dependency_links to terminaltables.egg-info/dependency_links.txt\n",
            "  writing top-level names to terminaltables.egg-info/top_level.txt\n",
            "  reading manifest file 'terminaltables.egg-info/SOURCES.txt'\n",
            "  writing manifest file 'terminaltables.egg-info/SOURCES.txt'\n",
            "  Copying terminaltables.egg-info to build/bdist.linux-x86_64/wheel/terminaltables-3.1.0-py3.7.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/terminaltables-3.1.0.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-lrki21cl/terminaltables-3.1.0-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'terminaltables/__init__.py'\n",
            "  adding 'terminaltables/ascii_table.py'\n",
            "  adding 'terminaltables/base_table.py'\n",
            "  adding 'terminaltables/build.py'\n",
            "  adding 'terminaltables/github_table.py'\n",
            "  adding 'terminaltables/other_tables.py'\n",
            "  adding 'terminaltables/terminal_io.py'\n",
            "  adding 'terminaltables/width_and_alignment.py'\n",
            "  adding 'terminaltables-3.1.0.dist-info/METADATA'\n",
            "  adding 'terminaltables-3.1.0.dist-info/WHEEL'\n",
            "  adding 'terminaltables-3.1.0.dist-info/top_level.txt'\n",
            "  adding 'terminaltables-3.1.0.dist-info/zip-safe'\n",
            "  adding 'terminaltables-3.1.0.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=f4b087d96a4d4029a86de5d2e115646758e8a0fa5a105c71c8863f3f66643470\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\n",
            "Successfully built terminaltables\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "  Created temporary directory: /tmp/pip-unpacked-wheel-iqephjcp\n",
            "\n",
            "  Running setup.py develop for mmdet\n",
            "    Running command /usr/local/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/content/drive/My Drive/mmdetection-master/setup.py'\"'\"'; __file__='\"'\"'/content/drive/My Drive/mmdetection-master/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\n",
            "    running develop\n",
            "    running egg_info\n",
            "    writing mmdet.egg-info/PKG-INFO\n",
            "    writing dependency_links to mmdet.egg-info/dependency_links.txt\n",
            "    writing requirements to mmdet.egg-info/requires.txt\n",
            "    writing top-level names to mmdet.egg-info/top_level.txt\n",
            "    reading manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "    Creating /usr/local/lib/python3.7/site-packages/mmdet.egg-link (link to .)\n",
            "    Adding mmdet 2.3.0 to easy-install.pth file\n",
            "\n",
            "    Installed /content/drive/My Drive/mmdetection-master\n",
            "Successfully installed mmdet terminaltables-3.1.0\n",
            "Cleaning up...\n",
            "  Removing source in /tmp/pip-install-5ewyn4_f/terminaltables\n",
            "Removed build tracker: '/tmp/pip-req-tracker-nt9s4epn'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT0VbUre6_fD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "b8103519-e4f0-4b84-9816-d2dc6a1c3b86"
      },
      "source": [
        "!pip install mmcv-full"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mmcv-full\n",
            "  Downloading mmcv-full-1.1.2.tar.gz (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 35.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 2.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 3.9 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 3.3 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 153 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 194 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 235 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading addict-2.2.1-py3-none-any.whl (3.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from mmcv-full) (1.19.1)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
            "\u001b[K     |████████████████████████████████| 269 kB 12.5 MB/s \n",
            "\u001b[?25hCollecting yapf\n",
            "  Downloading yapf-0.30.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 20.1 MB/s \n",
            "\u001b[?25hCollecting opencv-python>=3\n",
            "  Downloading opencv_python-4.4.0.42-cp37-cp37m-manylinux2014_x86_64.whl (49.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.4 MB 50 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mmcv-full, pyyaml\n",
            "  Building wheel for mmcv-full (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv-full: filename=mmcv_full-1.1.2-cp37-cp37m-linux_x86_64.whl size=16037740 sha256=a81a86afd54a740041a1f03e4ebdb841b6280ad98d99d6c2c07b58b1638827c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/dc/9c/b08cc3aaddc4dc75f57e1e522f208671645f7956b17bfcff9c\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=393702 sha256=3d9572d45324aa4cd7a99fa30cd5b450e5605de4d138cfc56472db875ca7eaf4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n",
            "Successfully built mmcv-full pyyaml\n",
            "Installing collected packages: addict, pyyaml, yapf, opencv-python, mmcv-full\n",
            "Successfully installed addict-2.2.1 mmcv-full-1.1.2 opencv-python-4.4.0.42 pyyaml-5.3.1 yapf-0.30.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5l0njSzfdss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8c46970-321e-44a8-f8c9-65f7bb0dabeb"
      },
      "source": [
        "!pip install ipykernel"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipykernel\n",
            "  Downloading ipykernel-5.3.4-py3-none-any.whl (120 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▊                             | 10 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 30 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 51 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 61 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 92 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 102 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 112 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 120 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting jupyter-client\n",
            "  Downloading jupyter_client-6.1.7-py3-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 17.8 MB/s \n",
            "\u001b[?25hCollecting ipython>=5.0.0\n",
            "  Downloading ipython-7.18.1-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 16.0 MB/s \n",
            "\u001b[?25hCollecting tornado>=4.2\n",
            "  Downloading tornado-6.0.4.tar.gz (496 kB)\n",
            "\u001b[K     |████████████████████████████████| 496 kB 35.4 MB/s \n",
            "\u001b[?25hCollecting traitlets>=4.1.0\n",
            "  Downloading traitlets-5.0.4-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 8.3 MB/s \n",
            "\u001b[?25hCollecting jupyter-core>=4.6.0\n",
            "  Downloading jupyter_core-4.6.3-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from jupyter-client->ipykernel) (2.8.1)\n",
            "Collecting pyzmq>=13\n",
            "  Downloading pyzmq-19.0.2-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 31.3 MB/s \n",
            "\u001b[?25hCollecting jedi>=0.10\n",
            "  Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 53.2 MB/s \n",
            "\u001b[?25hCollecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.7-py3-none-any.whl (355 kB)\n",
            "\u001b[K     |████████████████████████████████| 355 kB 62.2 MB/s \n",
            "\u001b[?25hCollecting decorator\n",
            "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting pygments\n",
            "  Downloading Pygments-2.6.1-py3-none-any.whl (914 kB)\n",
            "\u001b[K     |████████████████████████████████| 914 kB 67.1 MB/s \n",
            "\u001b[?25hCollecting pexpect>4.3; sys_platform != \"win32\"\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel) (45.2.0.post20200210)\n",
            "Collecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting ipython-genutils\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.1->jupyter-client->ipykernel) (1.14.0)\n",
            "Collecting parso<0.8.0,>=0.7.0\n",
            "  Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 67.5 MB/s \n",
            "\u001b[?25hCollecting wcwidth\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Collecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.6.0-py2.py3-none-any.whl (39 kB)\n",
            "Building wheels for collected packages: tornado\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-6.0.4-cp37-cp37m-linux_x86_64.whl size=428628 sha256=65f562a18065b411af6a4be4a1d6b4362246fd7fd8edda7d32ad312e534a4578\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/14/fa/d88fb5da77d813ea0ffca38a2ab2a052874e9e1142bad0b348\n",
            "Successfully built tornado\n",
            "Installing collected packages: ipython-genutils, traitlets, tornado, jupyter-core, pyzmq, jupyter-client, parso, jedi, wcwidth, prompt-toolkit, decorator, pickleshare, pygments, ptyprocess, pexpect, backcall, ipython, ipykernel\n",
            "Successfully installed backcall-0.2.0 decorator-4.4.2 ipykernel-5.3.4 ipython-7.18.1 ipython-genutils-0.2.0 jedi-0.17.2 jupyter-client-6.1.7 jupyter-core-4.6.3 parso-0.7.1 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.7 ptyprocess-0.6.0 pygments-2.6.1 pyzmq-19.0.2 tornado-6.0.4 traitlets-5.0.4 wcwidth-0.2.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "decorator",
                  "ipython_genutils",
                  "jupyter_core",
                  "pexpect",
                  "pickleshare",
                  "wcwidth",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DFcw0QKIROn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "outputId": "948d6265-addd-4cb9-b0b7-9fe4bbd7a408"
      },
      "source": [
        "!pip install albumentations"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting albumentations\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▉                             | 10 kB 27.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 20 kB 2.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 30 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 40 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 51 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 61 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 71 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 81 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 102 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 112 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 117 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/site-packages (from albumentations) (1.19.1)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 7.2 kB/s \n",
            "\u001b[?25hCollecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 64.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/site-packages (from albumentations) (5.3.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/site-packages (from albumentations) (4.4.0.42)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (3.3.1)\n",
            "Collecting imageio\n",
            "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 65.8 MB/s \n",
            "\u001b[?25hCollecting Shapely\n",
            "  Downloading Shapely-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 55.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (1.14.0)\n",
            "Collecting scikit-image>=0.14.2\n",
            "  Downloading scikit_image-0.17.2-cp37-cp37m-manylinux1_x86_64.whl (12.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.5 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2020.6.20)\n",
            "Collecting networkx>=2.0\n",
            "  Downloading networkx-2.5-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 63.6 MB/s \n",
            "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
            "  Downloading PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 53.0 MB/s \n",
            "\u001b[?25hCollecting tifffile>=2019.7.26\n",
            "  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
            "\u001b[K     |████████████████████████████████| 148 kB 52.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug>=0.4.0->albumentations) (4.4.2)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65162 sha256=d32a380a69378767beeb0ac7cf1929f816ac8439e426d0fbfd8463756d7d9367\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
            "Successfully built albumentations\n",
            "Installing collected packages: scipy, imageio, Shapely, networkx, PyWavelets, tifffile, scikit-image, imgaug, albumentations\n",
            "Successfully installed PyWavelets-1.1.1 Shapely-1.7.1 albumentations-0.4.6 imageio-2.9.0 imgaug-0.4.0 networkx-2.5 scikit-image-0.17.2 scipy-1.5.2 tifffile-2020.9.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WxC1ukvUOND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dedff1cb-6889-403f-e6ae-15a0e11cd3f4"
      },
      "source": [
        "!python tools/train.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py --resume-from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_12.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-08 04:31:37,595 - mmdet - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]\n",
            "CUDA available: True\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
            "GPU 0: Tesla T4\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.4.0\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CUDA Runtime 10.0\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.1\n",
            "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "TorchVision: 0.5.0\n",
            "OpenCV: 4.4.0\n",
            "MMCV: 1.1.2\n",
            "MMDetection: 2.3.0+\n",
            "MMDetection Compiler: GCC 7.5\n",
            "MMDetection CUDA Compiler: 10.1\n",
            "------------------------------------------------------------\n",
            "\n",
            "2020-09-08 04:31:38,346 - mmdet - INFO - Distributed training: False\n",
            "2020-09-08 04:31:39,129 - mmdet - INFO - Config:\n",
            "model = dict(\n",
            "    type='CascadeRCNN',\n",
            "    pretrained='open-mmlab://resnext101_32x4d',\n",
            "    backbone=dict(\n",
            "        type='DetectoRS_ResNeXt',\n",
            "        depth=101,\n",
            "        groups=32,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch',\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(False, True, True, True),\n",
            "        output_img=True),\n",
            "    neck=dict(\n",
            "        type='RFP',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5,\n",
            "        rfp_steps=2,\n",
            "        aspp_out_channels=64,\n",
            "        aspp_dilations=(1, 3, 6, 1),\n",
            "        rfp_backbone=dict(\n",
            "            rfp_inplanes=256,\n",
            "            type='DetectoRS_ResNeXt',\n",
            "            depth=101,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(False, True, True, True),\n",
            "            pretrained='open-mmlab://resnext101_32x4d',\n",
            "            style='pytorch')),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(\n",
            "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='CascadeRoIHead',\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[1, 0.5, 0.25],\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='GenericRoIExtractor',\n",
            "            aggregation='sum',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32],\n",
            "            pre_cfg=dict(\n",
            "                type='ConvModule',\n",
            "                in_channels=256,\n",
            "                out_channels=256,\n",
            "                kernel_size=5,\n",
            "                padding=2,\n",
            "                inplace=False),\n",
            "            post_cfg=dict(\n",
            "                type='GeneralizedAttention',\n",
            "                in_channels=256,\n",
            "                spatial_range=-1,\n",
            "                num_heads=6,\n",
            "                attention_type='0100',\n",
            "                kv_stride=2)),\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.7),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.5),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.3),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0))\n",
            "        ]))\n",
            "train_cfg = dict(\n",
            "    rpn=dict(\n",
            "        assigner=dict(\n",
            "            type='MaxIoUAssigner',\n",
            "            pos_iou_thr=0.7,\n",
            "            neg_iou_thr=0.3,\n",
            "            min_pos_iou=0.3,\n",
            "            match_low_quality=True,\n",
            "            ignore_iof_thr=-1),\n",
            "        sampler=dict(\n",
            "            type='RandomSampler',\n",
            "            num=256,\n",
            "            pos_fraction=0.5,\n",
            "            neg_pos_ub=-1,\n",
            "            add_gt_as_proposals=False),\n",
            "        allowed_border=0,\n",
            "        pos_weight=-1,\n",
            "        debug=False),\n",
            "    rpn_proposal=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=2000,\n",
            "        nms_post=2000,\n",
            "        max_num=2000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=[\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.6,\n",
            "                neg_iou_thr=0.6,\n",
            "                min_pos_iou=0.6,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.7,\n",
            "                min_pos_iou=0.7,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)\n",
            "    ])\n",
            "test_cfg = dict(\n",
            "    rpn=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=1000,\n",
            "        nms_post=1000,\n",
            "        max_num=1000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=dict(\n",
            "        score_thr=0.05,\n",
            "        nms=dict(type='nms', iou_threshold=0.5),\n",
            "        max_per_img=100))\n",
            "dataset_type = 'CustomDataset'\n",
            "data_root = 'data/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "albu_train_transforms = [\n",
            "    dict(\n",
            "        type='ShiftScaleRotate',\n",
            "        shift_limit=0.0625,\n",
            "        scale_limit=0.0,\n",
            "        rotate_limit=0,\n",
            "        interpolation=1,\n",
            "        p=0.5),\n",
            "    dict(\n",
            "        type='RandomBrightnessContrast',\n",
            "        brightness_limit=[0.1, 0.3],\n",
            "        contrast_limit=[0.1, 0.3],\n",
            "        p=0.2),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='RGBShift',\n",
            "                r_shift_limit=10,\n",
            "                g_shift_limit=10,\n",
            "                b_shift_limit=10,\n",
            "                p=1.0),\n",
            "            dict(\n",
            "                type='HueSaturationValue',\n",
            "                hue_shift_limit=20,\n",
            "                sat_shift_limit=30,\n",
            "                val_shift_limit=20,\n",
            "                p=1.0)\n",
            "        ],\n",
            "        p=0.1),\n",
            "    dict(type='JpegCompression', quality_lower=85, quality_upper=95, p=0.2),\n",
            "    dict(type='ChannelShuffle', p=0.1),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "        ],\n",
            "        p=0.1)\n",
            "]\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        type='Resize',\n",
            "        multiscale_mode='range',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(\n",
            "        type='Albu',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='ShiftScaleRotate',\n",
            "                shift_limit=0.0625,\n",
            "                scale_limit=0.0,\n",
            "                rotate_limit=0,\n",
            "                interpolation=1,\n",
            "                p=0.5),\n",
            "            dict(\n",
            "                type='RandomBrightnessContrast',\n",
            "                brightness_limit=[0.1, 0.3],\n",
            "                contrast_limit=[0.1, 0.3],\n",
            "                p=0.2),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='RGBShift',\n",
            "                        r_shift_limit=10,\n",
            "                        g_shift_limit=10,\n",
            "                        b_shift_limit=10,\n",
            "                        p=1.0),\n",
            "                    dict(\n",
            "                        type='HueSaturationValue',\n",
            "                        hue_shift_limit=20,\n",
            "                        sat_shift_limit=30,\n",
            "                        val_shift_limit=20,\n",
            "                        p=1.0)\n",
            "                ],\n",
            "                p=0.1),\n",
            "            dict(\n",
            "                type='JpegCompression',\n",
            "                quality_lower=85,\n",
            "                quality_upper=95,\n",
            "                p=0.2),\n",
            "            dict(type='ChannelShuffle', p=0.1),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                    dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                ],\n",
            "                p=0.1)\n",
            "        ],\n",
            "        bbox_params=dict(\n",
            "            type='BboxParams',\n",
            "            format='pascal_voc',\n",
            "            label_fields=['gt_labels'],\n",
            "            min_visibility=0.0,\n",
            "            filter_lost_elements=True),\n",
            "        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "        update_pad_shape=False,\n",
            "        skip_img_without_anno=True),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(\n",
            "        type='Collect',\n",
            "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "        meta_keys=('filename', 'ori_shape', 'img_shape', 'img_norm_cfg',\n",
            "                   'pad_shape', 'scale_factor'))\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        transforms=[\n",
            "            dict(type='Resize', multiscale_mode='range', keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=1.0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=1,\n",
            "    workers_per_gpu=1,\n",
            "    train=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/train_80_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                multiscale_mode='range',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(\n",
            "                type='Albu',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='ShiftScaleRotate',\n",
            "                        shift_limit=0.0625,\n",
            "                        scale_limit=0.0,\n",
            "                        rotate_limit=0,\n",
            "                        interpolation=1,\n",
            "                        p=0.5),\n",
            "                    dict(\n",
            "                        type='RandomBrightnessContrast',\n",
            "                        brightness_limit=[0.1, 0.3],\n",
            "                        contrast_limit=[0.1, 0.3],\n",
            "                        p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(\n",
            "                                type='RGBShift',\n",
            "                                r_shift_limit=10,\n",
            "                                g_shift_limit=10,\n",
            "                                b_shift_limit=10,\n",
            "                                p=1.0),\n",
            "                            dict(\n",
            "                                type='HueSaturationValue',\n",
            "                                hue_shift_limit=20,\n",
            "                                sat_shift_limit=30,\n",
            "                                val_shift_limit=20,\n",
            "                                p=1.0)\n",
            "                        ],\n",
            "                        p=0.1),\n",
            "                    dict(\n",
            "                        type='JpegCompression',\n",
            "                        quality_lower=75,\n",
            "                        quality_upper=95,\n",
            "                        p=0.2),\n",
            "                    dict(type='ChannelShuffle', p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                        ],\n",
            "                        p=0.1)\n",
            "                ],\n",
            "                bbox_params=dict(\n",
            "                    type='BboxParams',\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=['gt_labels'],\n",
            "                    min_visibility=0.0,\n",
            "                    filter_lost_elements=True),\n",
            "                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "                update_pad_shape=False,\n",
            "                skip_img_without_anno=True),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "                meta_keys=('filename', 'ori_shape', 'img_shape',\n",
            "                           'img_norm_cfg', 'pad_shape', 'scale_factor'))\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/val_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/test_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 200), (1999, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=1, metric='mAP')\n",
            "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.3333333333333333,\n",
            "    step=[8, 11])\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=64, hooks=[dict(type='TextLoggerHook')])\n",
            "total_epochs = 20\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "work_dir = './work_dirs/cascade_rcnn_x101_32x4d_fpn_1x'\n",
            "load_from = None\n",
            "resume_from = 'work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_12.pth'\n",
            "workflow = [('train', 1)]\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "2020-09-08 04:31:43,392 - mmdet - INFO - load model from: open-mmlab://resnext101_32x4d\n",
            "Downloading: \"https://openmmlab.oss-accelerate.aliyuncs.com/pretrain/third_party/resnext101_32x4d-a5af3160.pth\" to /root/.cache/torch/checkpoints/resnext101_32x4d-a5af3160.pth\n",
            "100% 161M/161M [00:16<00:00, 10.2MB/s]\n",
            "2020-09-08 04:32:01,121 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "2020-09-08 04:32:01,696 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
            "size mismatch for layer1.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.2.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
            "size mismatch for layer2.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.0.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.1.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.1.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.2.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.2.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.2.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.3.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.3.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.3.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
            "size mismatch for layer3.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.2.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.3.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.3.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.3.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.4.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.4.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.4.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.5.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.5.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.5.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.6.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.6.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.6.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.7.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.7.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.7.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.8.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.8.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.8.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.9.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.9.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.9.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.10.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.10.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.10.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.11.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.11.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.11.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.12.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.12.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.12.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.13.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.13.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.13.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.14.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.14.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.14.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.15.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.15.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.15.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.16.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.16.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.16.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.17.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.17.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.17.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.18.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.18.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.18.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.19.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.19.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.19.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.20.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.20.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.20.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.21.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.21.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.21.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.22.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.22.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.22.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
            "size mismatch for layer4.0.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.0.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.1.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.1.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.2.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.2.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.2.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-08 04:32:08,153 - mmdet - INFO - load checkpoint from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_12.pth\n",
            "2020-09-08 04:32:23,600 - mmdet - INFO - resumed epoch 12, iter 63984\n",
            "2020-09-08 04:32:23,609 - mmdet - INFO - Start running, host: root@f2ce0782ffd8, work_dir: /content/drive/My Drive/mmdetection-master/work_dirs/cascade_rcnn_x101_32x4d_fpn_1x\n",
            "2020-09-08 04:32:23,609 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs\n",
            "2020-09-08 04:34:36,021 - mmdet - INFO - Epoch [13][64/5332]\tlr: 1.000e-05, eta: 1 day, 0:28:28, time: 2.069, data_time: 0.044, memory: 8014, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0216, s0.acc: 99.2065, s0.loss_bbox_cls: 0.0193, s0.loss_bbox_reg: 0.0428, s1.loss_cls: 0.0171, s1.acc: 98.7122, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0346, s2.loss_cls: 0.0103, s2.acc: 98.4039, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0224, loss: 0.2036, grad_norm: 5.0805\n",
            "2020-09-08 04:36:51,886 - mmdet - INFO - Epoch [13][128/5332]\tlr: 1.000e-05, eta: 1 day, 0:45:29, time: 2.123, data_time: 0.005, memory: 8014, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0223, s0.acc: 99.0570, s0.loss_bbox_cls: 0.0234, s0.loss_bbox_reg: 0.0492, s1.loss_cls: 0.0166, s1.acc: 98.6237, s1.loss_bbox_cls: 0.0198, s1.loss_bbox_reg: 0.0395, s2.loss_cls: 0.0112, s2.acc: 98.1079, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0229, loss: 0.2234, grad_norm: 5.6682\n",
            "2020-09-08 04:39:10,522 - mmdet - INFO - Epoch [13][192/5332]\tlr: 1.000e-05, eta: 1 day, 0:59:51, time: 2.166, data_time: 0.005, memory: 8014, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0263, s0.acc: 98.9746, s0.loss_bbox_cls: 0.0229, s0.loss_bbox_reg: 0.0441, s1.loss_cls: 0.0175, s1.acc: 98.5199, s1.loss_bbox_cls: 0.0162, s1.loss_bbox_reg: 0.0329, s2.loss_cls: 0.0105, s2.acc: 98.3582, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0198, loss: 0.2076, grad_norm: 5.1491\n",
            "2020-09-08 04:41:29,924 - mmdet - INFO - Epoch [13][256/5332]\tlr: 1.000e-05, eta: 1 day, 1:08:00, time: 2.178, data_time: 0.005, memory: 8014, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0026, s0.loss_cls: 0.0195, s0.acc: 99.2218, s0.loss_bbox_cls: 0.0182, s0.loss_bbox_reg: 0.0423, s1.loss_cls: 0.0155, s1.acc: 98.6877, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0352, s2.loss_cls: 0.0098, s2.acc: 98.3307, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0217, loss: 0.1963, grad_norm: 5.9388\n",
            "2020-09-08 04:43:48,773 - mmdet - INFO - Epoch [13][320/5332]\tlr: 1.000e-05, eta: 1 day, 1:10:44, time: 2.170, data_time: 0.005, memory: 8014, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0283, s0.acc: 98.8434, s0.loss_bbox_cls: 0.0246, s0.loss_bbox_reg: 0.0504, s1.loss_cls: 0.0188, s1.acc: 98.5535, s1.loss_bbox_cls: 0.0168, s1.loss_bbox_reg: 0.0350, s2.loss_cls: 0.0108, s2.acc: 98.2880, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0211, loss: 0.2244, grad_norm: 5.8972\n",
            "2020-09-08 04:46:07,876 - mmdet - INFO - Epoch [13][384/5332]\tlr: 1.000e-05, eta: 1 day, 1:12:15, time: 2.173, data_time: 0.005, memory: 8014, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0282, s0.acc: 98.8525, s0.loss_bbox_cls: 0.0236, s0.loss_bbox_reg: 0.0490, s1.loss_cls: 0.0205, s1.acc: 98.3948, s1.loss_bbox_cls: 0.0183, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0124, s2.acc: 97.7356, s2.loss_bbox_cls: 0.0092, s2.loss_bbox_reg: 0.0191, loss: 0.2246, grad_norm: 5.7139\n",
            "2020-09-08 04:48:28,223 - mmdet - INFO - Epoch [13][448/5332]\tlr: 1.000e-05, eta: 1 day, 1:14:38, time: 2.193, data_time: 0.005, memory: 8014, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0269, s0.acc: 98.8861, s0.loss_bbox_cls: 0.0206, s0.loss_bbox_reg: 0.0440, s1.loss_cls: 0.0227, s1.acc: 98.0652, s1.loss_bbox_cls: 0.0162, s1.loss_bbox_reg: 0.0336, s2.loss_cls: 0.0136, s2.acc: 97.6868, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0197, loss: 0.2173, grad_norm: 5.7348\n",
            "2020-09-08 04:50:46,616 - mmdet - INFO - Epoch [13][512/5332]\tlr: 1.000e-05, eta: 1 day, 1:13:09, time: 2.162, data_time: 0.005, memory: 8014, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0282, s0.acc: 98.9716, s0.loss_bbox_cls: 0.0218, s0.loss_bbox_reg: 0.0467, s1.loss_cls: 0.0216, s1.acc: 98.3032, s1.loss_bbox_cls: 0.0190, s1.loss_bbox_reg: 0.0383, s2.loss_cls: 0.0119, s2.acc: 98.0743, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0223, loss: 0.2283, grad_norm: 5.9904\n",
            "2020-09-08 04:53:04,917 - mmdet - INFO - Epoch [13][576/5332]\tlr: 1.000e-05, eta: 1 day, 1:11:22, time: 2.161, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0230, s0.acc: 99.1425, s0.loss_bbox_cls: 0.0194, s0.loss_bbox_reg: 0.0416, s1.loss_cls: 0.0185, s1.acc: 98.4924, s1.loss_bbox_cls: 0.0166, s1.loss_bbox_reg: 0.0322, s2.loss_cls: 0.0114, s2.acc: 98.1171, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0200, loss: 0.1988, grad_norm: 4.9687\n",
            "2020-09-08 04:55:23,862 - mmdet - INFO - Epoch [13][640/5332]\tlr: 1.000e-05, eta: 1 day, 1:10:12, time: 2.171, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0268, s0.acc: 98.8953, s0.loss_bbox_cls: 0.0234, s0.loss_bbox_reg: 0.0481, s1.loss_cls: 0.0193, s1.acc: 98.2819, s1.loss_bbox_cls: 0.0182, s1.loss_bbox_reg: 0.0368, s2.loss_cls: 0.0131, s2.acc: 97.7448, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0226, loss: 0.2266, grad_norm: 6.0863\n",
            "2020-09-08 04:57:43,811 - mmdet - INFO - Epoch [13][704/5332]\tlr: 1.000e-05, eta: 1 day, 1:09:48, time: 2.187, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0234, s0.acc: 99.1089, s0.loss_bbox_cls: 0.0190, s0.loss_bbox_reg: 0.0396, s1.loss_cls: 0.0184, s1.acc: 98.5138, s1.loss_bbox_cls: 0.0147, s1.loss_bbox_reg: 0.0308, s2.loss_cls: 0.0122, s2.acc: 97.9462, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0186, loss: 0.1923, grad_norm: 5.0706\n",
            "2020-09-08 05:00:03,509 - mmdet - INFO - Epoch [13][768/5332]\tlr: 1.000e-05, eta: 1 day, 1:08:52, time: 2.183, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0247, s0.acc: 99.0540, s0.loss_bbox_cls: 0.0200, s0.loss_bbox_reg: 0.0465, s1.loss_cls: 0.0163, s1.acc: 98.6328, s1.loss_bbox_cls: 0.0164, s1.loss_bbox_reg: 0.0360, s2.loss_cls: 0.0104, s2.acc: 98.5229, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0214, loss: 0.2100, grad_norm: 5.2471\n",
            "2020-09-08 05:02:22,595 - mmdet - INFO - Epoch [13][832/5332]\tlr: 1.000e-05, eta: 1 day, 1:07:12, time: 2.173, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0274, s0.acc: 98.7976, s0.loss_bbox_cls: 0.0261, s0.loss_bbox_reg: 0.0528, s1.loss_cls: 0.0165, s1.acc: 98.7183, s1.loss_bbox_cls: 0.0220, s1.loss_bbox_reg: 0.0401, s2.loss_cls: 0.0110, s2.acc: 98.1750, s2.loss_bbox_cls: 0.0123, s2.loss_bbox_reg: 0.0228, loss: 0.2422, grad_norm: 6.0183\n",
            "2020-09-08 05:04:42,674 - mmdet - INFO - Epoch [13][896/5332]\tlr: 1.000e-05, eta: 1 day, 1:06:13, time: 2.189, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0215, s0.acc: 99.1272, s0.loss_bbox_cls: 0.0193, s0.loss_bbox_reg: 0.0445, s1.loss_cls: 0.0157, s1.acc: 98.6938, s1.loss_bbox_cls: 0.0162, s1.loss_bbox_reg: 0.0327, s2.loss_cls: 0.0105, s2.acc: 98.2605, s2.loss_bbox_cls: 0.0088, s2.loss_bbox_reg: 0.0192, loss: 0.1952, grad_norm: 5.0776\n",
            "2020-09-08 05:06:59,175 - mmdet - INFO - Epoch [13][960/5332]\tlr: 1.000e-05, eta: 1 day, 1:02:27, time: 2.133, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0242, s0.acc: 99.0326, s0.loss_bbox_cls: 0.0231, s0.loss_bbox_reg: 0.0487, s1.loss_cls: 0.0179, s1.acc: 98.6206, s1.loss_bbox_cls: 0.0194, s1.loss_bbox_reg: 0.0394, s2.loss_cls: 0.0109, s2.acc: 98.0377, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0227, loss: 0.2259, grad_norm: 5.6928\n",
            "2020-09-08 05:09:17,800 - mmdet - INFO - Epoch [13][1024/5332]\tlr: 1.000e-05, eta: 1 day, 1:00:19, time: 2.166, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0201, s0.acc: 99.3225, s0.loss_bbox_cls: 0.0213, s0.loss_bbox_reg: 0.0464, s1.loss_cls: 0.0160, s1.acc: 98.8434, s1.loss_bbox_cls: 0.0186, s1.loss_bbox_reg: 0.0369, s2.loss_cls: 0.0105, s2.acc: 98.4375, s2.loss_bbox_cls: 0.0110, s2.loss_bbox_reg: 0.0223, loss: 0.2087, grad_norm: 5.7485\n",
            "2020-09-08 05:11:37,373 - mmdet - INFO - Epoch [13][1088/5332]\tlr: 1.000e-05, eta: 1 day, 0:58:46, time: 2.181, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0217, s0.acc: 99.1150, s0.loss_bbox_cls: 0.0211, s0.loss_bbox_reg: 0.0439, s1.loss_cls: 0.0157, s1.acc: 98.6725, s1.loss_bbox_cls: 0.0187, s1.loss_bbox_reg: 0.0345, s2.loss_cls: 0.0090, s2.acc: 98.6328, s2.loss_bbox_cls: 0.0118, s2.loss_bbox_reg: 0.0225, loss: 0.2050, grad_norm: 5.5619\n",
            "2020-09-08 05:13:56,609 - mmdet - INFO - Epoch [13][1152/5332]\tlr: 1.000e-05, eta: 1 day, 0:56:56, time: 2.176, data_time: 0.020, memory: 8090, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0281, s0.acc: 98.9624, s0.loss_bbox_cls: 0.0216, s0.loss_bbox_reg: 0.0452, s1.loss_cls: 0.0204, s1.acc: 98.4100, s1.loss_bbox_cls: 0.0164, s1.loss_bbox_reg: 0.0341, s2.loss_cls: 0.0133, s2.acc: 97.9736, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0205, loss: 0.2183, grad_norm: 5.7414\n",
            "2020-09-08 05:16:16,134 - mmdet - INFO - Epoch [13][1216/5332]\tlr: 1.000e-05, eta: 1 day, 0:55:12, time: 2.180, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0295, s0.acc: 98.7457, s0.loss_bbox_cls: 0.0221, s0.loss_bbox_reg: 0.0458, s1.loss_cls: 0.0226, s1.acc: 97.9980, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0352, s2.loss_cls: 0.0140, s2.acc: 97.3999, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0196, loss: 0.2257, grad_norm: 5.6910\n",
            "2020-09-08 05:18:31,278 - mmdet - INFO - Epoch [13][1280/5332]\tlr: 1.000e-05, eta: 1 day, 0:51:04, time: 2.112, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0191, s0.acc: 99.1943, s0.loss_bbox_cls: 0.0170, s0.loss_bbox_reg: 0.0400, s1.loss_cls: 0.0146, s1.acc: 98.7335, s1.loss_bbox_cls: 0.0147, s1.loss_bbox_reg: 0.0324, s2.loss_cls: 0.0087, s2.acc: 98.6053, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0196, loss: 0.1806, grad_norm: 4.9368\n",
            "2020-09-08 05:20:49,491 - mmdet - INFO - Epoch [13][1344/5332]\tlr: 1.000e-05, eta: 1 day, 0:48:40, time: 2.160, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0229, s0.acc: 99.1119, s0.loss_bbox_cls: 0.0228, s0.loss_bbox_reg: 0.0431, s1.loss_cls: 0.0172, s1.acc: 98.5138, s1.loss_bbox_cls: 0.0190, s1.loss_bbox_reg: 0.0339, s2.loss_cls: 0.0112, s2.acc: 98.2300, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0191, loss: 0.2078, grad_norm: 5.4422\n",
            "2020-09-08 05:23:06,771 - mmdet - INFO - Epoch [13][1408/5332]\tlr: 1.000e-05, eta: 1 day, 0:45:50, time: 2.145, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0063, s0.loss_cls: 0.0282, s0.acc: 98.8892, s0.loss_bbox_cls: 0.0233, s0.loss_bbox_reg: 0.0476, s1.loss_cls: 0.0209, s1.acc: 98.1415, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0355, s2.loss_cls: 0.0141, s2.acc: 97.4335, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0197, loss: 0.2281, grad_norm: 5.7966\n",
            "2020-09-08 05:25:23,623 - mmdet - INFO - Epoch [13][1472/5332]\tlr: 1.000e-05, eta: 1 day, 0:42:50, time: 2.138, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0284, s0.acc: 98.8861, s0.loss_bbox_cls: 0.0231, s0.loss_bbox_reg: 0.0476, s1.loss_cls: 0.0230, s1.acc: 98.1750, s1.loss_bbox_cls: 0.0192, s1.loss_bbox_reg: 0.0377, s2.loss_cls: 0.0149, s2.acc: 97.4945, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0235, loss: 0.2344, grad_norm: 6.0206\n",
            "2020-09-08 05:27:41,556 - mmdet - INFO - Epoch [13][1536/5332]\tlr: 1.000e-05, eta: 1 day, 0:40:23, time: 2.155, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0235, s0.acc: 99.0234, s0.loss_bbox_cls: 0.0228, s0.loss_bbox_reg: 0.0484, s1.loss_cls: 0.0160, s1.acc: 98.7518, s1.loss_bbox_cls: 0.0187, s1.loss_bbox_reg: 0.0371, s2.loss_cls: 0.0094, s2.acc: 98.4985, s2.loss_bbox_cls: 0.0124, s2.loss_bbox_reg: 0.0230, loss: 0.2200, grad_norm: 5.5346\n",
            "2020-09-08 05:29:59,279 - mmdet - INFO - Epoch [13][1600/5332]\tlr: 1.000e-05, eta: 1 day, 0:37:51, time: 2.152, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0188, s0.acc: 99.2310, s0.loss_bbox_cls: 0.0162, s0.loss_bbox_reg: 0.0374, s1.loss_cls: 0.0152, s1.acc: 98.7915, s1.loss_bbox_cls: 0.0148, s1.loss_bbox_reg: 0.0316, s2.loss_cls: 0.0105, s2.acc: 98.1964, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0195, loss: 0.1826, grad_norm: 5.1896\n",
            "2020-09-08 05:32:16,932 - mmdet - INFO - Epoch [13][1664/5332]\tlr: 1.000e-05, eta: 1 day, 0:35:19, time: 2.151, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0227, s0.acc: 99.1302, s0.loss_bbox_cls: 0.0219, s0.loss_bbox_reg: 0.0432, s1.loss_cls: 0.0171, s1.acc: 98.7213, s1.loss_bbox_cls: 0.0191, s1.loss_bbox_reg: 0.0350, s2.loss_cls: 0.0117, s2.acc: 98.0133, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0203, loss: 0.2090, grad_norm: 5.2692\n",
            "2020-09-08 05:34:34,204 - mmdet - INFO - Epoch [13][1728/5332]\tlr: 1.000e-05, eta: 1 day, 0:32:39, time: 2.145, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0279, s0.acc: 98.9380, s0.loss_bbox_cls: 0.0230, s0.loss_bbox_reg: 0.0469, s1.loss_cls: 0.0201, s1.acc: 98.5321, s1.loss_bbox_cls: 0.0160, s1.loss_bbox_reg: 0.0332, s2.loss_cls: 0.0112, s2.acc: 98.3490, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0190, loss: 0.2141, grad_norm: 5.7634\n",
            "2020-09-08 05:36:52,674 - mmdet - INFO - Epoch [13][1792/5332]\tlr: 1.000e-05, eta: 1 day, 0:30:27, time: 2.164, data_time: 0.017, memory: 8090, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0199, s0.acc: 99.2035, s0.loss_bbox_cls: 0.0181, s0.loss_bbox_reg: 0.0417, s1.loss_cls: 0.0152, s1.acc: 98.8586, s1.loss_bbox_cls: 0.0150, s1.loss_bbox_reg: 0.0328, s2.loss_cls: 0.0092, s2.acc: 98.4955, s2.loss_bbox_cls: 0.0087, s2.loss_bbox_reg: 0.0191, loss: 0.1881, grad_norm: 5.0182\n",
            "2020-09-08 05:39:11,677 - mmdet - INFO - Epoch [13][1856/5332]\tlr: 1.000e-05, eta: 1 day, 0:28:27, time: 2.172, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0207, s0.acc: 99.0997, s0.loss_bbox_cls: 0.0211, s0.loss_bbox_reg: 0.0423, s1.loss_cls: 0.0170, s1.acc: 98.5504, s1.loss_bbox_cls: 0.0174, s1.loss_bbox_reg: 0.0335, s2.loss_cls: 0.0131, s2.acc: 97.7661, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0196, loss: 0.2016, grad_norm: 5.3757\n",
            "2020-09-08 05:41:30,519 - mmdet - INFO - Epoch [13][1920/5332]\tlr: 1.000e-05, eta: 1 day, 0:26:22, time: 2.169, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0220, s0.acc: 99.1333, s0.loss_bbox_cls: 0.0204, s0.loss_bbox_reg: 0.0423, s1.loss_cls: 0.0175, s1.acc: 98.5138, s1.loss_bbox_cls: 0.0147, s1.loss_bbox_reg: 0.0294, s2.loss_cls: 0.0108, s2.acc: 98.1750, s2.loss_bbox_cls: 0.0076, s2.loss_bbox_reg: 0.0162, loss: 0.1917, grad_norm: 5.2159\n",
            "2020-09-08 05:43:49,424 - mmdet - INFO - Epoch [13][1984/5332]\tlr: 1.000e-05, eta: 1 day, 0:24:18, time: 2.170, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0303, s0.acc: 98.7915, s0.loss_bbox_cls: 0.0261, s0.loss_bbox_reg: 0.0501, s1.loss_cls: 0.0233, s1.acc: 98.1110, s1.loss_bbox_cls: 0.0212, s1.loss_bbox_reg: 0.0375, s2.loss_cls: 0.0143, s2.acc: 97.5433, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0206, loss: 0.2428, grad_norm: 6.3889\n",
            "2020-09-08 05:46:07,790 - mmdet - INFO - Epoch [13][2048/5332]\tlr: 1.000e-05, eta: 1 day, 0:22:02, time: 2.162, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0212, s0.acc: 99.1089, s0.loss_bbox_cls: 0.0233, s0.loss_bbox_reg: 0.0473, s1.loss_cls: 0.0141, s1.acc: 98.9777, s1.loss_bbox_cls: 0.0192, s1.loss_bbox_reg: 0.0361, s2.loss_cls: 0.0101, s2.acc: 98.3917, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0204, loss: 0.2081, grad_norm: 5.3470\n",
            "2020-09-08 05:48:27,920 - mmdet - INFO - Epoch [13][2112/5332]\tlr: 1.000e-05, eta: 1 day, 0:20:20, time: 2.190, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0233, s0.acc: 99.0509, s0.loss_bbox_cls: 0.0211, s0.loss_bbox_reg: 0.0431, s1.loss_cls: 0.0181, s1.acc: 98.5352, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0343, s2.loss_cls: 0.0118, s2.acc: 98.0408, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0202, loss: 0.2082, grad_norm: 5.2550\n",
            "2020-09-08 05:50:48,882 - mmdet - INFO - Epoch [13][2176/5332]\tlr: 1.000e-05, eta: 1 day, 0:18:51, time: 2.202, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0024, s0.loss_cls: 0.0261, s0.acc: 98.9990, s0.loss_bbox_cls: 0.0181, s0.loss_bbox_reg: 0.0409, s1.loss_cls: 0.0194, s1.acc: 98.5199, s1.loss_bbox_cls: 0.0162, s1.loss_bbox_reg: 0.0332, s2.loss_cls: 0.0119, s2.acc: 98.2483, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0211, loss: 0.2016, grad_norm: 5.0175\n",
            "2020-09-08 05:53:08,171 - mmdet - INFO - Epoch [13][2240/5332]\tlr: 1.000e-05, eta: 1 day, 0:16:49, time: 2.176, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0234, s0.acc: 99.0509, s0.loss_bbox_cls: 0.0200, s0.loss_bbox_reg: 0.0427, s1.loss_cls: 0.0191, s1.acc: 98.4222, s1.loss_bbox_cls: 0.0157, s1.loss_bbox_reg: 0.0325, s2.loss_cls: 0.0111, s2.acc: 98.1750, s2.loss_bbox_cls: 0.0086, s2.loss_bbox_reg: 0.0189, loss: 0.2014, grad_norm: 5.1401\n",
            "2020-09-08 05:55:27,530 - mmdet - INFO - Epoch [13][2304/5332]\tlr: 1.000e-05, eta: 1 day, 0:14:47, time: 2.177, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0257, s0.acc: 98.9532, s0.loss_bbox_cls: 0.0237, s0.loss_bbox_reg: 0.0496, s1.loss_cls: 0.0176, s1.acc: 98.5535, s1.loss_bbox_cls: 0.0203, s1.loss_bbox_reg: 0.0409, s2.loss_cls: 0.0113, s2.acc: 98.3002, s2.loss_bbox_cls: 0.0120, s2.loss_bbox_reg: 0.0250, loss: 0.2338, grad_norm: 5.7315\n",
            "2020-09-08 05:57:48,437 - mmdet - INFO - Epoch [13][2368/5332]\tlr: 1.000e-05, eta: 1 day, 0:13:10, time: 2.202, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0251, s0.acc: 99.0204, s0.loss_bbox_cls: 0.0222, s0.loss_bbox_reg: 0.0469, s1.loss_cls: 0.0171, s1.acc: 98.6755, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0364, s2.loss_cls: 0.0104, s2.acc: 98.2361, s2.loss_bbox_cls: 0.0112, s2.loss_bbox_reg: 0.0228, loss: 0.2181, grad_norm: 5.4659\n",
            "2020-09-08 06:00:06,263 - mmdet - INFO - Epoch [13][2432/5332]\tlr: 1.000e-05, eta: 1 day, 0:10:40, time: 2.154, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0260, s0.acc: 98.9410, s0.loss_bbox_cls: 0.0236, s0.loss_bbox_reg: 0.0451, s1.loss_cls: 0.0187, s1.acc: 98.4253, s1.loss_bbox_cls: 0.0145, s1.loss_bbox_reg: 0.0314, s2.loss_cls: 0.0117, s2.acc: 98.1476, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0193, loss: 0.2080, grad_norm: 5.4482\n",
            "2020-09-08 06:02:25,512 - mmdet - INFO - Epoch [13][2496/5332]\tlr: 1.000e-05, eta: 1 day, 0:08:34, time: 2.176, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0273, s0.acc: 98.9380, s0.loss_bbox_cls: 0.0239, s0.loss_bbox_reg: 0.0485, s1.loss_cls: 0.0189, s1.acc: 98.5199, s1.loss_bbox_cls: 0.0172, s1.loss_bbox_reg: 0.0363, s2.loss_cls: 0.0111, s2.acc: 98.0896, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0198, loss: 0.2200, grad_norm: 5.6548\n",
            "2020-09-08 06:04:43,775 - mmdet - INFO - Epoch [13][2560/5332]\tlr: 1.000e-05, eta: 1 day, 0:06:12, time: 2.160, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0293, s0.acc: 98.9197, s0.loss_bbox_cls: 0.0264, s0.loss_bbox_reg: 0.0514, s1.loss_cls: 0.0212, s1.acc: 98.3978, s1.loss_bbox_cls: 0.0215, s1.loss_bbox_reg: 0.0399, s2.loss_cls: 0.0143, s2.acc: 97.7722, s2.loss_bbox_cls: 0.0118, s2.loss_bbox_reg: 0.0225, loss: 0.2505, grad_norm: 6.0516\n",
            "2020-09-08 06:07:03,215 - mmdet - INFO - Epoch [13][2624/5332]\tlr: 1.000e-05, eta: 1 day, 0:04:08, time: 2.179, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0240, s0.acc: 98.9105, s0.loss_bbox_cls: 0.0216, s0.loss_bbox_reg: 0.0452, s1.loss_cls: 0.0194, s1.acc: 98.3063, s1.loss_bbox_cls: 0.0172, s1.loss_bbox_reg: 0.0332, s2.loss_cls: 0.0118, s2.acc: 98.1567, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0191, loss: 0.2095, grad_norm: 5.5291\n",
            "2020-09-08 06:09:21,427 - mmdet - INFO - Epoch [13][2688/5332]\tlr: 1.000e-05, eta: 1 day, 0:01:44, time: 2.160, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0225, s0.acc: 99.1119, s0.loss_bbox_cls: 0.0174, s0.loss_bbox_reg: 0.0389, s1.loss_cls: 0.0167, s1.acc: 98.5382, s1.loss_bbox_cls: 0.0152, s1.loss_bbox_reg: 0.0320, s2.loss_cls: 0.0106, s2.acc: 98.1781, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0198, loss: 0.1911, grad_norm: 4.9734\n",
            "2020-09-08 06:11:40,812 - mmdet - INFO - Epoch [13][2752/5332]\tlr: 1.000e-05, eta: 23:59:38, time: 2.178, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0240, s0.acc: 99.0814, s0.loss_bbox_cls: 0.0237, s0.loss_bbox_reg: 0.0463, s1.loss_cls: 0.0181, s1.acc: 98.4222, s1.loss_bbox_cls: 0.0198, s1.loss_bbox_reg: 0.0367, s2.loss_cls: 0.0115, s2.acc: 97.9675, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0211, loss: 0.2220, grad_norm: 5.6225\n",
            "2020-09-08 06:14:01,358 - mmdet - INFO - Epoch [13][2816/5332]\tlr: 1.000e-05, eta: 23:57:48, time: 2.196, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0233, s0.acc: 99.0997, s0.loss_bbox_cls: 0.0231, s0.loss_bbox_reg: 0.0438, s1.loss_cls: 0.0190, s1.acc: 98.3246, s1.loss_bbox_cls: 0.0189, s1.loss_bbox_reg: 0.0350, s2.loss_cls: 0.0137, s2.acc: 97.6562, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0187, loss: 0.2132, grad_norm: 5.6217\n",
            "2020-09-08 06:16:21,554 - mmdet - INFO - Epoch [13][2880/5332]\tlr: 1.000e-05, eta: 23:55:52, time: 2.191, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0224, s0.acc: 99.1791, s0.loss_bbox_cls: 0.0187, s0.loss_bbox_reg: 0.0400, s1.loss_cls: 0.0157, s1.acc: 98.7366, s1.loss_bbox_cls: 0.0139, s1.loss_bbox_reg: 0.0292, s2.loss_cls: 0.0111, s2.acc: 98.0591, s2.loss_bbox_cls: 0.0075, s2.loss_bbox_reg: 0.0168, loss: 0.1831, grad_norm: 5.0626\n",
            "2020-09-08 06:18:39,424 - mmdet - INFO - Epoch [13][2944/5332]\tlr: 1.000e-05, eta: 23:53:23, time: 2.154, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0238, s0.acc: 99.0540, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0458, s1.loss_cls: 0.0178, s1.acc: 98.4650, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0352, s2.loss_cls: 0.0107, s2.acc: 98.2758, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0221, loss: 0.2137, grad_norm: 5.5074\n",
            "2020-09-08 06:20:57,993 - mmdet - INFO - Epoch [13][3008/5332]\tlr: 1.000e-05, eta: 23:51:04, time: 2.165, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0218, s0.acc: 99.1394, s0.loss_bbox_cls: 0.0256, s0.loss_bbox_reg: 0.0521, s1.loss_cls: 0.0152, s1.acc: 98.7885, s1.loss_bbox_cls: 0.0217, s1.loss_bbox_reg: 0.0411, s2.loss_cls: 0.0105, s2.acc: 98.1262, s2.loss_bbox_cls: 0.0136, s2.loss_bbox_reg: 0.0257, loss: 0.2325, grad_norm: 5.9865\n",
            "2020-09-08 06:23:16,784 - mmdet - INFO - Epoch [13][3072/5332]\tlr: 1.000e-05, eta: 23:48:48, time: 2.169, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0243, s0.acc: 98.9349, s0.loss_bbox_cls: 0.0231, s0.loss_bbox_reg: 0.0492, s1.loss_cls: 0.0171, s1.acc: 98.7579, s1.loss_bbox_cls: 0.0192, s1.loss_bbox_reg: 0.0377, s2.loss_cls: 0.0111, s2.acc: 98.2178, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0213, loss: 0.2213, grad_norm: 5.6119\n",
            "2020-09-08 06:25:34,613 - mmdet - INFO - Epoch [13][3136/5332]\tlr: 1.000e-05, eta: 23:46:20, time: 2.154, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0207, s0.acc: 99.2249, s0.loss_bbox_cls: 0.0171, s0.loss_bbox_reg: 0.0407, s1.loss_cls: 0.0148, s1.acc: 98.9685, s1.loss_bbox_cls: 0.0143, s1.loss_bbox_reg: 0.0321, s2.loss_cls: 0.0088, s2.acc: 98.7000, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0201, loss: 0.1878, grad_norm: 4.8067\n",
            "2020-09-08 06:27:54,342 - mmdet - INFO - Epoch [13][3200/5332]\tlr: 1.000e-05, eta: 23:44:15, time: 2.183, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0234, s0.acc: 99.0662, s0.loss_bbox_cls: 0.0247, s0.loss_bbox_reg: 0.0532, s1.loss_cls: 0.0162, s1.acc: 98.7396, s1.loss_bbox_cls: 0.0208, s1.loss_bbox_reg: 0.0431, s2.loss_cls: 0.0102, s2.acc: 98.4467, s2.loss_bbox_cls: 0.0112, s2.loss_bbox_reg: 0.0240, loss: 0.2350, grad_norm: 6.1355\n",
            "2020-09-08 06:30:11,692 - mmdet - INFO - Epoch [13][3264/5332]\tlr: 1.000e-05, eta: 23:41:41, time: 2.146, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0212, s0.acc: 99.1425, s0.loss_bbox_cls: 0.0182, s0.loss_bbox_reg: 0.0417, s1.loss_cls: 0.0165, s1.acc: 98.6450, s1.loss_bbox_cls: 0.0147, s1.loss_bbox_reg: 0.0326, s2.loss_cls: 0.0096, s2.acc: 98.3856, s2.loss_bbox_cls: 0.0088, s2.loss_bbox_reg: 0.0197, loss: 0.1911, grad_norm: 5.3652\n",
            "2020-09-08 06:32:30,407 - mmdet - INFO - Epoch [13][3328/5332]\tlr: 1.000e-05, eta: 23:39:24, time: 2.167, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0219, s0.acc: 99.1394, s0.loss_bbox_cls: 0.0196, s0.loss_bbox_reg: 0.0409, s1.loss_cls: 0.0156, s1.acc: 98.6176, s1.loss_bbox_cls: 0.0165, s1.loss_bbox_reg: 0.0316, s2.loss_cls: 0.0098, s2.acc: 98.3490, s2.loss_bbox_cls: 0.0092, s2.loss_bbox_reg: 0.0186, loss: 0.1916, grad_norm: 4.8319\n",
            "2020-09-08 06:34:50,100 - mmdet - INFO - Epoch [13][3392/5332]\tlr: 1.000e-05, eta: 23:37:18, time: 2.183, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0272, s0.acc: 98.9288, s0.loss_bbox_cls: 0.0258, s0.loss_bbox_reg: 0.0550, s1.loss_cls: 0.0168, s1.acc: 98.6328, s1.loss_bbox_cls: 0.0226, s1.loss_bbox_reg: 0.0419, s2.loss_cls: 0.0113, s2.acc: 98.2330, s2.loss_bbox_cls: 0.0123, s2.loss_bbox_reg: 0.0244, loss: 0.2458, grad_norm: 6.1453\n",
            "2020-09-08 06:37:08,302 - mmdet - INFO - Epoch [13][3456/5332]\tlr: 1.000e-05, eta: 23:34:55, time: 2.159, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0215, s0.acc: 99.1516, s0.loss_bbox_cls: 0.0212, s0.loss_bbox_reg: 0.0438, s1.loss_cls: 0.0156, s1.acc: 98.6237, s1.loss_bbox_cls: 0.0193, s1.loss_bbox_reg: 0.0354, s2.loss_cls: 0.0110, s2.acc: 98.1689, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0211, loss: 0.2068, grad_norm: 5.2307\n",
            "2020-09-08 06:39:27,422 - mmdet - INFO - Epoch [13][3520/5332]\tlr: 1.000e-05, eta: 23:32:42, time: 2.174, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0249, s0.acc: 99.0509, s0.loss_bbox_cls: 0.0187, s0.loss_bbox_reg: 0.0426, s1.loss_cls: 0.0176, s1.acc: 98.6725, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0362, s2.loss_cls: 0.0107, s2.acc: 98.1781, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0210, loss: 0.2094, grad_norm: 5.8750\n",
            "2020-09-08 06:41:45,543 - mmdet - INFO - Epoch [13][3584/5332]\tlr: 1.000e-05, eta: 23:30:18, time: 2.158, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0228, s0.acc: 99.1486, s0.loss_bbox_cls: 0.0166, s0.loss_bbox_reg: 0.0389, s1.loss_cls: 0.0177, s1.acc: 98.5657, s1.loss_bbox_cls: 0.0139, s1.loss_bbox_reg: 0.0306, s2.loss_cls: 0.0114, s2.acc: 97.9584, s2.loss_bbox_cls: 0.0086, s2.loss_bbox_reg: 0.0192, loss: 0.1858, grad_norm: 4.9130\n",
            "2020-09-08 06:44:03,537 - mmdet - INFO - Epoch [13][3648/5332]\tlr: 1.000e-05, eta: 23:27:53, time: 2.156, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0267, s0.acc: 98.9563, s0.loss_bbox_cls: 0.0274, s0.loss_bbox_reg: 0.0516, s1.loss_cls: 0.0191, s1.acc: 98.5474, s1.loss_bbox_cls: 0.0201, s1.loss_bbox_reg: 0.0379, s2.loss_cls: 0.0125, s2.acc: 98.1476, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0211, loss: 0.2358, grad_norm: 5.5712\n",
            "2020-09-08 06:46:20,963 - mmdet - INFO - Epoch [13][3712/5332]\tlr: 1.000e-05, eta: 23:25:22, time: 2.147, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0223, s0.acc: 99.1852, s0.loss_bbox_cls: 0.0204, s0.loss_bbox_reg: 0.0471, s1.loss_cls: 0.0144, s1.acc: 98.9349, s1.loss_bbox_cls: 0.0168, s1.loss_bbox_reg: 0.0376, s2.loss_cls: 0.0085, s2.acc: 98.6816, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0229, loss: 0.2067, grad_norm: 5.2362\n",
            "2020-09-08 06:48:41,730 - mmdet - INFO - Epoch [13][3776/5332]\tlr: 1.000e-05, eta: 23:23:26, time: 2.199, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0217, s0.acc: 99.1577, s0.loss_bbox_cls: 0.0177, s0.loss_bbox_reg: 0.0396, s1.loss_cls: 0.0142, s1.acc: 98.9746, s1.loss_bbox_cls: 0.0138, s1.loss_bbox_reg: 0.0298, s2.loss_cls: 0.0101, s2.acc: 98.2483, s2.loss_bbox_cls: 0.0085, s2.loss_bbox_reg: 0.0188, loss: 0.1795, grad_norm: 4.7852\n",
            "2020-09-08 06:51:00,044 - mmdet - INFO - Epoch [13][3840/5332]\tlr: 1.000e-05, eta: 23:21:04, time: 2.161, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0249, s0.acc: 99.1028, s0.loss_bbox_cls: 0.0193, s0.loss_bbox_reg: 0.0416, s1.loss_cls: 0.0168, s1.acc: 98.7457, s1.loss_bbox_cls: 0.0145, s1.loss_bbox_reg: 0.0293, s2.loss_cls: 0.0090, s2.acc: 98.6389, s2.loss_bbox_cls: 0.0083, s2.loss_bbox_reg: 0.0176, loss: 0.1920, grad_norm: 5.2751\n",
            "2020-09-08 06:53:20,443 - mmdet - INFO - Epoch [13][3904/5332]\tlr: 1.000e-05, eta: 23:19:04, time: 2.194, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0226, s0.acc: 99.1150, s0.loss_bbox_cls: 0.0198, s0.loss_bbox_reg: 0.0421, s1.loss_cls: 0.0142, s1.acc: 98.7640, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0328, s2.loss_cls: 0.0105, s2.acc: 98.3459, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0197, loss: 0.1964, grad_norm: 5.5174\n",
            "2020-09-08 06:55:40,253 - mmdet - INFO - Epoch [13][3968/5332]\tlr: 1.000e-05, eta: 23:16:56, time: 2.185, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0302, s0.acc: 98.8525, s0.loss_bbox_cls: 0.0251, s0.loss_bbox_reg: 0.0480, s1.loss_cls: 0.0199, s1.acc: 98.5382, s1.loss_bbox_cls: 0.0218, s1.loss_bbox_reg: 0.0386, s2.loss_cls: 0.0129, s2.acc: 98.1079, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0207, loss: 0.2388, grad_norm: 5.5592\n",
            "2020-09-08 06:57:57,489 - mmdet - INFO - Epoch [13][4032/5332]\tlr: 1.000e-05, eta: 23:14:24, time: 2.144, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0307, s0.acc: 98.7732, s0.loss_bbox_cls: 0.0262, s0.loss_bbox_reg: 0.0526, s1.loss_cls: 0.0221, s1.acc: 98.1659, s1.loss_bbox_cls: 0.0214, s1.loss_bbox_reg: 0.0401, s2.loss_cls: 0.0137, s2.acc: 97.6624, s2.loss_bbox_cls: 0.0127, s2.loss_bbox_reg: 0.0239, loss: 0.2560, grad_norm: 6.0115\n",
            "2020-09-08 07:00:17,081 - mmdet - INFO - Epoch [13][4096/5332]\tlr: 1.000e-05, eta: 23:12:14, time: 2.181, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0246, s0.acc: 98.9807, s0.loss_bbox_cls: 0.0228, s0.loss_bbox_reg: 0.0474, s1.loss_cls: 0.0187, s1.acc: 98.3307, s1.loss_bbox_cls: 0.0187, s1.loss_bbox_reg: 0.0374, s2.loss_cls: 0.0115, s2.acc: 98.0133, s2.loss_bbox_cls: 0.0120, s2.loss_bbox_reg: 0.0244, loss: 0.2238, grad_norm: 5.7124\n",
            "2020-09-08 07:02:36,433 - mmdet - INFO - Epoch [13][4160/5332]\tlr: 1.000e-05, eta: 23:10:02, time: 2.177, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0234, s0.acc: 99.0326, s0.loss_bbox_cls: 0.0221, s0.loss_bbox_reg: 0.0425, s1.loss_cls: 0.0175, s1.acc: 98.6237, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0322, s2.loss_cls: 0.0129, s2.acc: 97.7448, s2.loss_bbox_cls: 0.0079, s2.loss_bbox_reg: 0.0173, loss: 0.1995, grad_norm: 4.6094\n",
            "2020-09-08 07:04:55,628 - mmdet - INFO - Epoch [13][4224/5332]\tlr: 1.000e-05, eta: 23:07:49, time: 2.175, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0253, s0.acc: 98.9685, s0.loss_bbox_cls: 0.0244, s0.loss_bbox_reg: 0.0482, s1.loss_cls: 0.0186, s1.acc: 98.4589, s1.loss_bbox_cls: 0.0213, s1.loss_bbox_reg: 0.0401, s2.loss_cls: 0.0115, s2.acc: 97.9492, s2.loss_bbox_cls: 0.0123, s2.loss_bbox_reg: 0.0230, loss: 0.2341, grad_norm: 5.6450\n",
            "2020-09-08 07:07:14,003 - mmdet - INFO - Epoch [13][4288/5332]\tlr: 1.000e-05, eta: 23:05:27, time: 2.162, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0253, s0.acc: 98.9624, s0.loss_bbox_cls: 0.0204, s0.loss_bbox_reg: 0.0461, s1.loss_cls: 0.0183, s1.acc: 98.5138, s1.loss_bbox_cls: 0.0198, s1.loss_bbox_reg: 0.0389, s2.loss_cls: 0.0111, s2.acc: 98.3063, s2.loss_bbox_cls: 0.0122, s2.loss_bbox_reg: 0.0235, loss: 0.2219, grad_norm: 5.9896\n",
            "2020-09-08 07:09:34,301 - mmdet - INFO - Epoch [13][4352/5332]\tlr: 1.000e-05, eta: 23:03:23, time: 2.192, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0265, s0.acc: 98.9349, s0.loss_bbox_cls: 0.0220, s0.loss_bbox_reg: 0.0426, s1.loss_cls: 0.0180, s1.acc: 98.4039, s1.loss_bbox_cls: 0.0187, s1.loss_bbox_reg: 0.0335, s2.loss_cls: 0.0115, s2.acc: 97.8760, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0201, loss: 0.2106, grad_norm: 5.3730\n",
            "2020-09-08 07:11:55,355 - mmdet - INFO - Epoch [13][4416/5332]\tlr: 1.000e-05, eta: 23:01:25, time: 2.204, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0192, s0.acc: 99.2981, s0.loss_bbox_cls: 0.0216, s0.loss_bbox_reg: 0.0468, s1.loss_cls: 0.0144, s1.acc: 99.0356, s1.loss_bbox_cls: 0.0180, s1.loss_bbox_reg: 0.0378, s2.loss_cls: 0.0096, s2.acc: 98.6145, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0223, loss: 0.2082, grad_norm: 5.3583\n",
            "2020-09-08 07:14:15,358 - mmdet - INFO - Epoch [13][4480/5332]\tlr: 1.000e-05, eta: 22:59:17, time: 2.188, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0209, s0.acc: 99.1272, s0.loss_bbox_cls: 0.0195, s0.loss_bbox_reg: 0.0390, s1.loss_cls: 0.0166, s1.acc: 98.5687, s1.loss_bbox_cls: 0.0154, s1.loss_bbox_reg: 0.0311, s2.loss_cls: 0.0105, s2.acc: 98.2422, s2.loss_bbox_cls: 0.0080, s2.loss_bbox_reg: 0.0180, loss: 0.1885, grad_norm: 4.9404\n",
            "2020-09-08 07:16:33,013 - mmdet - INFO - Epoch [13][4544/5332]\tlr: 1.000e-05, eta: 22:56:49, time: 2.151, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0239, s0.acc: 99.0051, s0.loss_bbox_cls: 0.0232, s0.loss_bbox_reg: 0.0485, s1.loss_cls: 0.0178, s1.acc: 98.5107, s1.loss_bbox_cls: 0.0207, s1.loss_bbox_reg: 0.0381, s2.loss_cls: 0.0113, s2.acc: 98.1079, s2.loss_bbox_cls: 0.0126, s2.loss_bbox_reg: 0.0233, loss: 0.2254, grad_norm: 5.6840\n",
            "2020-09-08 07:18:51,754 - mmdet - INFO - Epoch [13][4608/5332]\tlr: 1.000e-05, eta: 22:54:31, time: 2.168, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0249, s0.acc: 98.9929, s0.loss_bbox_cls: 0.0198, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0178, s1.acc: 98.6145, s1.loss_bbox_cls: 0.0168, s1.loss_bbox_reg: 0.0348, s2.loss_cls: 0.0112, s2.acc: 98.1964, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0221, loss: 0.2109, grad_norm: 5.6179\n",
            "2020-09-08 07:21:10,069 - mmdet - INFO - Epoch [13][4672/5332]\tlr: 1.000e-05, eta: 22:52:09, time: 2.161, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0275, s0.acc: 98.9929, s0.loss_bbox_cls: 0.0237, s0.loss_bbox_reg: 0.0451, s1.loss_cls: 0.0205, s1.acc: 98.2697, s1.loss_bbox_cls: 0.0189, s1.loss_bbox_reg: 0.0346, s2.loss_cls: 0.0136, s2.acc: 97.4640, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0192, loss: 0.2213, grad_norm: 5.6343\n",
            "2020-09-08 07:23:30,933 - mmdet - INFO - Epoch [13][4736/5332]\tlr: 1.000e-05, eta: 22:50:07, time: 2.201, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0238, s0.acc: 99.0753, s0.loss_bbox_cls: 0.0225, s0.loss_bbox_reg: 0.0461, s1.loss_cls: 0.0185, s1.acc: 98.5992, s1.loss_bbox_cls: 0.0160, s1.loss_bbox_reg: 0.0347, s2.loss_cls: 0.0117, s2.acc: 98.3307, s2.loss_bbox_cls: 0.0087, s2.loss_bbox_reg: 0.0198, loss: 0.2114, grad_norm: 5.3420\n",
            "2020-09-08 07:25:50,790 - mmdet - INFO - Epoch [13][4800/5332]\tlr: 1.000e-05, eta: 22:47:57, time: 2.185, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0232, s0.acc: 99.1211, s0.loss_bbox_cls: 0.0190, s0.loss_bbox_reg: 0.0426, s1.loss_cls: 0.0165, s1.acc: 98.7335, s1.loss_bbox_cls: 0.0166, s1.loss_bbox_reg: 0.0334, s2.loss_cls: 0.0116, s2.acc: 98.1415, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0205, loss: 0.2020, grad_norm: 5.5791\n",
            "2020-09-08 07:28:10,458 - mmdet - INFO - Epoch [13][4864/5332]\tlr: 1.000e-05, eta: 22:45:45, time: 2.182, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0264, s0.acc: 98.9563, s0.loss_bbox_cls: 0.0223, s0.loss_bbox_reg: 0.0414, s1.loss_cls: 0.0179, s1.acc: 98.4680, s1.loss_bbox_cls: 0.0180, s1.loss_bbox_reg: 0.0323, s2.loss_cls: 0.0131, s2.acc: 97.9767, s2.loss_bbox_cls: 0.0082, s2.loss_bbox_reg: 0.0171, loss: 0.2039, grad_norm: 5.3216\n",
            "2020-09-08 07:30:28,516 - mmdet - INFO - Epoch [13][4928/5332]\tlr: 1.000e-05, eta: 22:43:21, time: 2.157, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0239, s0.acc: 99.0967, s0.loss_bbox_cls: 0.0229, s0.loss_bbox_reg: 0.0458, s1.loss_cls: 0.0173, s1.acc: 98.6969, s1.loss_bbox_cls: 0.0174, s1.loss_bbox_reg: 0.0356, s2.loss_cls: 0.0110, s2.acc: 98.3826, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0224, loss: 0.2155, grad_norm: 5.6879\n",
            "2020-09-08 07:32:47,914 - mmdet - INFO - Epoch [13][4992/5332]\tlr: 1.000e-05, eta: 22:41:07, time: 2.178, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0240, s0.acc: 99.0692, s0.loss_bbox_cls: 0.0206, s0.loss_bbox_reg: 0.0434, s1.loss_cls: 0.0158, s1.acc: 98.8129, s1.loss_bbox_cls: 0.0155, s1.loss_bbox_reg: 0.0323, s2.loss_cls: 0.0101, s2.acc: 98.3124, s2.loss_bbox_cls: 0.0092, s2.loss_bbox_reg: 0.0206, loss: 0.2028, grad_norm: 5.0665\n",
            "2020-09-08 07:35:06,894 - mmdet - INFO - Epoch [13][5056/5332]\tlr: 1.000e-05, eta: 22:38:50, time: 2.172, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0247, s0.acc: 99.0479, s0.loss_bbox_cls: 0.0225, s0.loss_bbox_reg: 0.0479, s1.loss_cls: 0.0169, s1.acc: 98.6450, s1.loss_bbox_cls: 0.0182, s1.loss_bbox_reg: 0.0368, s2.loss_cls: 0.0110, s2.acc: 98.3215, s2.loss_bbox_cls: 0.0112, s2.loss_bbox_reg: 0.0226, loss: 0.2186, grad_norm: 5.7712\n",
            "2020-09-08 07:37:22,995 - mmdet - INFO - Epoch [13][5120/5332]\tlr: 1.000e-05, eta: 22:36:11, time: 2.127, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0200, s0.acc: 99.2493, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0431, s1.loss_cls: 0.0143, s1.acc: 98.8068, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0338, s2.loss_cls: 0.0095, s2.acc: 98.5016, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0205, loss: 0.1987, grad_norm: 4.9668\n",
            "2020-09-08 07:39:41,077 - mmdet - INFO - Epoch [13][5184/5332]\tlr: 1.000e-05, eta: 22:33:48, time: 2.158, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0230, s0.acc: 99.0723, s0.loss_bbox_cls: 0.0231, s0.loss_bbox_reg: 0.0475, s1.loss_cls: 0.0164, s1.acc: 98.6237, s1.loss_bbox_cls: 0.0206, s1.loss_bbox_reg: 0.0403, s2.loss_cls: 0.0123, s2.acc: 98.0621, s2.loss_bbox_cls: 0.0116, s2.loss_bbox_reg: 0.0232, loss: 0.2251, grad_norm: 5.6168\n",
            "2020-09-08 07:41:59,447 - mmdet - INFO - Epoch [13][5248/5332]\tlr: 1.000e-05, eta: 22:31:27, time: 2.162, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0291, s0.acc: 98.8831, s0.loss_bbox_cls: 0.0220, s0.loss_bbox_reg: 0.0459, s1.loss_cls: 0.0208, s1.acc: 98.4558, s1.loss_bbox_cls: 0.0190, s1.loss_bbox_reg: 0.0361, s2.loss_cls: 0.0131, s2.acc: 97.8424, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0208, loss: 0.2241, grad_norm: 6.0382\n",
            "2020-09-08 07:44:17,401 - mmdet - INFO - Epoch [13][5312/5332]\tlr: 1.000e-05, eta: 22:29:02, time: 2.156, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0219, s0.acc: 99.1669, s0.loss_bbox_cls: 0.0223, s0.loss_bbox_reg: 0.0468, s1.loss_cls: 0.0144, s1.acc: 98.8525, s1.loss_bbox_cls: 0.0203, s1.loss_bbox_reg: 0.0378, s2.loss_cls: 0.0110, s2.acc: 98.1506, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0194, loss: 0.2112, grad_norm: 5.4743\n",
            "2020-09-08 07:45:00,690 - mmdet - INFO - Saving checkpoint at 13 epochs\n",
            "[>>] 667/667, 0.5 task/s, elapsed: 1283s, ETA:     0s2020-09-08 08:06:31,317 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 264  | 0.829  | 0.651 |\n",
            "| 3     | 22  | 59   | 0.818  | 0.677 |\n",
            "| 4     | 529 | 1232 | 0.924  | 0.832 |\n",
            "| 5     | 78  | 192  | 0.885  | 0.793 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.738 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-08 08:06:31,321 - mmdet - INFO - Epoch(val) [13][5332]\tmAP: 0.7380\n",
            "2020-09-08 08:08:51,936 - mmdet - INFO - Epoch [14][64/5332]\tlr: 1.000e-05, eta: 22:21:14, time: 2.197, data_time: 0.037, memory: 8090, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0192, s0.acc: 99.2218, s0.loss_bbox_cls: 0.0191, s0.loss_bbox_reg: 0.0427, s1.loss_cls: 0.0138, s1.acc: 98.8617, s1.loss_bbox_cls: 0.0168, s1.loss_bbox_reg: 0.0337, s2.loss_cls: 0.0100, s2.acc: 98.2910, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0204, loss: 0.1934, grad_norm: 5.0874\n",
            "2020-09-08 08:11:08,357 - mmdet - INFO - Epoch [14][128/5332]\tlr: 1.000e-05, eta: 22:18:43, time: 2.132, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0211, s0.acc: 99.1516, s0.loss_bbox_cls: 0.0214, s0.loss_bbox_reg: 0.0445, s1.loss_cls: 0.0140, s1.acc: 98.8708, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0335, s2.loss_cls: 0.0090, s2.acc: 98.5016, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0200, loss: 0.1977, grad_norm: 5.1364\n",
            "2020-09-08 08:13:26,992 - mmdet - INFO - Epoch [14][192/5332]\tlr: 1.000e-05, eta: 22:16:28, time: 2.166, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0299, s0.acc: 98.8129, s0.loss_bbox_cls: 0.0248, s0.loss_bbox_reg: 0.0528, s1.loss_cls: 0.0209, s1.acc: 98.4344, s1.loss_bbox_cls: 0.0220, s1.loss_bbox_reg: 0.0413, s2.loss_cls: 0.0143, s2.acc: 97.8577, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0228, loss: 0.2461, grad_norm: 6.5042\n",
            "2020-09-08 08:15:42,344 - mmdet - INFO - Epoch [14][256/5332]\tlr: 1.000e-05, eta: 22:13:51, time: 2.115, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0226, s0.acc: 99.1180, s0.loss_bbox_cls: 0.0202, s0.loss_bbox_reg: 0.0460, s1.loss_cls: 0.0153, s1.acc: 98.7518, s1.loss_bbox_cls: 0.0163, s1.loss_bbox_reg: 0.0352, s2.loss_cls: 0.0102, s2.acc: 98.0835, s2.loss_bbox_cls: 0.0117, s2.loss_bbox_reg: 0.0228, loss: 0.2065, grad_norm: 5.4064\n",
            "2020-09-08 08:18:00,390 - mmdet - INFO - Epoch [14][320/5332]\tlr: 1.000e-05, eta: 22:11:32, time: 2.157, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0252, s0.acc: 98.9624, s0.loss_bbox_cls: 0.0243, s0.loss_bbox_reg: 0.0499, s1.loss_cls: 0.0174, s1.acc: 98.7122, s1.loss_bbox_cls: 0.0198, s1.loss_bbox_reg: 0.0394, s2.loss_cls: 0.0113, s2.acc: 98.4161, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0230, loss: 0.2287, grad_norm: 5.6105\n",
            "2020-09-08 08:20:16,447 - mmdet - INFO - Epoch [14][384/5332]\tlr: 1.000e-05, eta: 22:09:00, time: 2.126, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0213, s0.acc: 99.1333, s0.loss_bbox_cls: 0.0181, s0.loss_bbox_reg: 0.0412, s1.loss_cls: 0.0156, s1.acc: 98.6938, s1.loss_bbox_cls: 0.0152, s1.loss_bbox_reg: 0.0312, s2.loss_cls: 0.0099, s2.acc: 98.2056, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0196, loss: 0.1897, grad_norm: 5.1078\n",
            "2020-09-08 08:22:33,822 - mmdet - INFO - Epoch [14][448/5332]\tlr: 1.000e-05, eta: 22:06:37, time: 2.146, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0270, s0.acc: 98.9777, s0.loss_bbox_cls: 0.0231, s0.loss_bbox_reg: 0.0438, s1.loss_cls: 0.0215, s1.acc: 98.3337, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0317, s2.loss_cls: 0.0140, s2.acc: 97.6471, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0188, loss: 0.2138, grad_norm: 5.4053\n",
            "2020-09-08 08:24:50,097 - mmdet - INFO - Epoch [14][512/5332]\tlr: 1.000e-05, eta: 22:04:07, time: 2.129, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0261, s0.acc: 99.0356, s0.loss_bbox_cls: 0.0188, s0.loss_bbox_reg: 0.0388, s1.loss_cls: 0.0185, s1.acc: 98.6389, s1.loss_bbox_cls: 0.0143, s1.loss_bbox_reg: 0.0286, s2.loss_cls: 0.0121, s2.acc: 98.0835, s2.loss_bbox_cls: 0.0073, s2.loss_bbox_reg: 0.0167, loss: 0.1890, grad_norm: 5.0409\n",
            "2020-09-08 08:27:06,387 - mmdet - INFO - Epoch [14][576/5332]\tlr: 1.000e-05, eta: 22:01:37, time: 2.130, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0236, s0.acc: 99.0356, s0.loss_bbox_cls: 0.0204, s0.loss_bbox_reg: 0.0440, s1.loss_cls: 0.0163, s1.acc: 98.7854, s1.loss_bbox_cls: 0.0191, s1.loss_bbox_reg: 0.0350, s2.loss_cls: 0.0105, s2.acc: 98.4344, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0192, loss: 0.2022, grad_norm: 5.7736\n",
            "2020-09-08 08:29:24,348 - mmdet - INFO - Epoch [14][640/5332]\tlr: 1.000e-05, eta: 21:59:18, time: 2.156, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0231, s0.acc: 99.0326, s0.loss_bbox_cls: 0.0213, s0.loss_bbox_reg: 0.0430, s1.loss_cls: 0.0172, s1.acc: 98.5809, s1.loss_bbox_cls: 0.0172, s1.loss_bbox_reg: 0.0329, s2.loss_cls: 0.0111, s2.acc: 98.0133, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0196, loss: 0.2050, grad_norm: 5.5429\n",
            "2020-09-08 08:31:42,392 - mmdet - INFO - Epoch [14][704/5332]\tlr: 1.000e-05, eta: 21:57:00, time: 2.157, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0238, s0.acc: 99.0417, s0.loss_bbox_cls: 0.0227, s0.loss_bbox_reg: 0.0460, s1.loss_cls: 0.0210, s1.acc: 98.2178, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0122, s2.acc: 97.7814, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0189, loss: 0.2146, grad_norm: 5.8522\n",
            "2020-09-08 08:34:02,003 - mmdet - INFO - Epoch [14][768/5332]\tlr: 1.000e-05, eta: 21:54:51, time: 2.181, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0264, s0.acc: 98.9807, s0.loss_bbox_cls: 0.0229, s0.loss_bbox_reg: 0.0442, s1.loss_cls: 0.0182, s1.acc: 98.6786, s1.loss_bbox_cls: 0.0192, s1.loss_bbox_reg: 0.0335, s2.loss_cls: 0.0129, s2.acc: 97.8577, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0213, loss: 0.2189, grad_norm: 5.3890\n",
            "2020-09-08 08:36:19,955 - mmdet - INFO - Epoch [14][832/5332]\tlr: 1.000e-05, eta: 21:52:32, time: 2.155, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0238, s0.acc: 99.0601, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0443, s1.loss_cls: 0.0175, s1.acc: 98.5321, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0338, s2.loss_cls: 0.0110, s2.acc: 98.0408, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0218, loss: 0.2094, grad_norm: 5.8344\n",
            "2020-09-08 08:38:36,880 - mmdet - INFO - Epoch [14][896/5332]\tlr: 1.000e-05, eta: 21:50:07, time: 2.139, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0263, s0.acc: 98.9288, s0.loss_bbox_cls: 0.0250, s0.loss_bbox_reg: 0.0506, s1.loss_cls: 0.0190, s1.acc: 98.4100, s1.loss_bbox_cls: 0.0200, s1.loss_bbox_reg: 0.0383, s2.loss_cls: 0.0123, s2.acc: 97.9187, s2.loss_bbox_cls: 0.0121, s2.loss_bbox_reg: 0.0235, loss: 0.2352, grad_norm: 5.4991\n",
            "2020-09-08 08:40:54,863 - mmdet - INFO - Epoch [14][960/5332]\tlr: 1.000e-05, eta: 21:47:48, time: 2.156, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0218, s0.acc: 99.1119, s0.loss_bbox_cls: 0.0197, s0.loss_bbox_reg: 0.0444, s1.loss_cls: 0.0177, s1.acc: 98.4741, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0361, s2.loss_cls: 0.0111, s2.acc: 98.1018, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0203, loss: 0.2051, grad_norm: 5.6023\n",
            "2020-09-08 08:43:13,266 - mmdet - INFO - Epoch [14][1024/5332]\tlr: 1.000e-05, eta: 21:45:31, time: 2.163, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0240, s0.acc: 99.0173, s0.loss_bbox_cls: 0.0216, s0.loss_bbox_reg: 0.0486, s1.loss_cls: 0.0159, s1.acc: 98.7305, s1.loss_bbox_cls: 0.0182, s1.loss_bbox_reg: 0.0375, s2.loss_cls: 0.0101, s2.acc: 98.3521, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0241, loss: 0.2187, grad_norm: 5.4538\n",
            "2020-09-08 08:45:32,877 - mmdet - INFO - Epoch [14][1088/5332]\tlr: 1.000e-05, eta: 21:43:22, time: 2.181, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0217, s0.acc: 99.1760, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0453, s1.loss_cls: 0.0147, s1.acc: 98.8556, s1.loss_bbox_cls: 0.0180, s1.loss_bbox_reg: 0.0348, s2.loss_cls: 0.0095, s2.acc: 98.4100, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0217, loss: 0.2047, grad_norm: 5.2782\n",
            "2020-09-08 08:47:51,161 - mmdet - INFO - Epoch [14][1152/5332]\tlr: 1.000e-05, eta: 21:41:05, time: 2.161, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0232, s0.acc: 99.0631, s0.loss_bbox_cls: 0.0211, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0166, s1.acc: 98.6633, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0363, s2.loss_cls: 0.0108, s2.acc: 98.1293, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0222, loss: 0.2091, grad_norm: 5.4013\n",
            "2020-09-08 08:50:08,747 - mmdet - INFO - Epoch [14][1216/5332]\tlr: 1.000e-05, eta: 21:38:44, time: 2.150, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0273, s0.acc: 98.9624, s0.loss_bbox_cls: 0.0241, s0.loss_bbox_reg: 0.0500, s1.loss_cls: 0.0180, s1.acc: 98.6115, s1.loss_bbox_cls: 0.0183, s1.loss_bbox_reg: 0.0362, s2.loss_cls: 0.0110, s2.acc: 98.1964, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0210, loss: 0.2250, grad_norm: 5.9710\n",
            "2020-09-08 08:52:26,464 - mmdet - INFO - Epoch [14][1280/5332]\tlr: 1.000e-05, eta: 21:36:23, time: 2.152, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0236, s0.acc: 99.1058, s0.loss_bbox_cls: 0.0231, s0.loss_bbox_reg: 0.0450, s1.loss_cls: 0.0163, s1.acc: 98.7091, s1.loss_bbox_cls: 0.0191, s1.loss_bbox_reg: 0.0342, s2.loss_cls: 0.0096, s2.acc: 98.3276, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0197, loss: 0.2083, grad_norm: 5.4113\n",
            "2020-09-08 08:54:44,771 - mmdet - INFO - Epoch [14][1344/5332]\tlr: 1.000e-05, eta: 21:34:06, time: 2.161, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0340, s0.acc: 98.8007, s0.loss_bbox_cls: 0.0265, s0.loss_bbox_reg: 0.0525, s1.loss_cls: 0.0240, s1.acc: 98.1995, s1.loss_bbox_cls: 0.0202, s1.loss_bbox_reg: 0.0393, s2.loss_cls: 0.0151, s2.acc: 97.5891, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0210, loss: 0.2518, grad_norm: 5.8376\n",
            "2020-09-08 08:57:02,914 - mmdet - INFO - Epoch [14][1408/5332]\tlr: 1.000e-05, eta: 21:31:48, time: 2.158, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0196, s0.acc: 99.1913, s0.loss_bbox_cls: 0.0201, s0.loss_bbox_reg: 0.0445, s1.loss_cls: 0.0140, s1.acc: 98.7793, s1.loss_bbox_cls: 0.0183, s1.loss_bbox_reg: 0.0357, s2.loss_cls: 0.0098, s2.acc: 98.2971, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0206, loss: 0.2000, grad_norm: 5.6891\n",
            "2020-09-08 08:59:18,607 - mmdet - INFO - Epoch [14][1472/5332]\tlr: 1.000e-05, eta: 21:29:17, time: 2.120, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0220, s0.acc: 99.1547, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0435, s1.loss_cls: 0.0172, s1.acc: 98.5382, s1.loss_bbox_cls: 0.0158, s1.loss_bbox_reg: 0.0316, s2.loss_cls: 0.0105, s2.acc: 98.0347, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0184, loss: 0.1968, grad_norm: 5.0276\n",
            "2020-09-08 09:01:35,406 - mmdet - INFO - Epoch [14][1536/5332]\tlr: 1.000e-05, eta: 21:26:53, time: 2.137, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0213, s0.acc: 99.1119, s0.loss_bbox_cls: 0.0210, s0.loss_bbox_reg: 0.0462, s1.loss_cls: 0.0156, s1.acc: 98.6847, s1.loss_bbox_cls: 0.0197, s1.loss_bbox_reg: 0.0392, s2.loss_cls: 0.0098, s2.acc: 98.1628, s2.loss_bbox_cls: 0.0112, s2.loss_bbox_reg: 0.0240, loss: 0.2141, grad_norm: 5.6593\n",
            "2020-09-08 09:03:53,476 - mmdet - INFO - Epoch [14][1600/5332]\tlr: 1.000e-05, eta: 21:24:34, time: 2.157, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0203, s0.acc: 99.2310, s0.loss_bbox_cls: 0.0226, s0.loss_bbox_reg: 0.0481, s1.loss_cls: 0.0145, s1.acc: 98.9746, s1.loss_bbox_cls: 0.0206, s1.loss_bbox_reg: 0.0393, s2.loss_cls: 0.0108, s2.acc: 98.3398, s2.loss_bbox_cls: 0.0115, s2.loss_bbox_reg: 0.0223, loss: 0.2164, grad_norm: 6.1404\n",
            "2020-09-08 09:06:11,981 - mmdet - INFO - Epoch [14][1664/5332]\tlr: 1.000e-05, eta: 21:22:18, time: 2.164, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0249, s0.acc: 98.9899, s0.loss_bbox_cls: 0.0261, s0.loss_bbox_reg: 0.0513, s1.loss_cls: 0.0185, s1.acc: 98.4314, s1.loss_bbox_cls: 0.0217, s1.loss_bbox_reg: 0.0389, s2.loss_cls: 0.0113, s2.acc: 97.8271, s2.loss_bbox_cls: 0.0114, s2.loss_bbox_reg: 0.0225, loss: 0.2343, grad_norm: 5.7587\n",
            "2020-09-08 09:08:29,727 - mmdet - INFO - Epoch [14][1728/5332]\tlr: 1.000e-05, eta: 21:19:59, time: 2.152, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0200, s0.acc: 99.1699, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0427, s1.loss_cls: 0.0152, s1.acc: 98.9349, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0341, s2.loss_cls: 0.0103, s2.acc: 98.3643, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0204, loss: 0.1996, grad_norm: 5.5354\n",
            "2020-09-08 09:10:46,523 - mmdet - INFO - Epoch [14][1792/5332]\tlr: 1.000e-05, eta: 21:17:34, time: 2.137, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0227, s0.acc: 99.0997, s0.loss_bbox_cls: 0.0206, s0.loss_bbox_reg: 0.0445, s1.loss_cls: 0.0154, s1.acc: 98.6755, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0356, s2.loss_cls: 0.0112, s2.acc: 98.1171, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0193, loss: 0.2027, grad_norm: 5.5569\n",
            "2020-09-08 09:13:03,712 - mmdet - INFO - Epoch [14][1856/5332]\tlr: 1.000e-05, eta: 21:15:12, time: 2.144, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0026, s0.loss_cls: 0.0212, s0.acc: 99.1516, s0.loss_bbox_cls: 0.0189, s0.loss_bbox_reg: 0.0406, s1.loss_cls: 0.0155, s1.acc: 98.6725, s1.loss_bbox_cls: 0.0156, s1.loss_bbox_reg: 0.0320, s2.loss_cls: 0.0102, s2.acc: 98.0682, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0193, loss: 0.1898, grad_norm: 5.2411\n",
            "2020-09-08 09:15:21,421 - mmdet - INFO - Epoch [14][1920/5332]\tlr: 1.000e-05, eta: 21:12:52, time: 2.152, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0296, s0.acc: 98.9136, s0.loss_bbox_cls: 0.0237, s0.loss_bbox_reg: 0.0526, s1.loss_cls: 0.0201, s1.acc: 98.4589, s1.loss_bbox_cls: 0.0194, s1.loss_bbox_reg: 0.0418, s2.loss_cls: 0.0114, s2.acc: 98.1781, s2.loss_bbox_cls: 0.0117, s2.loss_bbox_reg: 0.0259, loss: 0.2445, grad_norm: 6.2496\n",
            "2020-09-08 09:17:40,354 - mmdet - INFO - Epoch [14][1984/5332]\tlr: 1.000e-05, eta: 21:10:38, time: 2.171, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0066, s0.loss_cls: 0.0287, s0.acc: 98.8983, s0.loss_bbox_cls: 0.0240, s0.loss_bbox_reg: 0.0490, s1.loss_cls: 0.0220, s1.acc: 98.2605, s1.loss_bbox_cls: 0.0192, s1.loss_bbox_reg: 0.0364, s2.loss_cls: 0.0141, s2.acc: 97.8912, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0207, loss: 0.2341, grad_norm: 6.1708\n",
            "2020-09-08 09:19:57,477 - mmdet - INFO - Epoch [14][2048/5332]\tlr: 1.000e-05, eta: 21:08:16, time: 2.143, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0261, s0.acc: 98.9197, s0.loss_bbox_cls: 0.0235, s0.loss_bbox_reg: 0.0479, s1.loss_cls: 0.0189, s1.acc: 98.4467, s1.loss_bbox_cls: 0.0199, s1.loss_bbox_reg: 0.0386, s2.loss_cls: 0.0125, s2.acc: 97.5159, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0213, loss: 0.2284, grad_norm: 5.6521\n",
            "2020-09-08 09:22:16,815 - mmdet - INFO - Epoch [14][2112/5332]\tlr: 1.000e-05, eta: 21:06:04, time: 2.177, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0245, s0.acc: 98.9807, s0.loss_bbox_cls: 0.0213, s0.loss_bbox_reg: 0.0418, s1.loss_cls: 0.0185, s1.acc: 98.3704, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0328, s2.loss_cls: 0.0105, s2.acc: 98.1110, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0197, loss: 0.2014, grad_norm: 5.5171\n",
            "2020-09-08 09:24:35,192 - mmdet - INFO - Epoch [14][2176/5332]\tlr: 1.000e-05, eta: 21:03:47, time: 2.162, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0268, s0.acc: 99.0143, s0.loss_bbox_cls: 0.0227, s0.loss_bbox_reg: 0.0499, s1.loss_cls: 0.0165, s1.acc: 98.8373, s1.loss_bbox_cls: 0.0182, s1.loss_bbox_reg: 0.0363, s2.loss_cls: 0.0118, s2.acc: 98.0591, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0219, loss: 0.2242, grad_norm: 5.7038\n",
            "2020-09-08 09:26:55,075 - mmdet - INFO - Epoch [14][2240/5332]\tlr: 1.000e-05, eta: 21:01:37, time: 2.186, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0215, s0.acc: 99.0967, s0.loss_bbox_cls: 0.0198, s0.loss_bbox_reg: 0.0427, s1.loss_cls: 0.0142, s1.acc: 98.8129, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0342, s2.loss_cls: 0.0100, s2.acc: 98.4131, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0215, loss: 0.1994, grad_norm: 5.4340\n",
            "2020-09-08 09:29:13,167 - mmdet - INFO - Epoch [14][2304/5332]\tlr: 1.000e-05, eta: 20:59:19, time: 2.158, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0210, s0.acc: 99.1028, s0.loss_bbox_cls: 0.0183, s0.loss_bbox_reg: 0.0430, s1.loss_cls: 0.0143, s1.acc: 98.7579, s1.loss_bbox_cls: 0.0140, s1.loss_bbox_reg: 0.0328, s2.loss_cls: 0.0083, s2.acc: 98.7671, s2.loss_bbox_cls: 0.0083, s2.loss_bbox_reg: 0.0201, loss: 0.1868, grad_norm: 5.2023\n",
            "2020-09-08 09:31:30,466 - mmdet - INFO - Epoch [14][2368/5332]\tlr: 1.000e-05, eta: 20:56:57, time: 2.145, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0287, s0.acc: 98.9624, s0.loss_bbox_cls: 0.0236, s0.loss_bbox_reg: 0.0475, s1.loss_cls: 0.0192, s1.acc: 98.6176, s1.loss_bbox_cls: 0.0175, s1.loss_bbox_reg: 0.0352, s2.loss_cls: 0.0109, s2.acc: 98.2605, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0207, loss: 0.2217, grad_norm: 5.5586\n",
            "2020-09-08 09:33:47,197 - mmdet - INFO - Epoch [14][2432/5332]\tlr: 1.000e-05, eta: 20:54:33, time: 2.136, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0072, s0.loss_cls: 0.0271, s0.acc: 98.9014, s0.loss_bbox_cls: 0.0227, s0.loss_bbox_reg: 0.0468, s1.loss_cls: 0.0182, s1.acc: 98.4772, s1.loss_bbox_cls: 0.0181, s1.loss_bbox_reg: 0.0350, s2.loss_cls: 0.0109, s2.acc: 98.2025, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0204, loss: 0.2209, grad_norm: 5.8663\n",
            "2020-09-08 09:36:05,197 - mmdet - INFO - Epoch [14][2496/5332]\tlr: 1.000e-05, eta: 20:52:15, time: 2.156, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0228, s0.acc: 99.1547, s0.loss_bbox_cls: 0.0206, s0.loss_bbox_reg: 0.0457, s1.loss_cls: 0.0174, s1.acc: 98.5657, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0360, s2.loss_cls: 0.0113, s2.acc: 98.1018, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0217, loss: 0.2102, grad_norm: 5.5351\n",
            "2020-09-08 09:38:23,222 - mmdet - INFO - Epoch [14][2560/5332]\tlr: 1.000e-05, eta: 20:49:57, time: 2.157, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0265, s0.acc: 98.9838, s0.loss_bbox_cls: 0.0193, s0.loss_bbox_reg: 0.0443, s1.loss_cls: 0.0213, s1.acc: 98.2330, s1.loss_bbox_cls: 0.0156, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0131, s2.acc: 97.8973, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0216, loss: 0.2145, grad_norm: 5.7711\n",
            "2020-09-08 09:40:39,624 - mmdet - INFO - Epoch [14][2624/5332]\tlr: 1.000e-05, eta: 20:47:31, time: 2.131, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0238, s0.acc: 99.1364, s0.loss_bbox_cls: 0.0221, s0.loss_bbox_reg: 0.0467, s1.loss_cls: 0.0176, s1.acc: 98.6237, s1.loss_bbox_cls: 0.0169, s1.loss_bbox_reg: 0.0335, s2.loss_cls: 0.0111, s2.acc: 98.3307, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0206, loss: 0.2116, grad_norm: 5.3375\n",
            "2020-09-08 09:42:56,451 - mmdet - INFO - Epoch [14][2688/5332]\tlr: 1.000e-05, eta: 20:45:08, time: 2.138, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0229, s0.acc: 99.1547, s0.loss_bbox_cls: 0.0167, s0.loss_bbox_reg: 0.0386, s1.loss_cls: 0.0163, s1.acc: 98.5596, s1.loss_bbox_cls: 0.0140, s1.loss_bbox_reg: 0.0301, s2.loss_cls: 0.0104, s2.acc: 98.3307, s2.loss_bbox_cls: 0.0086, s2.loss_bbox_reg: 0.0183, loss: 0.1854, grad_norm: 5.2177\n",
            "2020-09-08 09:45:13,101 - mmdet - INFO - Epoch [14][2752/5332]\tlr: 1.000e-05, eta: 20:42:44, time: 2.135, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0235, s0.acc: 99.0906, s0.loss_bbox_cls: 0.0205, s0.loss_bbox_reg: 0.0436, s1.loss_cls: 0.0170, s1.acc: 98.6694, s1.loss_bbox_cls: 0.0164, s1.loss_bbox_reg: 0.0333, s2.loss_cls: 0.0115, s2.acc: 98.1110, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0189, loss: 0.2012, grad_norm: 5.0889\n",
            "2020-09-08 09:47:31,851 - mmdet - INFO - Epoch [14][2816/5332]\tlr: 1.000e-05, eta: 20:40:29, time: 2.168, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0069, s0.loss_cls: 0.0245, s0.acc: 99.0356, s0.loss_bbox_cls: 0.0231, s0.loss_bbox_reg: 0.0464, s1.loss_cls: 0.0169, s1.acc: 98.6359, s1.loss_bbox_cls: 0.0172, s1.loss_bbox_reg: 0.0364, s2.loss_cls: 0.0121, s2.acc: 97.8302, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0206, loss: 0.2182, grad_norm: 5.9761\n",
            "2020-09-08 09:49:50,609 - mmdet - INFO - Epoch [14][2880/5332]\tlr: 1.000e-05, eta: 20:38:14, time: 2.168, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0104, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0224, s0.acc: 99.1241, s0.loss_bbox_cls: 0.0203, s0.loss_bbox_reg: 0.0451, s1.loss_cls: 0.0165, s1.acc: 98.7610, s1.loss_bbox_cls: 0.0188, s1.loss_bbox_reg: 0.0376, s2.loss_cls: 0.0133, s2.acc: 97.8943, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0207, loss: 0.2207, grad_norm: 5.8004\n",
            "2020-09-08 09:52:08,121 - mmdet - INFO - Epoch [14][2944/5332]\tlr: 1.000e-05, eta: 20:35:54, time: 2.149, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0286, s0.acc: 98.9502, s0.loss_bbox_cls: 0.0256, s0.loss_bbox_reg: 0.0510, s1.loss_cls: 0.0209, s1.acc: 98.3002, s1.loss_bbox_cls: 0.0195, s1.loss_bbox_reg: 0.0374, s2.loss_cls: 0.0134, s2.acc: 97.8943, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0203, loss: 0.2340, grad_norm: 5.6526\n",
            "2020-09-08 09:54:25,520 - mmdet - INFO - Epoch [14][3008/5332]\tlr: 1.000e-05, eta: 20:33:33, time: 2.147, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0239, s0.acc: 99.0448, s0.loss_bbox_cls: 0.0211, s0.loss_bbox_reg: 0.0465, s1.loss_cls: 0.0186, s1.acc: 98.4711, s1.loss_bbox_cls: 0.0190, s1.loss_bbox_reg: 0.0382, s2.loss_cls: 0.0126, s2.acc: 97.9218, s2.loss_bbox_cls: 0.0114, s2.loss_bbox_reg: 0.0229, loss: 0.2268, grad_norm: 6.2007\n",
            "2020-09-08 09:56:43,414 - mmdet - INFO - Epoch [14][3072/5332]\tlr: 1.000e-05, eta: 20:31:14, time: 2.155, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0250, s0.acc: 99.0143, s0.loss_bbox_cls: 0.0197, s0.loss_bbox_reg: 0.0407, s1.loss_cls: 0.0195, s1.acc: 98.5046, s1.loss_bbox_cls: 0.0172, s1.loss_bbox_reg: 0.0325, s2.loss_cls: 0.0115, s2.acc: 98.2544, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0201, loss: 0.2060, grad_norm: 4.9277\n",
            "2020-09-08 09:59:01,603 - mmdet - INFO - Epoch [14][3136/5332]\tlr: 1.000e-05, eta: 20:28:57, time: 2.159, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0314, s0.acc: 98.8251, s0.loss_bbox_cls: 0.0256, s0.loss_bbox_reg: 0.0506, s1.loss_cls: 0.0236, s1.acc: 98.2239, s1.loss_bbox_cls: 0.0208, s1.loss_bbox_reg: 0.0408, s2.loss_cls: 0.0157, s2.acc: 97.4091, s2.loss_bbox_cls: 0.0119, s2.loss_bbox_reg: 0.0237, loss: 0.2531, grad_norm: 6.2482\n",
            "2020-09-08 10:01:20,054 - mmdet - INFO - Epoch [14][3200/5332]\tlr: 1.000e-05, eta: 20:26:41, time: 2.163, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0243, s0.acc: 99.0021, s0.loss_bbox_cls: 0.0204, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0188, s1.acc: 98.5168, s1.loss_bbox_cls: 0.0176, s1.loss_bbox_reg: 0.0345, s2.loss_cls: 0.0122, s2.acc: 97.9797, s2.loss_bbox_cls: 0.0112, s2.loss_bbox_reg: 0.0211, loss: 0.2147, grad_norm: 5.8795\n",
            "2020-09-08 10:03:37,991 - mmdet - INFO - Epoch [14][3264/5332]\tlr: 1.000e-05, eta: 20:24:22, time: 2.155, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0271, s0.acc: 98.9075, s0.loss_bbox_cls: 0.0231, s0.loss_bbox_reg: 0.0494, s1.loss_cls: 0.0216, s1.acc: 98.2361, s1.loss_bbox_cls: 0.0206, s1.loss_bbox_reg: 0.0406, s2.loss_cls: 0.0121, s2.acc: 98.1537, s2.loss_bbox_cls: 0.0122, s2.loss_bbox_reg: 0.0242, loss: 0.2365, grad_norm: 6.1663\n",
            "2020-09-08 10:05:56,205 - mmdet - INFO - Epoch [14][3328/5332]\tlr: 1.000e-05, eta: 20:22:05, time: 2.160, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0217, s0.acc: 99.1150, s0.loss_bbox_cls: 0.0199, s0.loss_bbox_reg: 0.0419, s1.loss_cls: 0.0139, s1.acc: 98.8922, s1.loss_bbox_cls: 0.0168, s1.loss_bbox_reg: 0.0325, s2.loss_cls: 0.0109, s2.acc: 98.5199, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0191, loss: 0.1944, grad_norm: 5.2028\n",
            "2020-09-08 10:08:14,043 - mmdet - INFO - Epoch [14][3392/5332]\tlr: 1.000e-05, eta: 20:19:46, time: 2.154, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0242, s0.acc: 99.0845, s0.loss_bbox_cls: 0.0194, s0.loss_bbox_reg: 0.0433, s1.loss_cls: 0.0178, s1.acc: 98.6023, s1.loss_bbox_cls: 0.0165, s1.loss_bbox_reg: 0.0334, s2.loss_cls: 0.0117, s2.acc: 98.1781, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0202, loss: 0.2056, grad_norm: 5.5905\n",
            "2020-09-08 10:10:32,655 - mmdet - INFO - Epoch [14][3456/5332]\tlr: 1.000e-05, eta: 20:17:30, time: 2.166, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0067, s0.loss_cls: 0.0265, s0.acc: 98.9624, s0.loss_bbox_cls: 0.0236, s0.loss_bbox_reg: 0.0454, s1.loss_cls: 0.0175, s1.acc: 98.5199, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0331, s2.loss_cls: 0.0123, s2.acc: 97.9034, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0183, loss: 0.2156, grad_norm: 5.3865\n",
            "2020-09-08 10:12:49,700 - mmdet - INFO - Epoch [14][3520/5332]\tlr: 1.000e-05, eta: 20:15:08, time: 2.141, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0203, s0.acc: 99.1974, s0.loss_bbox_cls: 0.0250, s0.loss_bbox_reg: 0.0491, s1.loss_cls: 0.0154, s1.acc: 98.6206, s1.loss_bbox_cls: 0.0227, s1.loss_bbox_reg: 0.0408, s2.loss_cls: 0.0103, s2.acc: 98.1628, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0217, loss: 0.2229, grad_norm: 5.6184\n",
            "2020-09-08 10:15:07,146 - mmdet - INFO - Epoch [14][3584/5332]\tlr: 1.000e-05, eta: 20:12:48, time: 2.148, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0252, s0.acc: 98.9990, s0.loss_bbox_cls: 0.0219, s0.loss_bbox_reg: 0.0464, s1.loss_cls: 0.0180, s1.acc: 98.4802, s1.loss_bbox_cls: 0.0188, s1.loss_bbox_reg: 0.0364, s2.loss_cls: 0.0109, s2.acc: 98.2086, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0211, loss: 0.2182, grad_norm: 5.6104\n",
            "2020-09-08 10:17:24,083 - mmdet - INFO - Epoch [14][3648/5332]\tlr: 1.000e-05, eta: 20:10:26, time: 2.140, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0240, s0.acc: 99.0051, s0.loss_bbox_cls: 0.0214, s0.loss_bbox_reg: 0.0462, s1.loss_cls: 0.0167, s1.acc: 98.6633, s1.loss_bbox_cls: 0.0183, s1.loss_bbox_reg: 0.0366, s2.loss_cls: 0.0106, s2.acc: 98.2452, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0219, loss: 0.2145, grad_norm: 6.0152\n",
            "2020-09-08 10:19:42,468 - mmdet - INFO - Epoch [14][3712/5332]\tlr: 1.000e-05, eta: 20:08:09, time: 2.162, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0191, s0.acc: 99.2706, s0.loss_bbox_cls: 0.0188, s0.loss_bbox_reg: 0.0392, s1.loss_cls: 0.0149, s1.acc: 98.8495, s1.loss_bbox_cls: 0.0165, s1.loss_bbox_reg: 0.0342, s2.loss_cls: 0.0114, s2.acc: 98.3215, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0209, loss: 0.1898, grad_norm: 4.9785\n",
            "2020-09-08 10:22:01,153 - mmdet - INFO - Epoch [14][3776/5332]\tlr: 1.000e-05, eta: 20:05:54, time: 2.167, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0277, s0.acc: 98.9014, s0.loss_bbox_cls: 0.0254, s0.loss_bbox_reg: 0.0519, s1.loss_cls: 0.0194, s1.acc: 98.4894, s1.loss_bbox_cls: 0.0188, s1.loss_bbox_reg: 0.0378, s2.loss_cls: 0.0115, s2.acc: 98.2452, s2.loss_bbox_cls: 0.0110, s2.loss_bbox_reg: 0.0223, loss: 0.2376, grad_norm: 6.2722\n",
            "2020-09-08 10:24:18,538 - mmdet - INFO - Epoch [14][3840/5332]\tlr: 1.000e-05, eta: 20:03:33, time: 2.147, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0246, s0.acc: 98.9288, s0.loss_bbox_cls: 0.0229, s0.loss_bbox_reg: 0.0475, s1.loss_cls: 0.0195, s1.acc: 98.3368, s1.loss_bbox_cls: 0.0200, s1.loss_bbox_reg: 0.0374, s2.loss_cls: 0.0119, s2.acc: 98.1628, s2.loss_bbox_cls: 0.0116, s2.loss_bbox_reg: 0.0232, loss: 0.2271, grad_norm: 6.0696\n",
            "2020-09-08 10:26:36,544 - mmdet - INFO - Epoch [14][3904/5332]\tlr: 1.000e-05, eta: 20:01:15, time: 2.156, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0245, s0.acc: 98.9838, s0.loss_bbox_cls: 0.0189, s0.loss_bbox_reg: 0.0452, s1.loss_cls: 0.0169, s1.acc: 98.6481, s1.loss_bbox_cls: 0.0153, s1.loss_bbox_reg: 0.0349, s2.loss_cls: 0.0101, s2.acc: 98.3368, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0219, loss: 0.2028, grad_norm: 5.5328\n",
            "2020-09-08 10:28:55,377 - mmdet - INFO - Epoch [14][3968/5332]\tlr: 1.000e-05, eta: 19:59:00, time: 2.169, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0201, s0.acc: 99.1913, s0.loss_bbox_cls: 0.0180, s0.loss_bbox_reg: 0.0391, s1.loss_cls: 0.0148, s1.acc: 98.8129, s1.loss_bbox_cls: 0.0144, s1.loss_bbox_reg: 0.0306, s2.loss_cls: 0.0095, s2.acc: 98.4253, s2.loss_bbox_cls: 0.0084, s2.loss_bbox_reg: 0.0184, loss: 0.1797, grad_norm: 4.9995\n",
            "2020-09-08 10:31:13,586 - mmdet - INFO - Epoch [14][4032/5332]\tlr: 1.000e-05, eta: 19:56:43, time: 2.159, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0218, s0.acc: 99.0875, s0.loss_bbox_cls: 0.0217, s0.loss_bbox_reg: 0.0464, s1.loss_cls: 0.0164, s1.acc: 98.7579, s1.loss_bbox_cls: 0.0188, s1.loss_bbox_reg: 0.0378, s2.loss_cls: 0.0106, s2.acc: 98.2452, s2.loss_bbox_cls: 0.0110, s2.loss_bbox_reg: 0.0227, loss: 0.2139, grad_norm: 5.7326\n",
            "2020-09-08 10:33:32,202 - mmdet - INFO - Epoch [14][4096/5332]\tlr: 1.000e-05, eta: 19:54:27, time: 2.166, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0023, s0.loss_cls: 0.0188, s0.acc: 99.2126, s0.loss_bbox_cls: 0.0170, s0.loss_bbox_reg: 0.0415, s1.loss_cls: 0.0131, s1.acc: 98.9563, s1.loss_bbox_cls: 0.0161, s1.loss_bbox_reg: 0.0344, s2.loss_cls: 0.0085, s2.acc: 98.5718, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0224, loss: 0.1873, grad_norm: 5.4462\n",
            "2020-09-08 10:35:49,928 - mmdet - INFO - Epoch [14][4160/5332]\tlr: 1.000e-05, eta: 19:52:07, time: 2.152, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0207, s0.acc: 99.1211, s0.loss_bbox_cls: 0.0157, s0.loss_bbox_reg: 0.0375, s1.loss_cls: 0.0161, s1.acc: 98.5352, s1.loss_bbox_cls: 0.0130, s1.loss_bbox_reg: 0.0279, s2.loss_cls: 0.0111, s2.acc: 97.8271, s2.loss_bbox_cls: 0.0080, s2.loss_bbox_reg: 0.0172, loss: 0.1769, grad_norm: 5.3660\n",
            "2020-09-08 10:38:07,951 - mmdet - INFO - Epoch [14][4224/5332]\tlr: 1.000e-05, eta: 19:49:49, time: 2.157, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0281, s0.acc: 98.8007, s0.loss_bbox_cls: 0.0241, s0.loss_bbox_reg: 0.0426, s1.loss_cls: 0.0193, s1.acc: 98.3002, s1.loss_bbox_cls: 0.0181, s1.loss_bbox_reg: 0.0326, s2.loss_cls: 0.0135, s2.acc: 97.5220, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0178, loss: 0.2151, grad_norm: 5.4822\n",
            "2020-09-08 10:40:25,797 - mmdet - INFO - Epoch [14][4288/5332]\tlr: 1.000e-05, eta: 19:47:31, time: 2.154, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0249, s0.acc: 98.9380, s0.loss_bbox_cls: 0.0221, s0.loss_bbox_reg: 0.0464, s1.loss_cls: 0.0197, s1.acc: 98.2208, s1.loss_bbox_cls: 0.0193, s1.loss_bbox_reg: 0.0366, s2.loss_cls: 0.0122, s2.acc: 97.8485, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0206, loss: 0.2192, grad_norm: 5.8769\n",
            "2020-09-08 10:42:44,099 - mmdet - INFO - Epoch [14][4352/5332]\tlr: 1.000e-05, eta: 19:45:14, time: 2.161, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0329, s0.acc: 98.8251, s0.loss_bbox_cls: 0.0226, s0.loss_bbox_reg: 0.0421, s1.loss_cls: 0.0239, s1.acc: 98.1354, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0317, s2.loss_cls: 0.0145, s2.acc: 97.5494, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0173, loss: 0.2214, grad_norm: 5.4627\n",
            "2020-09-08 10:45:02,497 - mmdet - INFO - Epoch [14][4416/5332]\tlr: 1.000e-05, eta: 19:42:57, time: 2.162, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0257, s0.acc: 98.9380, s0.loss_bbox_cls: 0.0175, s0.loss_bbox_reg: 0.0400, s1.loss_cls: 0.0195, s1.acc: 98.4619, s1.loss_bbox_cls: 0.0151, s1.loss_bbox_reg: 0.0320, s2.loss_cls: 0.0125, s2.acc: 97.8546, s2.loss_bbox_cls: 0.0088, s2.loss_bbox_reg: 0.0187, loss: 0.1987, grad_norm: 5.4972\n",
            "2020-09-08 10:47:20,062 - mmdet - INFO - Epoch [14][4480/5332]\tlr: 1.000e-05, eta: 19:40:37, time: 2.149, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0208, s0.acc: 99.0875, s0.loss_bbox_cls: 0.0198, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0157, s1.acc: 98.7610, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0355, s2.loss_cls: 0.0103, s2.acc: 98.4253, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0227, loss: 0.2044, grad_norm: 5.7892\n",
            "2020-09-08 10:49:38,622 - mmdet - INFO - Epoch [14][4544/5332]\tlr: 1.000e-05, eta: 19:38:21, time: 2.165, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0218, s0.acc: 99.1577, s0.loss_bbox_cls: 0.0179, s0.loss_bbox_reg: 0.0364, s1.loss_cls: 0.0158, s1.acc: 98.6267, s1.loss_bbox_cls: 0.0158, s1.loss_bbox_reg: 0.0293, s2.loss_cls: 0.0110, s2.acc: 98.1293, s2.loss_bbox_cls: 0.0083, s2.loss_bbox_reg: 0.0162, loss: 0.1786, grad_norm: 5.0209\n",
            "2020-09-08 10:51:55,105 - mmdet - INFO - Epoch [14][4608/5332]\tlr: 1.000e-05, eta: 19:35:58, time: 2.133, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0213, s0.acc: 99.2096, s0.loss_bbox_cls: 0.0224, s0.loss_bbox_reg: 0.0469, s1.loss_cls: 0.0162, s1.acc: 98.6206, s1.loss_bbox_cls: 0.0181, s1.loss_bbox_reg: 0.0364, s2.loss_cls: 0.0100, s2.acc: 98.4253, s2.loss_bbox_cls: 0.0114, s2.loss_bbox_reg: 0.0224, loss: 0.2133, grad_norm: 5.6023\n",
            "2020-09-08 10:54:13,360 - mmdet - INFO - Epoch [14][4672/5332]\tlr: 1.000e-05, eta: 19:33:40, time: 2.160, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0237, s0.acc: 99.0967, s0.loss_bbox_cls: 0.0193, s0.loss_bbox_reg: 0.0406, s1.loss_cls: 0.0207, s1.acc: 98.0988, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0343, s2.loss_cls: 0.0131, s2.acc: 97.5067, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0189, loss: 0.2045, grad_norm: 5.7174\n",
            "2020-09-08 10:56:32,575 - mmdet - INFO - Epoch [14][4736/5332]\tlr: 1.000e-05, eta: 19:31:26, time: 2.175, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0233, s0.acc: 99.0875, s0.loss_bbox_cls: 0.0219, s0.loss_bbox_reg: 0.0489, s1.loss_cls: 0.0158, s1.acc: 98.7854, s1.loss_bbox_cls: 0.0189, s1.loss_bbox_reg: 0.0388, s2.loss_cls: 0.0098, s2.acc: 98.6389, s2.loss_bbox_cls: 0.0117, s2.loss_bbox_reg: 0.0244, loss: 0.2202, grad_norm: 6.1192\n",
            "2020-09-08 10:58:50,765 - mmdet - INFO - Epoch [14][4800/5332]\tlr: 1.000e-05, eta: 19:29:09, time: 2.159, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0248, s0.acc: 98.9471, s0.loss_bbox_cls: 0.0221, s0.loss_bbox_reg: 0.0451, s1.loss_cls: 0.0188, s1.acc: 98.3795, s1.loss_bbox_cls: 0.0180, s1.loss_bbox_reg: 0.0355, s2.loss_cls: 0.0119, s2.acc: 97.9340, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0214, loss: 0.2178, grad_norm: 6.1280\n",
            "2020-09-08 11:01:08,133 - mmdet - INFO - Epoch [14][4864/5332]\tlr: 1.000e-05, eta: 19:26:48, time: 2.146, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0025, s0.loss_cls: 0.0216, s0.acc: 99.1180, s0.loss_bbox_cls: 0.0210, s0.loss_bbox_reg: 0.0438, s1.loss_cls: 0.0174, s1.acc: 98.5260, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0109, s2.acc: 98.1934, s2.loss_bbox_cls: 0.0114, s2.loss_bbox_reg: 0.0222, loss: 0.2066, grad_norm: 5.2844\n",
            "2020-09-08 11:03:27,913 - mmdet - INFO - Epoch [14][4928/5332]\tlr: 1.000e-05, eta: 19:24:36, time: 2.184, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0247, s0.acc: 98.9960, s0.loss_bbox_cls: 0.0200, s0.loss_bbox_reg: 0.0414, s1.loss_cls: 0.0186, s1.acc: 98.4009, s1.loss_bbox_cls: 0.0148, s1.loss_bbox_reg: 0.0306, s2.loss_cls: 0.0110, s2.acc: 97.9095, s2.loss_bbox_cls: 0.0088, s2.loss_bbox_reg: 0.0188, loss: 0.1965, grad_norm: 5.0238\n",
            "2020-09-08 11:05:45,306 - mmdet - INFO - Epoch [14][4992/5332]\tlr: 1.000e-05, eta: 19:22:16, time: 2.147, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0225, s0.acc: 99.1089, s0.loss_bbox_cls: 0.0237, s0.loss_bbox_reg: 0.0502, s1.loss_cls: 0.0134, s1.acc: 98.9227, s1.loss_bbox_cls: 0.0218, s1.loss_bbox_reg: 0.0416, s2.loss_cls: 0.0104, s2.acc: 98.4009, s2.loss_bbox_cls: 0.0116, s2.loss_bbox_reg: 0.0228, loss: 0.2231, grad_norm: 5.5100\n",
            "2020-09-08 11:08:05,143 - mmdet - INFO - Epoch [14][5056/5332]\tlr: 1.000e-05, eta: 19:20:03, time: 2.185, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0068, s0.loss_cls: 0.0214, s0.acc: 99.1180, s0.loss_bbox_cls: 0.0223, s0.loss_bbox_reg: 0.0435, s1.loss_cls: 0.0151, s1.acc: 98.8342, s1.loss_bbox_cls: 0.0156, s1.loss_bbox_reg: 0.0317, s2.loss_cls: 0.0091, s2.acc: 98.5962, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0180, loss: 0.1966, grad_norm: 5.2102\n",
            "2020-09-08 11:10:23,572 - mmdet - INFO - Epoch [14][5120/5332]\tlr: 1.000e-05, eta: 19:17:47, time: 2.163, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0230, s0.acc: 99.0387, s0.loss_bbox_cls: 0.0241, s0.loss_bbox_reg: 0.0504, s1.loss_cls: 0.0151, s1.acc: 98.8708, s1.loss_bbox_cls: 0.0199, s1.loss_bbox_reg: 0.0377, s2.loss_cls: 0.0095, s2.acc: 98.5260, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0217, loss: 0.2199, grad_norm: 5.4412\n",
            "2020-09-08 11:12:40,646 - mmdet - INFO - Epoch [14][5184/5332]\tlr: 1.000e-05, eta: 19:15:25, time: 2.142, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0251, s0.acc: 98.9471, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0447, s1.loss_cls: 0.0186, s1.acc: 98.5474, s1.loss_bbox_cls: 0.0166, s1.loss_bbox_reg: 0.0345, s2.loss_cls: 0.0108, s2.acc: 98.3978, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0201, loss: 0.2082, grad_norm: 5.7681\n",
            "2020-09-08 11:14:59,735 - mmdet - INFO - Epoch [14][5248/5332]\tlr: 1.000e-05, eta: 19:13:11, time: 2.173, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0230, s0.acc: 99.1150, s0.loss_bbox_cls: 0.0190, s0.loss_bbox_reg: 0.0412, s1.loss_cls: 0.0194, s1.acc: 98.3643, s1.loss_bbox_cls: 0.0151, s1.loss_bbox_reg: 0.0321, s2.loss_cls: 0.0118, s2.acc: 98.1445, s2.loss_bbox_cls: 0.0087, s2.loss_bbox_reg: 0.0191, loss: 0.1985, grad_norm: 5.4490\n",
            "2020-09-08 11:17:17,399 - mmdet - INFO - Epoch [14][5312/5332]\tlr: 1.000e-05, eta: 19:10:51, time: 2.151, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0222, s0.acc: 99.0997, s0.loss_bbox_cls: 0.0226, s0.loss_bbox_reg: 0.0456, s1.loss_cls: 0.0172, s1.acc: 98.6206, s1.loss_bbox_cls: 0.0175, s1.loss_bbox_reg: 0.0332, s2.loss_cls: 0.0107, s2.acc: 97.9889, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0203, loss: 0.2086, grad_norm: 4.9208\n",
            "2020-09-08 11:18:01,577 - mmdet - INFO - Saving checkpoint at 14 epochs\n",
            "[>>] 667/667, 0.5 task/s, elapsed: 1290s, ETA:     0s2020-09-08 11:39:39,906 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 259  | 0.866  | 0.675 |\n",
            "| 3     | 22  | 63   | 0.818  | 0.684 |\n",
            "| 4     | 529 | 1250 | 0.928  | 0.837 |\n",
            "| 5     | 78  | 181  | 0.897  | 0.802 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.749 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-08 11:39:39,910 - mmdet - INFO - Epoch(val) [14][5332]\tmAP: 0.7495\n",
            "2020-09-08 11:42:00,390 - mmdet - INFO - Epoch [15][64/5332]\tlr: 1.000e-05, eta: 19:05:49, time: 2.195, data_time: 0.037, memory: 8090, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0242, s0.acc: 98.9716, s0.loss_bbox_cls: 0.0202, s0.loss_bbox_reg: 0.0420, s1.loss_cls: 0.0185, s1.acc: 98.4100, s1.loss_bbox_cls: 0.0159, s1.loss_bbox_reg: 0.0337, s2.loss_cls: 0.0119, s2.acc: 98.1537, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0183, loss: 0.2028, grad_norm: 5.2235\n",
            "2020-09-08 11:44:20,114 - mmdet - INFO - Epoch [15][128/5332]\tlr: 1.000e-05, eta: 19:03:37, time: 2.183, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0248, s0.acc: 99.1577, s0.loss_bbox_cls: 0.0200, s0.loss_bbox_reg: 0.0436, s1.loss_cls: 0.0182, s1.acc: 98.6969, s1.loss_bbox_cls: 0.0155, s1.loss_bbox_reg: 0.0325, s2.loss_cls: 0.0106, s2.acc: 98.4070, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0191, loss: 0.2034, grad_norm: 5.2695\n",
            "2020-09-08 11:46:38,458 - mmdet - INFO - Epoch [15][192/5332]\tlr: 1.000e-05, eta: 19:01:20, time: 2.162, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0291, s0.acc: 98.8098, s0.loss_bbox_cls: 0.0298, s0.loss_bbox_reg: 0.0552, s1.loss_cls: 0.0227, s1.acc: 98.1476, s1.loss_bbox_cls: 0.0250, s1.loss_bbox_reg: 0.0413, s2.loss_cls: 0.0142, s2.acc: 97.5342, s2.loss_bbox_cls: 0.0124, s2.loss_bbox_reg: 0.0221, loss: 0.2600, grad_norm: 5.9617\n",
            "2020-09-08 11:48:55,876 - mmdet - INFO - Epoch [15][256/5332]\tlr: 1.000e-05, eta: 18:59:01, time: 2.147, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0253, s0.acc: 98.9258, s0.loss_bbox_cls: 0.0244, s0.loss_bbox_reg: 0.0487, s1.loss_cls: 0.0185, s1.acc: 98.4528, s1.loss_bbox_cls: 0.0180, s1.loss_bbox_reg: 0.0352, s2.loss_cls: 0.0108, s2.acc: 98.3276, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0206, loss: 0.2210, grad_norm: 5.4925\n",
            "2020-09-08 11:51:12,178 - mmdet - INFO - Epoch [15][320/5332]\tlr: 1.000e-05, eta: 18:56:39, time: 2.130, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0260, s0.acc: 98.9471, s0.loss_bbox_cls: 0.0197, s0.loss_bbox_reg: 0.0445, s1.loss_cls: 0.0176, s1.acc: 98.6298, s1.loss_bbox_cls: 0.0160, s1.loss_bbox_reg: 0.0350, s2.loss_cls: 0.0108, s2.acc: 98.2330, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0215, loss: 0.2089, grad_norm: 5.8200\n",
            "2020-09-08 11:53:29,455 - mmdet - INFO - Epoch [15][384/5332]\tlr: 1.000e-05, eta: 18:54:20, time: 2.145, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0068, s0.loss_cls: 0.0256, s0.acc: 98.8953, s0.loss_bbox_cls: 0.0243, s0.loss_bbox_reg: 0.0523, s1.loss_cls: 0.0178, s1.acc: 98.6084, s1.loss_bbox_cls: 0.0204, s1.loss_bbox_reg: 0.0404, s2.loss_cls: 0.0106, s2.acc: 98.2300, s2.loss_bbox_cls: 0.0122, s2.loss_bbox_reg: 0.0246, loss: 0.2409, grad_norm: 6.2548\n",
            "2020-09-08 11:55:47,842 - mmdet - INFO - Epoch [15][448/5332]\tlr: 1.000e-05, eta: 18:52:04, time: 2.162, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0062, s0.loss_cls: 0.0303, s0.acc: 98.7915, s0.loss_bbox_cls: 0.0295, s0.loss_bbox_reg: 0.0523, s1.loss_cls: 0.0223, s1.acc: 98.2391, s1.loss_bbox_cls: 0.0203, s1.loss_bbox_reg: 0.0369, s2.loss_cls: 0.0136, s2.acc: 97.6685, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0212, loss: 0.2504, grad_norm: 6.2168\n",
            "2020-09-08 11:58:05,400 - mmdet - INFO - Epoch [15][512/5332]\tlr: 1.000e-05, eta: 18:49:45, time: 2.149, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0269, s0.acc: 98.8678, s0.loss_bbox_cls: 0.0233, s0.loss_bbox_reg: 0.0465, s1.loss_cls: 0.0195, s1.acc: 98.3521, s1.loss_bbox_cls: 0.0189, s1.loss_bbox_reg: 0.0373, s2.loss_cls: 0.0122, s2.acc: 98.0530, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0222, loss: 0.2257, grad_norm: 5.6054\n",
            "2020-09-08 12:00:22,616 - mmdet - INFO - Epoch [15][576/5332]\tlr: 1.000e-05, eta: 18:47:26, time: 2.144, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0240, s0.acc: 99.1058, s0.loss_bbox_cls: 0.0251, s0.loss_bbox_reg: 0.0476, s1.loss_cls: 0.0174, s1.acc: 98.5779, s1.loss_bbox_cls: 0.0200, s1.loss_bbox_reg: 0.0358, s2.loss_cls: 0.0109, s2.acc: 97.9187, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0203, loss: 0.2243, grad_norm: 5.5690\n",
            "2020-09-08 12:02:40,437 - mmdet - INFO - Epoch [15][640/5332]\tlr: 1.000e-05, eta: 18:45:08, time: 2.153, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0230, s0.acc: 99.1119, s0.loss_bbox_cls: 0.0236, s0.loss_bbox_reg: 0.0468, s1.loss_cls: 0.0158, s1.acc: 98.7701, s1.loss_bbox_cls: 0.0207, s1.loss_bbox_reg: 0.0373, s2.loss_cls: 0.0115, s2.acc: 98.1262, s2.loss_bbox_cls: 0.0119, s2.loss_bbox_reg: 0.0228, loss: 0.2214, grad_norm: 5.5591\n",
            "2020-09-08 12:04:58,535 - mmdet - INFO - Epoch [15][704/5332]\tlr: 1.000e-05, eta: 18:42:51, time: 2.158, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0206, s0.acc: 99.1486, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0426, s1.loss_cls: 0.0170, s1.acc: 98.6053, s1.loss_bbox_cls: 0.0168, s1.loss_bbox_reg: 0.0341, s2.loss_cls: 0.0108, s2.acc: 98.0194, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0197, loss: 0.1968, grad_norm: 5.0970\n",
            "2020-09-08 12:07:18,737 - mmdet - INFO - Epoch [15][768/5332]\tlr: 1.000e-05, eta: 18:40:40, time: 2.191, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0199, s0.acc: 99.2279, s0.loss_bbox_cls: 0.0166, s0.loss_bbox_reg: 0.0391, s1.loss_cls: 0.0160, s1.acc: 98.7579, s1.loss_bbox_cls: 0.0144, s1.loss_bbox_reg: 0.0321, s2.loss_cls: 0.0109, s2.acc: 98.1781, s2.loss_bbox_cls: 0.0087, s2.loss_bbox_reg: 0.0199, loss: 0.1854, grad_norm: 5.2323\n",
            "2020-09-08 12:09:36,630 - mmdet - INFO - Epoch [15][832/5332]\tlr: 1.000e-05, eta: 18:38:22, time: 2.155, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0194, s0.acc: 99.2371, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0444, s1.loss_cls: 0.0139, s1.acc: 98.9349, s1.loss_bbox_cls: 0.0188, s1.loss_bbox_reg: 0.0356, s2.loss_cls: 0.0110, s2.acc: 98.2361, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0214, loss: 0.2028, grad_norm: 5.3810\n",
            "2020-09-08 12:11:53,710 - mmdet - INFO - Epoch [15][896/5332]\tlr: 1.000e-05, eta: 18:36:02, time: 2.142, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0210, s0.acc: 99.1547, s0.loss_bbox_cls: 0.0223, s0.loss_bbox_reg: 0.0466, s1.loss_cls: 0.0159, s1.acc: 98.7274, s1.loss_bbox_cls: 0.0184, s1.loss_bbox_reg: 0.0367, s2.loss_cls: 0.0099, s2.acc: 98.3398, s2.loss_bbox_cls: 0.0119, s2.loss_bbox_reg: 0.0230, loss: 0.2126, grad_norm: 5.9114\n",
            "2020-09-08 12:14:11,614 - mmdet - INFO - Epoch [15][960/5332]\tlr: 1.000e-05, eta: 18:33:45, time: 2.155, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0253, s0.acc: 99.0326, s0.loss_bbox_cls: 0.0240, s0.loss_bbox_reg: 0.0533, s1.loss_cls: 0.0174, s1.acc: 98.5626, s1.loss_bbox_cls: 0.0188, s1.loss_bbox_reg: 0.0401, s2.loss_cls: 0.0115, s2.acc: 98.0591, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0232, loss: 0.2316, grad_norm: 6.4672\n",
            "2020-09-08 12:16:29,998 - mmdet - INFO - Epoch [15][1024/5332]\tlr: 1.000e-05, eta: 18:31:28, time: 2.162, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0214, s0.acc: 99.1058, s0.loss_bbox_cls: 0.0190, s0.loss_bbox_reg: 0.0436, s1.loss_cls: 0.0155, s1.acc: 98.6847, s1.loss_bbox_cls: 0.0168, s1.loss_bbox_reg: 0.0353, s2.loss_cls: 0.0098, s2.acc: 98.3459, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0211, loss: 0.2035, grad_norm: 5.8547\n",
            "2020-09-08 12:18:49,624 - mmdet - INFO - Epoch [15][1088/5332]\tlr: 1.000e-05, eta: 18:29:15, time: 2.182, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0228, s0.acc: 99.0906, s0.loss_bbox_cls: 0.0200, s0.loss_bbox_reg: 0.0439, s1.loss_cls: 0.0160, s1.acc: 98.7091, s1.loss_bbox_cls: 0.0169, s1.loss_bbox_reg: 0.0356, s2.loss_cls: 0.0113, s2.acc: 98.3154, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0210, loss: 0.2035, grad_norm: 5.2629\n",
            "2020-09-08 12:21:10,000 - mmdet - INFO - Epoch [15][1152/5332]\tlr: 1.000e-05, eta: 18:27:04, time: 2.193, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0199, s0.acc: 99.2371, s0.loss_bbox_cls: 0.0173, s0.loss_bbox_reg: 0.0392, s1.loss_cls: 0.0152, s1.acc: 98.7915, s1.loss_bbox_cls: 0.0147, s1.loss_bbox_reg: 0.0327, s2.loss_cls: 0.0082, s2.acc: 98.7793, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0206, loss: 0.1832, grad_norm: 5.0151\n",
            "2020-09-08 12:23:29,839 - mmdet - INFO - Epoch [15][1216/5332]\tlr: 1.000e-05, eta: 18:24:51, time: 2.185, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0221, s0.acc: 99.0479, s0.loss_bbox_cls: 0.0197, s0.loss_bbox_reg: 0.0448, s1.loss_cls: 0.0160, s1.acc: 98.6969, s1.loss_bbox_cls: 0.0166, s1.loss_bbox_reg: 0.0345, s2.loss_cls: 0.0094, s2.acc: 98.4253, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0205, loss: 0.2004, grad_norm: 5.7638\n",
            "2020-09-08 12:25:49,056 - mmdet - INFO - Epoch [15][1280/5332]\tlr: 1.000e-05, eta: 18:22:37, time: 2.175, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0206, s0.acc: 99.1119, s0.loss_bbox_cls: 0.0243, s0.loss_bbox_reg: 0.0516, s1.loss_cls: 0.0148, s1.acc: 98.7518, s1.loss_bbox_cls: 0.0195, s1.loss_bbox_reg: 0.0385, s2.loss_cls: 0.0085, s2.acc: 98.5016, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0222, loss: 0.2217, grad_norm: 5.9125\n",
            "2020-09-08 12:28:07,801 - mmdet - INFO - Epoch [15][1344/5332]\tlr: 1.000e-05, eta: 18:20:21, time: 2.168, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0247, s0.acc: 98.9594, s0.loss_bbox_cls: 0.0200, s0.loss_bbox_reg: 0.0429, s1.loss_cls: 0.0182, s1.acc: 98.5474, s1.loss_bbox_cls: 0.0175, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0117, s2.acc: 98.1415, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0202, loss: 0.2091, grad_norm: 5.5077\n",
            "2020-09-08 12:30:27,540 - mmdet - INFO - Epoch [15][1408/5332]\tlr: 1.000e-05, eta: 18:18:08, time: 2.183, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0026, s0.loss_cls: 0.0210, s0.acc: 99.1913, s0.loss_bbox_cls: 0.0190, s0.loss_bbox_reg: 0.0431, s1.loss_cls: 0.0150, s1.acc: 98.8647, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0357, s2.loss_cls: 0.0089, s2.acc: 98.5596, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0210, loss: 0.1955, grad_norm: 5.1270\n",
            "2020-09-08 12:32:45,062 - mmdet - INFO - Epoch [15][1472/5332]\tlr: 1.000e-05, eta: 18:15:49, time: 2.149, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0234, s0.acc: 99.0723, s0.loss_bbox_cls: 0.0212, s0.loss_bbox_reg: 0.0458, s1.loss_cls: 0.0155, s1.acc: 98.6633, s1.loss_bbox_cls: 0.0181, s1.loss_bbox_reg: 0.0373, s2.loss_cls: 0.0100, s2.acc: 98.4100, s2.loss_bbox_cls: 0.0116, s2.loss_bbox_reg: 0.0237, loss: 0.2159, grad_norm: 5.7247\n",
            "2020-09-08 12:35:03,990 - mmdet - INFO - Epoch [15][1536/5332]\tlr: 1.000e-05, eta: 18:13:34, time: 2.171, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0296, s0.acc: 98.7915, s0.loss_bbox_cls: 0.0238, s0.loss_bbox_reg: 0.0480, s1.loss_cls: 0.0210, s1.acc: 98.0377, s1.loss_bbox_cls: 0.0185, s1.loss_bbox_reg: 0.0350, s2.loss_cls: 0.0138, s2.acc: 97.3053, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0209, loss: 0.2289, grad_norm: 6.0032\n",
            "2020-09-08 12:37:23,261 - mmdet - INFO - Epoch [15][1600/5332]\tlr: 1.000e-05, eta: 18:11:20, time: 2.176, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0246, s0.acc: 99.0784, s0.loss_bbox_cls: 0.0235, s0.loss_bbox_reg: 0.0480, s1.loss_cls: 0.0173, s1.acc: 98.6755, s1.loss_bbox_cls: 0.0194, s1.loss_bbox_reg: 0.0372, s2.loss_cls: 0.0113, s2.acc: 98.2208, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0207, loss: 0.2186, grad_norm: 5.7607\n",
            "2020-09-08 12:39:41,734 - mmdet - INFO - Epoch [15][1664/5332]\tlr: 1.000e-05, eta: 18:09:03, time: 2.164, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0203, s0.acc: 99.1943, s0.loss_bbox_cls: 0.0168, s0.loss_bbox_reg: 0.0372, s1.loss_cls: 0.0150, s1.acc: 98.8525, s1.loss_bbox_cls: 0.0150, s1.loss_bbox_reg: 0.0321, s2.loss_cls: 0.0094, s2.acc: 98.7091, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0200, loss: 0.1824, grad_norm: 5.0963\n",
            "2020-09-08 12:41:59,896 - mmdet - INFO - Epoch [15][1728/5332]\tlr: 1.000e-05, eta: 18:06:46, time: 2.159, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0241, s0.acc: 99.0234, s0.loss_bbox_cls: 0.0239, s0.loss_bbox_reg: 0.0455, s1.loss_cls: 0.0182, s1.acc: 98.4406, s1.loss_bbox_cls: 0.0196, s1.loss_bbox_reg: 0.0347, s2.loss_cls: 0.0120, s2.acc: 97.8638, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0193, loss: 0.2134, grad_norm: 5.8329\n",
            "2020-09-08 12:44:16,962 - mmdet - INFO - Epoch [15][1792/5332]\tlr: 1.000e-05, eta: 18:04:26, time: 2.142, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0257, s0.acc: 99.1119, s0.loss_bbox_cls: 0.0203, s0.loss_bbox_reg: 0.0426, s1.loss_cls: 0.0176, s1.acc: 98.7610, s1.loss_bbox_cls: 0.0166, s1.loss_bbox_reg: 0.0343, s2.loss_cls: 0.0104, s2.acc: 98.4314, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0210, loss: 0.2091, grad_norm: 5.0171\n",
            "2020-09-08 12:46:33,917 - mmdet - INFO - Epoch [15][1856/5332]\tlr: 1.000e-05, eta: 18:02:06, time: 2.140, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0238, s0.acc: 98.9929, s0.loss_bbox_cls: 0.0204, s0.loss_bbox_reg: 0.0448, s1.loss_cls: 0.0175, s1.acc: 98.5046, s1.loss_bbox_cls: 0.0157, s1.loss_bbox_reg: 0.0346, s2.loss_cls: 0.0112, s2.acc: 98.0621, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0200, loss: 0.2027, grad_norm: 5.8069\n",
            "2020-09-08 12:48:53,301 - mmdet - INFO - Epoch [15][1920/5332]\tlr: 1.000e-05, eta: 17:59:52, time: 2.178, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0231, s0.acc: 99.0509, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0429, s1.loss_cls: 0.0173, s1.acc: 98.6023, s1.loss_bbox_cls: 0.0174, s1.loss_bbox_reg: 0.0334, s2.loss_cls: 0.0112, s2.acc: 98.0957, s2.loss_bbox_cls: 0.0087, s2.loss_bbox_reg: 0.0192, loss: 0.2021, grad_norm: 5.4701\n",
            "2020-09-08 12:51:10,839 - mmdet - INFO - Epoch [15][1984/5332]\tlr: 1.000e-05, eta: 17:57:33, time: 2.149, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0288, s0.acc: 98.8586, s0.loss_bbox_cls: 0.0246, s0.loss_bbox_reg: 0.0491, s1.loss_cls: 0.0223, s1.acc: 97.9553, s1.loss_bbox_cls: 0.0197, s1.loss_bbox_reg: 0.0391, s2.loss_cls: 0.0147, s2.acc: 97.2626, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0223, loss: 0.2406, grad_norm: 6.2625\n",
            "2020-09-08 12:53:29,647 - mmdet - INFO - Epoch [15][2048/5332]\tlr: 1.000e-05, eta: 17:55:17, time: 2.169, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0221, s0.acc: 99.0845, s0.loss_bbox_cls: 0.0201, s0.loss_bbox_reg: 0.0450, s1.loss_cls: 0.0140, s1.acc: 98.9166, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0371, s2.loss_cls: 0.0085, s2.acc: 98.7823, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0240, loss: 0.2082, grad_norm: 5.6842\n",
            "2020-09-08 12:55:47,922 - mmdet - INFO - Epoch [15][2112/5332]\tlr: 1.000e-05, eta: 17:53:00, time: 2.161, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0203, s0.acc: 99.2065, s0.loss_bbox_cls: 0.0198, s0.loss_bbox_reg: 0.0446, s1.loss_cls: 0.0146, s1.acc: 98.7610, s1.loss_bbox_cls: 0.0165, s1.loss_bbox_reg: 0.0341, s2.loss_cls: 0.0093, s2.acc: 98.4924, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0209, loss: 0.1976, grad_norm: 5.4544\n",
            "2020-09-08 12:58:06,081 - mmdet - INFO - Epoch [15][2176/5332]\tlr: 1.000e-05, eta: 17:50:43, time: 2.159, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0024, s0.loss_cls: 0.0238, s0.acc: 99.0417, s0.loss_bbox_cls: 0.0193, s0.loss_bbox_reg: 0.0443, s1.loss_cls: 0.0178, s1.acc: 98.5291, s1.loss_bbox_cls: 0.0164, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0110, s2.acc: 98.1628, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0200, loss: 0.2039, grad_norm: 5.5351\n",
            "2020-09-08 13:00:25,400 - mmdet - INFO - Epoch [15][2240/5332]\tlr: 1.000e-05, eta: 17:48:28, time: 2.177, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0218, s0.acc: 99.0967, s0.loss_bbox_cls: 0.0191, s0.loss_bbox_reg: 0.0411, s1.loss_cls: 0.0148, s1.acc: 98.8403, s1.loss_bbox_cls: 0.0169, s1.loss_bbox_reg: 0.0319, s2.loss_cls: 0.0095, s2.acc: 98.2666, s2.loss_bbox_cls: 0.0088, s2.loss_bbox_reg: 0.0184, loss: 0.1891, grad_norm: 5.3896\n",
            "2020-09-08 13:02:43,935 - mmdet - INFO - Epoch [15][2304/5332]\tlr: 1.000e-05, eta: 17:46:12, time: 2.165, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0203, s0.acc: 99.1608, s0.loss_bbox_cls: 0.0175, s0.loss_bbox_reg: 0.0402, s1.loss_cls: 0.0156, s1.acc: 98.6542, s1.loss_bbox_cls: 0.0150, s1.loss_bbox_reg: 0.0320, s2.loss_cls: 0.0094, s2.acc: 98.4131, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0186, loss: 0.1844, grad_norm: 5.0994\n",
            "2020-09-08 13:05:03,149 - mmdet - INFO - Epoch [15][2368/5332]\tlr: 1.000e-05, eta: 17:43:57, time: 2.175, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0225, s0.acc: 99.0601, s0.loss_bbox_cls: 0.0232, s0.loss_bbox_reg: 0.0491, s1.loss_cls: 0.0147, s1.acc: 98.8861, s1.loss_bbox_cls: 0.0186, s1.loss_bbox_reg: 0.0358, s2.loss_cls: 0.0091, s2.acc: 98.4497, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0217, loss: 0.2150, grad_norm: 5.6775\n",
            "2020-09-08 13:07:19,357 - mmdet - INFO - Epoch [15][2432/5332]\tlr: 1.000e-05, eta: 17:41:35, time: 2.128, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0201, s0.acc: 99.1699, s0.loss_bbox_cls: 0.0191, s0.loss_bbox_reg: 0.0411, s1.loss_cls: 0.0159, s1.acc: 98.7762, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0334, s2.loss_cls: 0.0115, s2.acc: 98.1201, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0200, loss: 0.1941, grad_norm: 5.4179\n",
            "2020-09-08 13:09:36,528 - mmdet - INFO - Epoch [15][2496/5332]\tlr: 1.000e-05, eta: 17:39:16, time: 2.143, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0227, s0.acc: 99.1150, s0.loss_bbox_cls: 0.0231, s0.loss_bbox_reg: 0.0489, s1.loss_cls: 0.0167, s1.acc: 98.5931, s1.loss_bbox_cls: 0.0224, s1.loss_bbox_reg: 0.0429, s2.loss_cls: 0.0118, s2.acc: 98.1750, s2.loss_bbox_cls: 0.0118, s2.loss_bbox_reg: 0.0244, loss: 0.2329, grad_norm: 5.9754\n",
            "2020-09-08 13:11:57,204 - mmdet - INFO - Epoch [15][2560/5332]\tlr: 1.000e-05, eta: 17:37:04, time: 2.198, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0239, s0.acc: 98.9807, s0.loss_bbox_cls: 0.0198, s0.loss_bbox_reg: 0.0429, s1.loss_cls: 0.0173, s1.acc: 98.6328, s1.loss_bbox_cls: 0.0162, s1.loss_bbox_reg: 0.0343, s2.loss_cls: 0.0124, s2.acc: 98.0042, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0196, loss: 0.2049, grad_norm: 5.8727\n",
            "2020-09-08 13:14:16,913 - mmdet - INFO - Epoch [15][2624/5332]\tlr: 1.000e-05, eta: 17:34:50, time: 2.183, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0259, s0.acc: 98.9380, s0.loss_bbox_cls: 0.0208, s0.loss_bbox_reg: 0.0433, s1.loss_cls: 0.0236, s1.acc: 98.1842, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0348, s2.loss_cls: 0.0151, s2.acc: 97.4762, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0206, loss: 0.2194, grad_norm: 5.8822\n",
            "2020-09-08 13:16:33,662 - mmdet - INFO - Epoch [15][2688/5332]\tlr: 1.000e-05, eta: 17:32:29, time: 2.137, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0281, s0.acc: 99.0112, s0.loss_bbox_cls: 0.0195, s0.loss_bbox_reg: 0.0454, s1.loss_cls: 0.0202, s1.acc: 98.4955, s1.loss_bbox_cls: 0.0182, s1.loss_bbox_reg: 0.0380, s2.loss_cls: 0.0111, s2.acc: 98.4650, s2.loss_bbox_cls: 0.0110, s2.loss_bbox_reg: 0.0225, loss: 0.2204, grad_norm: 6.1049\n",
            "2020-09-08 13:18:52,194 - mmdet - INFO - Epoch [15][2752/5332]\tlr: 1.000e-05, eta: 17:30:13, time: 2.165, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0215, s0.acc: 99.1455, s0.loss_bbox_cls: 0.0204, s0.loss_bbox_reg: 0.0417, s1.loss_cls: 0.0160, s1.acc: 98.7549, s1.loss_bbox_cls: 0.0153, s1.loss_bbox_reg: 0.0307, s2.loss_cls: 0.0096, s2.acc: 98.3856, s2.loss_bbox_cls: 0.0087, s2.loss_bbox_reg: 0.0173, loss: 0.1879, grad_norm: 5.4741\n",
            "2020-09-08 13:21:11,453 - mmdet - INFO - Epoch [15][2816/5332]\tlr: 1.000e-05, eta: 17:27:58, time: 2.176, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0209, s0.acc: 99.1882, s0.loss_bbox_cls: 0.0233, s0.loss_bbox_reg: 0.0463, s1.loss_cls: 0.0162, s1.acc: 98.7579, s1.loss_bbox_cls: 0.0186, s1.loss_bbox_reg: 0.0344, s2.loss_cls: 0.0101, s2.acc: 98.1781, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0195, loss: 0.2084, grad_norm: 5.1410\n",
            "2020-09-08 13:23:28,018 - mmdet - INFO - Epoch [15][2880/5332]\tlr: 1.000e-05, eta: 17:25:37, time: 2.134, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0209, s0.acc: 99.2432, s0.loss_bbox_cls: 0.0171, s0.loss_bbox_reg: 0.0377, s1.loss_cls: 0.0143, s1.acc: 98.7427, s1.loss_bbox_cls: 0.0142, s1.loss_bbox_reg: 0.0294, s2.loss_cls: 0.0095, s2.acc: 98.4009, s2.loss_bbox_cls: 0.0084, s2.loss_bbox_reg: 0.0174, loss: 0.1771, grad_norm: 5.0446\n",
            "2020-09-08 13:25:46,906 - mmdet - INFO - Epoch [15][2944/5332]\tlr: 1.000e-05, eta: 17:23:21, time: 2.170, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0251, s0.acc: 99.0051, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0436, s1.loss_cls: 0.0172, s1.acc: 98.6908, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0344, s2.loss_cls: 0.0111, s2.acc: 98.3093, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0202, loss: 0.2100, grad_norm: 5.5002\n",
            "2020-09-08 13:28:05,377 - mmdet - INFO - Epoch [15][3008/5332]\tlr: 1.000e-05, eta: 17:21:04, time: 2.164, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0247, s0.acc: 98.9929, s0.loss_bbox_cls: 0.0232, s0.loss_bbox_reg: 0.0478, s1.loss_cls: 0.0212, s1.acc: 98.2452, s1.loss_bbox_cls: 0.0191, s1.loss_bbox_reg: 0.0366, s2.loss_cls: 0.0133, s2.acc: 97.9187, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0216, loss: 0.2271, grad_norm: 5.5060\n",
            "2020-09-08 13:30:22,834 - mmdet - INFO - Epoch [15][3072/5332]\tlr: 1.000e-05, eta: 17:18:45, time: 2.148, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0241, s0.acc: 99.1577, s0.loss_bbox_cls: 0.0210, s0.loss_bbox_reg: 0.0476, s1.loss_cls: 0.0159, s1.acc: 98.8739, s1.loss_bbox_cls: 0.0168, s1.loss_bbox_reg: 0.0362, s2.loss_cls: 0.0102, s2.acc: 98.5779, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0235, loss: 0.2133, grad_norm: 5.8478\n",
            "2020-09-08 13:32:41,755 - mmdet - INFO - Epoch [15][3136/5332]\tlr: 1.000e-05, eta: 17:16:30, time: 2.171, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0213, s0.acc: 99.1760, s0.loss_bbox_cls: 0.0171, s0.loss_bbox_reg: 0.0387, s1.loss_cls: 0.0155, s1.acc: 98.6389, s1.loss_bbox_cls: 0.0152, s1.loss_bbox_reg: 0.0304, s2.loss_cls: 0.0101, s2.acc: 98.3093, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0188, loss: 0.1851, grad_norm: 5.2416\n",
            "2020-09-08 13:35:01,562 - mmdet - INFO - Epoch [15][3200/5332]\tlr: 1.000e-05, eta: 17:14:15, time: 2.184, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0218, s0.acc: 99.1119, s0.loss_bbox_cls: 0.0182, s0.loss_bbox_reg: 0.0450, s1.loss_cls: 0.0151, s1.acc: 98.7305, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0374, s2.loss_cls: 0.0094, s2.acc: 98.5962, s2.loss_bbox_cls: 0.0114, s2.loss_bbox_reg: 0.0241, loss: 0.2073, grad_norm: 5.6681\n",
            "2020-09-08 13:37:21,114 - mmdet - INFO - Epoch [15][3264/5332]\tlr: 1.000e-05, eta: 17:12:01, time: 2.180, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0231, s0.acc: 99.0906, s0.loss_bbox_cls: 0.0187, s0.loss_bbox_reg: 0.0446, s1.loss_cls: 0.0199, s1.acc: 98.2208, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0366, s2.loss_cls: 0.0117, s2.acc: 97.9248, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0222, loss: 0.2099, grad_norm: 6.0262\n",
            "2020-09-08 13:39:39,457 - mmdet - INFO - Epoch [15][3328/5332]\tlr: 1.000e-05, eta: 17:09:44, time: 2.162, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0234, s0.acc: 99.0936, s0.loss_bbox_cls: 0.0239, s0.loss_bbox_reg: 0.0477, s1.loss_cls: 0.0150, s1.acc: 98.9288, s1.loss_bbox_cls: 0.0189, s1.loss_bbox_reg: 0.0357, s2.loss_cls: 0.0104, s2.acc: 98.3612, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0212, loss: 0.2136, grad_norm: 5.8060\n",
            "2020-09-08 13:41:59,206 - mmdet - INFO - Epoch [15][3392/5332]\tlr: 1.000e-05, eta: 17:07:29, time: 2.184, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0190, s0.acc: 99.3622, s0.loss_bbox_cls: 0.0169, s0.loss_bbox_reg: 0.0402, s1.loss_cls: 0.0146, s1.acc: 99.0082, s1.loss_bbox_cls: 0.0151, s1.loss_bbox_reg: 0.0326, s2.loss_cls: 0.0091, s2.acc: 98.6572, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0206, loss: 0.1835, grad_norm: 5.0450\n",
            "2020-09-08 13:44:16,221 - mmdet - INFO - Epoch [15][3456/5332]\tlr: 1.000e-05, eta: 17:05:10, time: 2.141, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0231, s0.acc: 99.1211, s0.loss_bbox_cls: 0.0191, s0.loss_bbox_reg: 0.0441, s1.loss_cls: 0.0158, s1.acc: 98.9410, s1.loss_bbox_cls: 0.0172, s1.loss_bbox_reg: 0.0370, s2.loss_cls: 0.0093, s2.acc: 98.5718, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0234, loss: 0.2075, grad_norm: 5.5359\n",
            "2020-09-08 13:46:35,662 - mmdet - INFO - Epoch [15][3520/5332]\tlr: 1.000e-05, eta: 17:02:55, time: 2.179, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0227, s0.acc: 99.0906, s0.loss_bbox_cls: 0.0245, s0.loss_bbox_reg: 0.0505, s1.loss_cls: 0.0186, s1.acc: 98.6298, s1.loss_bbox_cls: 0.0199, s1.loss_bbox_reg: 0.0385, s2.loss_cls: 0.0127, s2.acc: 97.8546, s2.loss_bbox_cls: 0.0115, s2.loss_bbox_reg: 0.0233, loss: 0.2309, grad_norm: 6.1470\n",
            "2020-09-08 13:48:54,832 - mmdet - INFO - Epoch [15][3584/5332]\tlr: 1.000e-05, eta: 17:00:39, time: 2.175, data_time: 0.005, memory: 8090, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0227, s0.acc: 99.0845, s0.loss_bbox_cls: 0.0228, s0.loss_bbox_reg: 0.0479, s1.loss_cls: 0.0161, s1.acc: 98.6847, s1.loss_bbox_cls: 0.0195, s1.loss_bbox_reg: 0.0386, s2.loss_cls: 0.0102, s2.acc: 98.3215, s2.loss_bbox_cls: 0.0124, s2.loss_bbox_reg: 0.0236, loss: 0.2223, grad_norm: 5.8186\n",
            "2020-09-08 13:51:12,599 - mmdet - INFO - Epoch [15][3648/5332]\tlr: 1.000e-05, eta: 16:58:21, time: 2.153, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0248, s0.acc: 99.0784, s0.loss_bbox_cls: 0.0214, s0.loss_bbox_reg: 0.0442, s1.loss_cls: 0.0166, s1.acc: 98.6877, s1.loss_bbox_cls: 0.0184, s1.loss_bbox_reg: 0.0358, s2.loss_cls: 0.0098, s2.acc: 98.5046, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0216, loss: 0.2136, grad_norm: 5.6148\n",
            "2020-09-08 13:53:31,326 - mmdet - INFO - Epoch [15][3712/5332]\tlr: 1.000e-05, eta: 16:56:04, time: 2.168, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0259, s0.acc: 98.9136, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0434, s1.loss_cls: 0.0213, s1.acc: 98.1232, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0340, s2.loss_cls: 0.0138, s2.acc: 97.5006, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0203, loss: 0.2176, grad_norm: 5.7427\n",
            "2020-09-08 13:55:49,531 - mmdet - INFO - Epoch [15][3776/5332]\tlr: 1.000e-05, eta: 16:53:47, time: 2.159, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0062, s0.loss_cls: 0.0291, s0.acc: 98.9197, s0.loss_bbox_cls: 0.0222, s0.loss_bbox_reg: 0.0463, s1.loss_cls: 0.0196, s1.acc: 98.6176, s1.loss_bbox_cls: 0.0164, s1.loss_bbox_reg: 0.0335, s2.loss_cls: 0.0107, s2.acc: 98.2483, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0195, loss: 0.2172, grad_norm: 5.6576\n",
            "2020-09-08 13:58:06,452 - mmdet - INFO - Epoch [15][3840/5332]\tlr: 1.000e-05, eta: 16:51:27, time: 2.139, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0198, s0.acc: 99.2401, s0.loss_bbox_cls: 0.0180, s0.loss_bbox_reg: 0.0371, s1.loss_cls: 0.0151, s1.acc: 98.7061, s1.loss_bbox_cls: 0.0139, s1.loss_bbox_reg: 0.0272, s2.loss_cls: 0.0096, s2.acc: 98.3551, s2.loss_bbox_cls: 0.0073, s2.loss_bbox_reg: 0.0155, loss: 0.1708, grad_norm: 4.8855\n",
            "2020-09-08 14:00:24,234 - mmdet - INFO - Epoch [15][3904/5332]\tlr: 1.000e-05, eta: 16:49:08, time: 2.153, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0253, s0.acc: 99.0479, s0.loss_bbox_cls: 0.0174, s0.loss_bbox_reg: 0.0380, s1.loss_cls: 0.0196, s1.acc: 98.4314, s1.loss_bbox_cls: 0.0142, s1.loss_bbox_reg: 0.0296, s2.loss_cls: 0.0119, s2.acc: 98.0194, s2.loss_bbox_cls: 0.0073, s2.loss_bbox_reg: 0.0181, loss: 0.1919, grad_norm: 5.2940\n",
            "2020-09-08 14:02:41,245 - mmdet - INFO - Epoch [15][3968/5332]\tlr: 1.000e-05, eta: 16:46:49, time: 2.141, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0025, s0.loss_cls: 0.0205, s0.acc: 99.2249, s0.loss_bbox_cls: 0.0179, s0.loss_bbox_reg: 0.0382, s1.loss_cls: 0.0136, s1.acc: 99.0173, s1.loss_bbox_cls: 0.0163, s1.loss_bbox_reg: 0.0305, s2.loss_cls: 0.0088, s2.acc: 98.7732, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0180, loss: 0.1799, grad_norm: 5.0157\n",
            "2020-09-08 14:05:00,563 - mmdet - INFO - Epoch [15][4032/5332]\tlr: 1.000e-05, eta: 16:44:33, time: 2.177, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0271, s0.acc: 98.9288, s0.loss_bbox_cls: 0.0211, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0194, s1.acc: 98.4680, s1.loss_bbox_cls: 0.0169, s1.loss_bbox_reg: 0.0350, s2.loss_cls: 0.0122, s2.acc: 97.9614, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0206, loss: 0.2139, grad_norm: 5.8376\n",
            "2020-09-08 14:07:19,517 - mmdet - INFO - Epoch [15][4096/5332]\tlr: 1.000e-05, eta: 16:42:17, time: 2.171, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0279, s0.acc: 98.9899, s0.loss_bbox_cls: 0.0197, s0.loss_bbox_reg: 0.0426, s1.loss_cls: 0.0191, s1.acc: 98.5229, s1.loss_bbox_cls: 0.0159, s1.loss_bbox_reg: 0.0320, s2.loss_cls: 0.0109, s2.acc: 98.1964, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0199, loss: 0.2070, grad_norm: 5.6975\n",
            "2020-09-08 14:09:36,654 - mmdet - INFO - Epoch [15][4160/5332]\tlr: 1.000e-05, eta: 16:39:58, time: 2.143, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0231, s0.acc: 99.1058, s0.loss_bbox_cls: 0.0216, s0.loss_bbox_reg: 0.0439, s1.loss_cls: 0.0163, s1.acc: 98.6511, s1.loss_bbox_cls: 0.0174, s1.loss_bbox_reg: 0.0337, s2.loss_cls: 0.0103, s2.acc: 98.4009, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0212, loss: 0.2046, grad_norm: 5.1534\n",
            "2020-09-08 14:11:54,238 - mmdet - INFO - Epoch [15][4224/5332]\tlr: 1.000e-05, eta: 16:37:39, time: 2.150, data_time: 0.004, memory: 8090, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0211, s0.acc: 99.1669, s0.loss_bbox_cls: 0.0217, s0.loss_bbox_reg: 0.0439, s1.loss_cls: 0.0153, s1.acc: 98.7000, s1.loss_bbox_cls: 0.0181, s1.loss_bbox_reg: 0.0356, s2.loss_cls: 0.0099, s2.acc: 98.3826, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0194, loss: 0.2038, grad_norm: 5.2548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3n9iHo5I4ne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be71127a-fd18-4b54-8b18-63fd0ba7b201"
      },
      "source": [
        "!python tools/train.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py --resume-from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_14.pth"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-08 14:37:09,324 - mmdet - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]\n",
            "CUDA available: True\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
            "GPU 0: Tesla P100-PCIE-16GB\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.4.0\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CUDA Runtime 10.0\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.1\n",
            "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "TorchVision: 0.5.0\n",
            "OpenCV: 4.4.0\n",
            "MMCV: 1.1.2\n",
            "MMDetection: 2.3.0+\n",
            "MMDetection Compiler: GCC 7.5\n",
            "MMDetection CUDA Compiler: 10.1\n",
            "------------------------------------------------------------\n",
            "\n",
            "2020-09-08 14:37:10,005 - mmdet - INFO - Distributed training: False\n",
            "2020-09-08 14:37:10,699 - mmdet - INFO - Config:\n",
            "model = dict(\n",
            "    type='CascadeRCNN',\n",
            "    pretrained='open-mmlab://resnext101_32x4d',\n",
            "    backbone=dict(\n",
            "        type='DetectoRS_ResNeXt',\n",
            "        depth=101,\n",
            "        groups=32,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch',\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(False, True, True, True),\n",
            "        output_img=True),\n",
            "    neck=dict(\n",
            "        type='RFP',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5,\n",
            "        rfp_steps=2,\n",
            "        aspp_out_channels=64,\n",
            "        aspp_dilations=(1, 3, 6, 1),\n",
            "        rfp_backbone=dict(\n",
            "            rfp_inplanes=256,\n",
            "            type='DetectoRS_ResNeXt',\n",
            "            depth=101,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(False, True, True, True),\n",
            "            pretrained='open-mmlab://resnext101_32x4d',\n",
            "            style='pytorch')),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(\n",
            "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='CascadeRoIHead',\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[1, 0.5, 0.25],\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='GenericRoIExtractor',\n",
            "            aggregation='sum',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32],\n",
            "            pre_cfg=dict(\n",
            "                type='ConvModule',\n",
            "                in_channels=256,\n",
            "                out_channels=256,\n",
            "                kernel_size=5,\n",
            "                padding=2,\n",
            "                inplace=False),\n",
            "            post_cfg=dict(\n",
            "                type='GeneralizedAttention',\n",
            "                in_channels=256,\n",
            "                spatial_range=-1,\n",
            "                num_heads=6,\n",
            "                attention_type='0100',\n",
            "                kv_stride=2)),\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.7),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.5),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.3),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0))\n",
            "        ]))\n",
            "train_cfg = dict(\n",
            "    rpn=dict(\n",
            "        assigner=dict(\n",
            "            type='MaxIoUAssigner',\n",
            "            pos_iou_thr=0.7,\n",
            "            neg_iou_thr=0.3,\n",
            "            min_pos_iou=0.3,\n",
            "            match_low_quality=True,\n",
            "            ignore_iof_thr=-1),\n",
            "        sampler=dict(\n",
            "            type='RandomSampler',\n",
            "            num=256,\n",
            "            pos_fraction=0.5,\n",
            "            neg_pos_ub=-1,\n",
            "            add_gt_as_proposals=False),\n",
            "        allowed_border=0,\n",
            "        pos_weight=-1,\n",
            "        debug=False),\n",
            "    rpn_proposal=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=2000,\n",
            "        nms_post=2000,\n",
            "        max_num=2000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=[\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.6,\n",
            "                neg_iou_thr=0.6,\n",
            "                min_pos_iou=0.6,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.7,\n",
            "                min_pos_iou=0.7,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)\n",
            "    ])\n",
            "test_cfg = dict(\n",
            "    rpn=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=1000,\n",
            "        nms_post=1000,\n",
            "        max_num=1000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=dict(\n",
            "        score_thr=0.05,\n",
            "        nms=dict(type='nms', iou_threshold=0.5),\n",
            "        max_per_img=100))\n",
            "dataset_type = 'CustomDataset'\n",
            "data_root = 'data/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "albu_train_transforms = [\n",
            "    dict(\n",
            "        type='ShiftScaleRotate',\n",
            "        shift_limit=0.0625,\n",
            "        scale_limit=0.0,\n",
            "        rotate_limit=0,\n",
            "        interpolation=1,\n",
            "        p=0.5),\n",
            "    dict(\n",
            "        type='RandomBrightnessContrast',\n",
            "        brightness_limit=[0.1, 0.3],\n",
            "        contrast_limit=[0.1, 0.3],\n",
            "        p=0.2),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='RGBShift',\n",
            "                r_shift_limit=10,\n",
            "                g_shift_limit=10,\n",
            "                b_shift_limit=10,\n",
            "                p=1.0),\n",
            "            dict(\n",
            "                type='HueSaturationValue',\n",
            "                hue_shift_limit=20,\n",
            "                sat_shift_limit=30,\n",
            "                val_shift_limit=20,\n",
            "                p=1.0)\n",
            "        ],\n",
            "        p=0.1),\n",
            "    dict(type='JpegCompression', quality_lower=85, quality_upper=95, p=0.2),\n",
            "    dict(type='ChannelShuffle', p=0.1),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "        ],\n",
            "        p=0.1)\n",
            "]\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        type='Resize',\n",
            "        multiscale_mode='range',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(\n",
            "        type='Albu',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='ShiftScaleRotate',\n",
            "                shift_limit=0.0625,\n",
            "                scale_limit=0.0,\n",
            "                rotate_limit=0,\n",
            "                interpolation=1,\n",
            "                p=0.5),\n",
            "            dict(\n",
            "                type='RandomBrightnessContrast',\n",
            "                brightness_limit=[0.1, 0.3],\n",
            "                contrast_limit=[0.1, 0.3],\n",
            "                p=0.2),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='RGBShift',\n",
            "                        r_shift_limit=10,\n",
            "                        g_shift_limit=10,\n",
            "                        b_shift_limit=10,\n",
            "                        p=1.0),\n",
            "                    dict(\n",
            "                        type='HueSaturationValue',\n",
            "                        hue_shift_limit=20,\n",
            "                        sat_shift_limit=30,\n",
            "                        val_shift_limit=20,\n",
            "                        p=1.0)\n",
            "                ],\n",
            "                p=0.1),\n",
            "            dict(\n",
            "                type='JpegCompression',\n",
            "                quality_lower=85,\n",
            "                quality_upper=95,\n",
            "                p=0.2),\n",
            "            dict(type='ChannelShuffle', p=0.1),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                    dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                ],\n",
            "                p=0.1)\n",
            "        ],\n",
            "        bbox_params=dict(\n",
            "            type='BboxParams',\n",
            "            format='pascal_voc',\n",
            "            label_fields=['gt_labels'],\n",
            "            min_visibility=0.0,\n",
            "            filter_lost_elements=True),\n",
            "        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "        update_pad_shape=False,\n",
            "        skip_img_without_anno=True),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(\n",
            "        type='Collect',\n",
            "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "        meta_keys=('filename', 'ori_shape', 'img_shape', 'img_norm_cfg',\n",
            "                   'pad_shape', 'scale_factor'))\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        transforms=[\n",
            "            dict(type='Resize', multiscale_mode='range', keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=1.0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=1,\n",
            "    workers_per_gpu=1,\n",
            "    train=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/train_80_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                multiscale_mode='range',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(\n",
            "                type='Albu',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='ShiftScaleRotate',\n",
            "                        shift_limit=0.0625,\n",
            "                        scale_limit=0.0,\n",
            "                        rotate_limit=0,\n",
            "                        interpolation=1,\n",
            "                        p=0.5),\n",
            "                    dict(\n",
            "                        type='RandomBrightnessContrast',\n",
            "                        brightness_limit=[0.1, 0.3],\n",
            "                        contrast_limit=[0.1, 0.3],\n",
            "                        p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(\n",
            "                                type='RGBShift',\n",
            "                                r_shift_limit=10,\n",
            "                                g_shift_limit=10,\n",
            "                                b_shift_limit=10,\n",
            "                                p=1.0),\n",
            "                            dict(\n",
            "                                type='HueSaturationValue',\n",
            "                                hue_shift_limit=20,\n",
            "                                sat_shift_limit=30,\n",
            "                                val_shift_limit=20,\n",
            "                                p=1.0)\n",
            "                        ],\n",
            "                        p=0.1),\n",
            "                    dict(\n",
            "                        type='JpegCompression',\n",
            "                        quality_lower=75,\n",
            "                        quality_upper=95,\n",
            "                        p=0.2),\n",
            "                    dict(type='ChannelShuffle', p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                        ],\n",
            "                        p=0.1)\n",
            "                ],\n",
            "                bbox_params=dict(\n",
            "                    type='BboxParams',\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=['gt_labels'],\n",
            "                    min_visibility=0.0,\n",
            "                    filter_lost_elements=True),\n",
            "                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "                update_pad_shape=False,\n",
            "                skip_img_without_anno=True),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "                meta_keys=('filename', 'ori_shape', 'img_shape',\n",
            "                           'img_norm_cfg', 'pad_shape', 'scale_factor'))\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/val_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/test_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 200), (1999, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=1, metric='mAP')\n",
            "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.3333333333333333,\n",
            "    step=[8, 11])\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=64, hooks=[dict(type='TextLoggerHook')])\n",
            "total_epochs = 20\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "work_dir = './work_dirs/cascade_rcnn_x101_32x4d_fpn_1x'\n",
            "load_from = None\n",
            "resume_from = 'work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_14.pth'\n",
            "workflow = [('train', 1)]\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "2020-09-08 14:37:14,914 - mmdet - INFO - load model from: open-mmlab://resnext101_32x4d\n",
            "Downloading: \"https://openmmlab.oss-accelerate.aliyuncs.com/pretrain/third_party/resnext101_32x4d-a5af3160.pth\" to /root/.cache/torch/checkpoints/resnext101_32x4d-a5af3160.pth\n",
            "100% 161M/161M [00:07<00:00, 23.8MB/s]\n",
            "2020-09-08 14:37:23,073 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "2020-09-08 14:37:23,641 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
            "size mismatch for layer1.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.2.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
            "size mismatch for layer2.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.0.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.1.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.1.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.2.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.2.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.2.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.3.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.3.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.3.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
            "size mismatch for layer3.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.2.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.3.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.3.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.3.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.4.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.4.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.4.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.5.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.5.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.5.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.6.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.6.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.6.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.7.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.7.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.7.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.8.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.8.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.8.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.9.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.9.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.9.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.10.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.10.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.10.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.11.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.11.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.11.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.12.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.12.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.12.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.13.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.13.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.13.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.14.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.14.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.14.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.15.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.15.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.15.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.16.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.16.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.16.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.17.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.17.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.17.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.18.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.18.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.18.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.19.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.19.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.19.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.20.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.20.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.20.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.21.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.21.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.21.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.22.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.22.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.22.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
            "size mismatch for layer4.0.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.0.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.1.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.1.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.2.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.2.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.2.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-08 14:37:29,274 - mmdet - INFO - load checkpoint from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_14.pth\n",
            "2020-09-08 14:37:46,980 - mmdet - INFO - resumed epoch 14, iter 74648\n",
            "2020-09-08 14:37:46,985 - mmdet - INFO - Start running, host: root@be179207fca4, work_dir: /content/drive/My Drive/mmdetection-master/work_dirs/cascade_rcnn_x101_32x4d_fpn_1x\n",
            "2020-09-08 14:37:46,986 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs\n",
            "2020-09-08 14:39:55,195 - mmdet - INFO - Epoch [15][64/5332]\tlr: 1.000e-05, eta: 17:45:53, time: 2.003, data_time: 0.050, memory: 8907, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0222, s0.acc: 99.1119, s0.loss_bbox_cls: 0.0190, s0.loss_bbox_reg: 0.0403, s1.loss_cls: 0.0159, s1.acc: 98.6237, s1.loss_bbox_cls: 0.0164, s1.loss_bbox_reg: 0.0330, s2.loss_cls: 0.0090, s2.acc: 98.3673, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0206, loss: 0.1970, grad_norm: 5.6005\n",
            "2020-09-08 14:42:01,341 - mmdet - INFO - Epoch [15][128/5332]\tlr: 1.000e-05, eta: 17:35:15, time: 1.971, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0103, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0259, s0.acc: 98.9563, s0.loss_bbox_cls: 0.0194, s0.loss_bbox_reg: 0.0413, s1.loss_cls: 0.0183, s1.acc: 98.6084, s1.loss_bbox_cls: 0.0144, s1.loss_bbox_reg: 0.0297, s2.loss_cls: 0.0112, s2.acc: 98.1445, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0187, loss: 0.2034, grad_norm: 5.8820\n",
            "2020-09-08 14:44:07,455 - mmdet - INFO - Epoch [15][192/5332]\tlr: 1.000e-05, eta: 17:30:12, time: 1.971, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0293, s0.acc: 98.8831, s0.loss_bbox_cls: 0.0231, s0.loss_bbox_reg: 0.0512, s1.loss_cls: 0.0227, s1.acc: 98.1567, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0408, s2.loss_cls: 0.0126, s2.acc: 97.9401, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0252, loss: 0.2407, grad_norm: 6.1410\n",
            "2020-09-08 14:46:12,204 - mmdet - INFO - Epoch [15][256/5332]\tlr: 1.000e-05, eta: 17:23:49, time: 1.949, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0185, s0.acc: 99.3500, s0.loss_bbox_cls: 0.0170, s0.loss_bbox_reg: 0.0397, s1.loss_cls: 0.0149, s1.acc: 98.8586, s1.loss_bbox_cls: 0.0159, s1.loss_bbox_reg: 0.0322, s2.loss_cls: 0.0110, s2.acc: 98.3215, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0211, loss: 0.1860, grad_norm: 5.3316\n",
            "2020-09-08 14:48:17,206 - mmdet - INFO - Epoch [15][320/5332]\tlr: 1.000e-05, eta: 17:19:34, time: 1.953, data_time: 0.005, memory: 8979, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0284, s0.acc: 99.0326, s0.loss_bbox_cls: 0.0241, s0.loss_bbox_reg: 0.0465, s1.loss_cls: 0.0193, s1.acc: 98.7183, s1.loss_bbox_cls: 0.0166, s1.loss_bbox_reg: 0.0326, s2.loss_cls: 0.0116, s2.acc: 98.3551, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0197, loss: 0.2185, grad_norm: 5.4537\n",
            "2020-09-08 14:50:22,402 - mmdet - INFO - Epoch [15][384/5332]\tlr: 1.000e-05, eta: 17:16:19, time: 1.956, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0257, s0.acc: 99.0509, s0.loss_bbox_cls: 0.0190, s0.loss_bbox_reg: 0.0434, s1.loss_cls: 0.0172, s1.acc: 98.5443, s1.loss_bbox_cls: 0.0148, s1.loss_bbox_reg: 0.0326, s2.loss_cls: 0.0108, s2.acc: 98.1323, s2.loss_bbox_cls: 0.0084, s2.loss_bbox_reg: 0.0197, loss: 0.1979, grad_norm: 5.2873\n",
            "2020-09-08 14:52:27,832 - mmdet - INFO - Epoch [15][448/5332]\tlr: 1.000e-05, eta: 17:13:39, time: 1.960, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0205, s0.acc: 99.1364, s0.loss_bbox_cls: 0.0176, s0.loss_bbox_reg: 0.0371, s1.loss_cls: 0.0157, s1.acc: 98.7122, s1.loss_bbox_cls: 0.0143, s1.loss_bbox_reg: 0.0296, s2.loss_cls: 0.0094, s2.acc: 98.4039, s2.loss_bbox_cls: 0.0080, s2.loss_bbox_reg: 0.0170, loss: 0.1755, grad_norm: 4.9970\n",
            "2020-09-08 14:54:33,214 - mmdet - INFO - Epoch [15][512/5332]\tlr: 1.000e-05, eta: 17:11:06, time: 1.959, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0268, s0.acc: 98.9716, s0.loss_bbox_cls: 0.0244, s0.loss_bbox_reg: 0.0506, s1.loss_cls: 0.0206, s1.acc: 98.2788, s1.loss_bbox_cls: 0.0190, s1.loss_bbox_reg: 0.0392, s2.loss_cls: 0.0117, s2.acc: 97.8027, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0219, loss: 0.2333, grad_norm: 5.9549\n",
            "2020-09-08 14:56:38,532 - mmdet - INFO - Epoch [15][576/5332]\tlr: 1.000e-05, eta: 17:08:35, time: 1.958, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0314, s0.acc: 98.7915, s0.loss_bbox_cls: 0.0283, s0.loss_bbox_reg: 0.0547, s1.loss_cls: 0.0204, s1.acc: 98.1110, s1.loss_bbox_cls: 0.0208, s1.loss_bbox_reg: 0.0395, s2.loss_cls: 0.0129, s2.acc: 97.5769, s2.loss_bbox_cls: 0.0117, s2.loss_bbox_reg: 0.0225, loss: 0.2516, grad_norm: 6.1150\n",
            "2020-09-08 14:58:43,423 - mmdet - INFO - Epoch [15][640/5332]\tlr: 1.000e-05, eta: 17:05:48, time: 1.951, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0296, s0.acc: 98.9166, s0.loss_bbox_cls: 0.0224, s0.loss_bbox_reg: 0.0462, s1.loss_cls: 0.0216, s1.acc: 98.2361, s1.loss_bbox_cls: 0.0184, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0121, s2.acc: 97.9919, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0204, loss: 0.2248, grad_norm: 5.9330\n",
            "2020-09-08 15:00:50,075 - mmdet - INFO - Epoch [15][704/5332]\tlr: 1.000e-05, eta: 17:04:28, time: 1.979, data_time: 0.005, memory: 8979, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0292, s0.acc: 99.0112, s0.loss_bbox_cls: 0.0234, s0.loss_bbox_reg: 0.0528, s1.loss_cls: 0.0200, s1.acc: 98.5992, s1.loss_bbox_cls: 0.0198, s1.loss_bbox_reg: 0.0411, s2.loss_cls: 0.0114, s2.acc: 98.2788, s2.loss_bbox_cls: 0.0115, s2.loss_bbox_reg: 0.0244, loss: 0.2429, grad_norm: 6.3796\n",
            "2020-09-08 15:02:57,130 - mmdet - INFO - Epoch [15][768/5332]\tlr: 1.000e-05, eta: 17:03:16, time: 1.985, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0064, s0.loss_cls: 0.0240, s0.acc: 99.0845, s0.loss_bbox_cls: 0.0220, s0.loss_bbox_reg: 0.0425, s1.loss_cls: 0.0179, s1.acc: 98.5901, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0329, s2.loss_cls: 0.0109, s2.acc: 98.2697, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0183, loss: 0.2043, grad_norm: 4.9720\n",
            "2020-09-08 15:05:03,034 - mmdet - INFO - Epoch [15][832/5332]\tlr: 1.000e-05, eta: 17:01:12, time: 1.967, data_time: 0.005, memory: 8979, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0268, s0.acc: 99.0204, s0.loss_bbox_cls: 0.0208, s0.loss_bbox_reg: 0.0493, s1.loss_cls: 0.0177, s1.acc: 98.6572, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0375, s2.loss_cls: 0.0095, s2.acc: 98.4924, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0236, loss: 0.2226, grad_norm: 5.7875\n",
            "2020-09-08 15:07:08,467 - mmdet - INFO - Epoch [15][896/5332]\tlr: 1.000e-05, eta: 16:58:52, time: 1.960, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0026, s0.loss_cls: 0.0206, s0.acc: 99.1669, s0.loss_bbox_cls: 0.0165, s0.loss_bbox_reg: 0.0408, s1.loss_cls: 0.0135, s1.acc: 98.8922, s1.loss_bbox_cls: 0.0155, s1.loss_bbox_reg: 0.0348, s2.loss_cls: 0.0089, s2.acc: 98.6176, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0225, loss: 0.1883, grad_norm: 5.3336\n",
            "2020-09-08 15:09:12,603 - mmdet - INFO - Epoch [15][960/5332]\tlr: 1.000e-05, eta: 16:55:51, time: 1.940, data_time: 0.005, memory: 8979, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0292, s0.acc: 98.8617, s0.loss_bbox_cls: 0.0267, s0.loss_bbox_reg: 0.0540, s1.loss_cls: 0.0196, s1.acc: 98.5443, s1.loss_bbox_cls: 0.0207, s1.loss_bbox_reg: 0.0401, s2.loss_cls: 0.0110, s2.acc: 98.3826, s2.loss_bbox_cls: 0.0121, s2.loss_bbox_reg: 0.0237, loss: 0.2513, grad_norm: 6.2328\n",
            "2020-09-08 15:11:18,649 - mmdet - INFO - Epoch [15][1024/5332]\tlr: 1.000e-05, eta: 16:53:56, time: 1.969, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0026, s0.loss_cls: 0.0213, s0.acc: 99.1608, s0.loss_bbox_cls: 0.0206, s0.loss_bbox_reg: 0.0442, s1.loss_cls: 0.0160, s1.acc: 98.7366, s1.loss_bbox_cls: 0.0160, s1.loss_bbox_reg: 0.0332, s2.loss_cls: 0.0092, s2.acc: 98.7671, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0198, loss: 0.1955, grad_norm: 5.6994\n",
            "2020-09-08 15:13:24,584 - mmdet - INFO - Epoch [15][1088/5332]\tlr: 1.000e-05, eta: 16:51:56, time: 1.968, data_time: 0.005, memory: 8979, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0211, s0.acc: 99.1150, s0.loss_bbox_cls: 0.0237, s0.loss_bbox_reg: 0.0487, s1.loss_cls: 0.0151, s1.acc: 98.8251, s1.loss_bbox_cls: 0.0200, s1.loss_bbox_reg: 0.0387, s2.loss_cls: 0.0096, s2.acc: 98.4344, s2.loss_bbox_cls: 0.0123, s2.loss_bbox_reg: 0.0230, loss: 0.2203, grad_norm: 5.8509\n",
            "2020-09-08 15:15:30,656 - mmdet - INFO - Epoch [15][1152/5332]\tlr: 1.000e-05, eta: 16:49:59, time: 1.970, data_time: 0.005, memory: 8979, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0209, s0.acc: 99.2065, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0450, s1.loss_cls: 0.0161, s1.acc: 98.7335, s1.loss_bbox_cls: 0.0172, s1.loss_bbox_reg: 0.0341, s2.loss_cls: 0.0111, s2.acc: 98.2239, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0208, loss: 0.2028, grad_norm: 5.4976\n",
            "2020-09-08 15:17:36,265 - mmdet - INFO - Epoch [15][1216/5332]\tlr: 1.000e-05, eta: 16:47:50, time: 1.963, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0224, s0.acc: 99.0448, s0.loss_bbox_cls: 0.0216, s0.loss_bbox_reg: 0.0436, s1.loss_cls: 0.0169, s1.acc: 98.6145, s1.loss_bbox_cls: 0.0166, s1.loss_bbox_reg: 0.0324, s2.loss_cls: 0.0099, s2.acc: 98.4467, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0199, loss: 0.2014, grad_norm: 5.2408\n",
            "2020-09-08 15:19:43,234 - mmdet - INFO - Epoch [15][1280/5332]\tlr: 1.000e-05, eta: 16:46:13, time: 1.984, data_time: 0.005, memory: 8979, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0283, s0.acc: 98.9166, s0.loss_bbox_cls: 0.0205, s0.loss_bbox_reg: 0.0431, s1.loss_cls: 0.0224, s1.acc: 98.1415, s1.loss_bbox_cls: 0.0175, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0156, s2.acc: 97.2626, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0210, loss: 0.2206, grad_norm: 6.4932\n",
            "2020-09-08 15:21:48,201 - mmdet - INFO - Epoch [15][1344/5332]\tlr: 1.000e-05, eta: 16:43:48, time: 1.953, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0218, s0.acc: 99.0814, s0.loss_bbox_cls: 0.0212, s0.loss_bbox_reg: 0.0440, s1.loss_cls: 0.0153, s1.acc: 98.7335, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0335, s2.loss_cls: 0.0102, s2.acc: 98.1873, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0206, loss: 0.2031, grad_norm: 5.6424\n",
            "2020-09-08 15:23:55,414 - mmdet - INFO - Epoch [15][1408/5332]\tlr: 1.000e-05, eta: 16:42:14, time: 1.988, data_time: 0.005, memory: 8979, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0291, s0.acc: 98.9075, s0.loss_bbox_cls: 0.0256, s0.loss_bbox_reg: 0.0494, s1.loss_cls: 0.0188, s1.acc: 98.6267, s1.loss_bbox_cls: 0.0193, s1.loss_bbox_reg: 0.0365, s2.loss_cls: 0.0120, s2.acc: 98.0896, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0203, loss: 0.2281, grad_norm: 5.8232\n",
            "2020-09-08 15:26:01,922 - mmdet - INFO - Epoch [15][1472/5332]\tlr: 1.000e-05, eta: 16:40:22, time: 1.977, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0237, s0.acc: 99.0295, s0.loss_bbox_cls: 0.0181, s0.loss_bbox_reg: 0.0417, s1.loss_cls: 0.0178, s1.acc: 98.6298, s1.loss_bbox_cls: 0.0151, s1.loss_bbox_reg: 0.0318, s2.loss_cls: 0.0108, s2.acc: 98.2361, s2.loss_bbox_cls: 0.0087, s2.loss_bbox_reg: 0.0193, loss: 0.1934, grad_norm: 5.0507\n",
            "2020-09-08 15:28:08,916 - mmdet - INFO - Epoch [15][1536/5332]\tlr: 1.000e-05, eta: 16:38:38, time: 1.984, data_time: 0.005, memory: 8979, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0231, s0.acc: 99.1272, s0.loss_bbox_cls: 0.0225, s0.loss_bbox_reg: 0.0459, s1.loss_cls: 0.0169, s1.acc: 98.6481, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0370, s2.loss_cls: 0.0101, s2.acc: 98.4100, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0228, loss: 0.2144, grad_norm: 5.7967\n",
            "2020-09-08 15:30:13,291 - mmdet - INFO - Epoch [15][1600/5332]\tlr: 1.000e-05, eta: 16:36:03, time: 1.943, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0264, s0.acc: 99.0326, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0426, s1.loss_cls: 0.0207, s1.acc: 98.1903, s1.loss_bbox_cls: 0.0188, s1.loss_bbox_reg: 0.0356, s2.loss_cls: 0.0128, s2.acc: 97.7020, s2.loss_bbox_cls: 0.0114, s2.loss_bbox_reg: 0.0212, loss: 0.2215, grad_norm: 5.5514\n",
            "2020-09-08 15:32:19,735 - mmdet - INFO - Epoch [15][1664/5332]\tlr: 1.000e-05, eta: 16:34:08, time: 1.976, data_time: 0.016, memory: 8979, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0217, s0.acc: 99.1211, s0.loss_bbox_cls: 0.0211, s0.loss_bbox_reg: 0.0465, s1.loss_cls: 0.0149, s1.acc: 98.7396, s1.loss_bbox_cls: 0.0174, s1.loss_bbox_reg: 0.0358, s2.loss_cls: 0.0098, s2.acc: 98.5016, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0208, loss: 0.2074, grad_norm: 5.4287\n",
            "2020-09-08 15:34:24,356 - mmdet - INFO - Epoch [15][1728/5332]\tlr: 1.000e-05, eta: 16:31:40, time: 1.947, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0229, s0.acc: 99.0540, s0.loss_bbox_cls: 0.0237, s0.loss_bbox_reg: 0.0511, s1.loss_cls: 0.0181, s1.acc: 98.6115, s1.loss_bbox_cls: 0.0182, s1.loss_bbox_reg: 0.0387, s2.loss_cls: 0.0107, s2.acc: 98.4070, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0219, loss: 0.2229, grad_norm: 6.2421\n",
            "2020-09-08 15:36:30,974 - mmdet - INFO - Epoch [15][1792/5332]\tlr: 1.000e-05, eta: 16:29:48, time: 1.978, data_time: 0.005, memory: 8979, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0236, s0.acc: 99.1211, s0.loss_bbox_cls: 0.0195, s0.loss_bbox_reg: 0.0435, s1.loss_cls: 0.0167, s1.acc: 98.6023, s1.loss_bbox_cls: 0.0162, s1.loss_bbox_reg: 0.0357, s2.loss_cls: 0.0092, s2.acc: 98.4070, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0202, loss: 0.1987, grad_norm: 5.5301\n",
            "2020-09-08 15:38:36,205 - mmdet - INFO - Epoch [15][1856/5332]\tlr: 1.000e-05, eta: 16:27:32, time: 1.957, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0231, s0.acc: 99.0692, s0.loss_bbox_cls: 0.0251, s0.loss_bbox_reg: 0.0470, s1.loss_cls: 0.0180, s1.acc: 98.5321, s1.loss_bbox_cls: 0.0195, s1.loss_bbox_reg: 0.0366, s2.loss_cls: 0.0116, s2.acc: 97.8577, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0211, loss: 0.2183, grad_norm: 5.7379\n",
            "2020-09-08 15:40:40,464 - mmdet - INFO - Epoch [15][1920/5332]\tlr: 1.000e-05, eta: 16:25:01, time: 1.942, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0258, s0.acc: 98.9594, s0.loss_bbox_cls: 0.0186, s0.loss_bbox_reg: 0.0402, s1.loss_cls: 0.0192, s1.acc: 98.3582, s1.loss_bbox_cls: 0.0153, s1.loss_bbox_reg: 0.0308, s2.loss_cls: 0.0122, s2.acc: 98.1018, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0192, loss: 0.2033, grad_norm: 5.7089\n",
            "2020-09-08 15:42:45,925 - mmdet - INFO - Epoch [15][1984/5332]\tlr: 1.000e-05, eta: 16:22:51, time: 1.960, data_time: 0.005, memory: 8979, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0230, s0.acc: 99.0875, s0.loss_bbox_cls: 0.0208, s0.loss_bbox_reg: 0.0435, s1.loss_cls: 0.0180, s1.acc: 98.6694, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0330, s2.loss_cls: 0.0115, s2.acc: 98.3154, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0185, loss: 0.2022, grad_norm: 5.3448\n",
            "2020-09-08 15:44:51,700 - mmdet - INFO - Epoch [15][2048/5332]\tlr: 1.000e-05, eta: 16:20:45, time: 1.965, data_time: 0.005, memory: 8979, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0333, s0.acc: 98.6603, s0.loss_bbox_cls: 0.0256, s0.loss_bbox_reg: 0.0508, s1.loss_cls: 0.0259, s1.acc: 97.7722, s1.loss_bbox_cls: 0.0213, s1.loss_bbox_reg: 0.0404, s2.loss_cls: 0.0155, s2.acc: 97.1710, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0225, loss: 0.2549, grad_norm: 6.2418\n",
            "2020-09-08 15:46:57,035 - mmdet - INFO - Epoch [15][2112/5332]\tlr: 1.000e-05, eta: 16:18:33, time: 1.958, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0214, s0.acc: 99.1302, s0.loss_bbox_cls: 0.0171, s0.loss_bbox_reg: 0.0361, s1.loss_cls: 0.0161, s1.acc: 98.7183, s1.loss_bbox_cls: 0.0140, s1.loss_bbox_reg: 0.0281, s2.loss_cls: 0.0100, s2.acc: 98.4467, s2.loss_bbox_cls: 0.0081, s2.loss_bbox_reg: 0.0174, loss: 0.1742, grad_norm: 5.1228\n",
            "2020-09-08 15:49:03,296 - mmdet - INFO - Epoch [15][2176/5332]\tlr: 1.000e-05, eta: 16:16:34, time: 1.973, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0251, s0.acc: 99.0540, s0.loss_bbox_cls: 0.0241, s0.loss_bbox_reg: 0.0473, s1.loss_cls: 0.0184, s1.acc: 98.5657, s1.loss_bbox_cls: 0.0208, s1.loss_bbox_reg: 0.0371, s2.loss_cls: 0.0116, s2.acc: 98.3063, s2.loss_bbox_cls: 0.0117, s2.loss_bbox_reg: 0.0213, loss: 0.2258, grad_norm: 5.4634\n",
            "2020-09-08 15:51:10,637 - mmdet - INFO - Epoch [15][2240/5332]\tlr: 1.000e-05, eta: 16:14:49, time: 1.990, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0224, s0.acc: 99.0631, s0.loss_bbox_cls: 0.0238, s0.loss_bbox_reg: 0.0490, s1.loss_cls: 0.0150, s1.acc: 98.7732, s1.loss_bbox_cls: 0.0205, s1.loss_bbox_reg: 0.0378, s2.loss_cls: 0.0102, s2.acc: 98.2391, s2.loss_bbox_cls: 0.0120, s2.loss_bbox_reg: 0.0230, loss: 0.2242, grad_norm: 6.0059\n",
            "2020-09-08 15:53:17,907 - mmdet - INFO - Epoch [15][2304/5332]\tlr: 1.000e-05, eta: 16:13:02, time: 1.989, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0241, s0.acc: 99.0143, s0.loss_bbox_cls: 0.0230, s0.loss_bbox_reg: 0.0436, s1.loss_cls: 0.0180, s1.acc: 98.6206, s1.loss_bbox_cls: 0.0181, s1.loss_bbox_reg: 0.0326, s2.loss_cls: 0.0123, s2.acc: 98.1201, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0201, loss: 0.2104, grad_norm: 5.6058\n",
            "2020-09-08 15:55:23,040 - mmdet - INFO - Epoch [15][2368/5332]\tlr: 1.000e-05, eta: 16:10:47, time: 1.955, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0239, s0.acc: 99.1150, s0.loss_bbox_cls: 0.0253, s0.loss_bbox_reg: 0.0464, s1.loss_cls: 0.0158, s1.acc: 98.7701, s1.loss_bbox_cls: 0.0221, s1.loss_bbox_reg: 0.0346, s2.loss_cls: 0.0098, s2.acc: 98.5718, s2.loss_bbox_cls: 0.0118, s2.loss_bbox_reg: 0.0206, loss: 0.2166, grad_norm: 5.1805\n",
            "2020-09-08 15:57:28,359 - mmdet - INFO - Epoch [15][2432/5332]\tlr: 1.000e-05, eta: 16:08:35, time: 1.958, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0245, s0.acc: 99.0173, s0.loss_bbox_cls: 0.0281, s0.loss_bbox_reg: 0.0540, s1.loss_cls: 0.0157, s1.acc: 98.6908, s1.loss_bbox_cls: 0.0225, s1.loss_bbox_reg: 0.0395, s2.loss_cls: 0.0110, s2.acc: 97.9980, s2.loss_bbox_cls: 0.0110, s2.loss_bbox_reg: 0.0225, loss: 0.2364, grad_norm: 5.4196\n",
            "2020-09-08 15:59:34,590 - mmdet - INFO - Epoch [15][2496/5332]\tlr: 1.000e-05, eta: 16:06:34, time: 1.972, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0274, s0.acc: 99.0234, s0.loss_bbox_cls: 0.0222, s0.loss_bbox_reg: 0.0469, s1.loss_cls: 0.0193, s1.acc: 98.4833, s1.loss_bbox_cls: 0.0186, s1.loss_bbox_reg: 0.0369, s2.loss_cls: 0.0117, s2.acc: 98.2452, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0212, loss: 0.2236, grad_norm: 5.3889\n",
            "2020-09-08 16:01:38,630 - mmdet - INFO - Epoch [15][2560/5332]\tlr: 1.000e-05, eta: 16:04:07, time: 1.938, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0231, s0.acc: 99.0540, s0.loss_bbox_cls: 0.0183, s0.loss_bbox_reg: 0.0394, s1.loss_cls: 0.0180, s1.acc: 98.4039, s1.loss_bbox_cls: 0.0148, s1.loss_bbox_reg: 0.0305, s2.loss_cls: 0.0109, s2.acc: 97.8760, s2.loss_bbox_cls: 0.0078, s2.loss_bbox_reg: 0.0173, loss: 0.1884, grad_norm: 5.0004\n",
            "2020-09-08 16:03:42,217 - mmdet - INFO - Epoch [15][2624/5332]\tlr: 1.000e-05, eta: 16:01:37, time: 1.931, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0218, s0.acc: 99.1394, s0.loss_bbox_cls: 0.0184, s0.loss_bbox_reg: 0.0374, s1.loss_cls: 0.0169, s1.acc: 98.6511, s1.loss_bbox_cls: 0.0138, s1.loss_bbox_reg: 0.0273, s2.loss_cls: 0.0115, s2.acc: 98.1018, s2.loss_bbox_cls: 0.0076, s2.loss_bbox_reg: 0.0169, loss: 0.1819, grad_norm: 5.0005\n",
            "2020-09-08 16:05:47,597 - mmdet - INFO - Epoch [15][2688/5332]\tlr: 1.000e-05, eta: 15:59:27, time: 1.959, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0205, s0.acc: 99.1943, s0.loss_bbox_cls: 0.0182, s0.loss_bbox_reg: 0.0413, s1.loss_cls: 0.0147, s1.acc: 98.7793, s1.loss_bbox_cls: 0.0157, s1.loss_bbox_reg: 0.0341, s2.loss_cls: 0.0098, s2.acc: 98.2208, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0214, loss: 0.1933, grad_norm: 5.8365\n",
            "2020-09-08 16:07:52,730 - mmdet - INFO - Epoch [15][2752/5332]\tlr: 1.000e-05, eta: 15:57:15, time: 1.955, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0228, s0.acc: 99.0906, s0.loss_bbox_cls: 0.0199, s0.loss_bbox_reg: 0.0433, s1.loss_cls: 0.0176, s1.acc: 98.5901, s1.loss_bbox_cls: 0.0175, s1.loss_bbox_reg: 0.0349, s2.loss_cls: 0.0098, s2.acc: 98.5718, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0205, loss: 0.2027, grad_norm: 5.4180\n",
            "2020-09-08 16:09:59,909 - mmdet - INFO - Epoch [15][2816/5332]\tlr: 1.000e-05, eta: 15:55:25, time: 1.987, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0236, s0.acc: 98.9716, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0467, s1.loss_cls: 0.0180, s1.acc: 98.5535, s1.loss_bbox_cls: 0.0203, s1.loss_bbox_reg: 0.0398, s2.loss_cls: 0.0124, s2.acc: 98.0560, s2.loss_bbox_cls: 0.0110, s2.loss_bbox_reg: 0.0223, loss: 0.2221, grad_norm: 6.2537\n",
            "2020-09-08 16:12:04,282 - mmdet - INFO - Epoch [15][2880/5332]\tlr: 1.000e-05, eta: 15:53:05, time: 1.943, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0263, s0.acc: 98.8007, s0.loss_bbox_cls: 0.0211, s0.loss_bbox_reg: 0.0456, s1.loss_cls: 0.0199, s1.acc: 98.2697, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0348, s2.loss_cls: 0.0134, s2.acc: 97.5128, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0204, loss: 0.2164, grad_norm: 5.9689\n",
            "2020-09-08 16:14:07,606 - mmdet - INFO - Epoch [15][2944/5332]\tlr: 1.000e-05, eta: 15:50:36, time: 1.927, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0072, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0260, s0.acc: 98.9929, s0.loss_bbox_cls: 0.0217, s0.loss_bbox_reg: 0.0451, s1.loss_cls: 0.0170, s1.acc: 98.7396, s1.loss_bbox_cls: 0.0181, s1.loss_bbox_reg: 0.0367, s2.loss_cls: 0.0108, s2.acc: 98.1384, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0218, loss: 0.2201, grad_norm: 5.7866\n",
            "2020-09-08 16:16:10,882 - mmdet - INFO - Epoch [15][3008/5332]\tlr: 1.000e-05, eta: 15:48:07, time: 1.926, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0235, s0.acc: 99.0570, s0.loss_bbox_cls: 0.0178, s0.loss_bbox_reg: 0.0411, s1.loss_cls: 0.0161, s1.acc: 98.7915, s1.loss_bbox_cls: 0.0163, s1.loss_bbox_reg: 0.0336, s2.loss_cls: 0.0105, s2.acc: 98.3582, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0205, loss: 0.1982, grad_norm: 5.6574\n",
            "2020-09-08 16:18:13,816 - mmdet - INFO - Epoch [15][3072/5332]\tlr: 1.000e-05, eta: 15:45:36, time: 1.921, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0290, s0.acc: 98.8342, s0.loss_bbox_cls: 0.0233, s0.loss_bbox_reg: 0.0501, s1.loss_cls: 0.0209, s1.acc: 98.3124, s1.loss_bbox_cls: 0.0205, s1.loss_bbox_reg: 0.0401, s2.loss_cls: 0.0129, s2.acc: 97.9218, s2.loss_bbox_cls: 0.0120, s2.loss_bbox_reg: 0.0233, loss: 0.2442, grad_norm: 6.5958\n",
            "2020-09-08 16:20:21,798 - mmdet - INFO - Epoch [15][3136/5332]\tlr: 1.000e-05, eta: 15:43:53, time: 2.000, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0233, s0.acc: 99.1150, s0.loss_bbox_cls: 0.0234, s0.loss_bbox_reg: 0.0494, s1.loss_cls: 0.0199, s1.acc: 98.5565, s1.loss_bbox_cls: 0.0195, s1.loss_bbox_reg: 0.0386, s2.loss_cls: 0.0143, s2.acc: 97.8149, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0220, loss: 0.2324, grad_norm: 6.5498\n",
            "2020-09-08 16:22:25,499 - mmdet - INFO - Epoch [15][3200/5332]\tlr: 1.000e-05, eta: 15:41:30, time: 1.933, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0170, s0.acc: 99.3103, s0.loss_bbox_cls: 0.0199, s0.loss_bbox_reg: 0.0437, s1.loss_cls: 0.0136, s1.acc: 98.9685, s1.loss_bbox_cls: 0.0185, s1.loss_bbox_reg: 0.0368, s2.loss_cls: 0.0099, s2.acc: 98.6877, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0234, loss: 0.2003, grad_norm: 5.0555\n",
            "2020-09-08 16:24:30,659 - mmdet - INFO - Epoch [15][3264/5332]\tlr: 1.000e-05, eta: 15:39:21, time: 1.956, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0246, s0.acc: 99.0753, s0.loss_bbox_cls: 0.0204, s0.loss_bbox_reg: 0.0426, s1.loss_cls: 0.0182, s1.acc: 98.6969, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0343, s2.loss_cls: 0.0107, s2.acc: 98.4863, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0201, loss: 0.2054, grad_norm: 5.4604\n",
            "2020-09-08 16:26:37,404 - mmdet - INFO - Epoch [15][3328/5332]\tlr: 1.000e-05, eta: 15:37:26, time: 1.980, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0087, loss_rpn_bbox: 0.0070, s0.loss_cls: 0.0275, s0.acc: 98.8647, s0.loss_bbox_cls: 0.0279, s0.loss_bbox_reg: 0.0515, s1.loss_cls: 0.0189, s1.acc: 98.3582, s1.loss_bbox_cls: 0.0220, s1.loss_bbox_reg: 0.0386, s2.loss_cls: 0.0128, s2.acc: 97.8485, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0201, loss: 0.2454, grad_norm: 6.1839\n",
            "2020-09-08 16:28:44,059 - mmdet - INFO - Epoch [15][3392/5332]\tlr: 1.000e-05, eta: 15:35:29, time: 1.979, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0266, s0.acc: 98.9105, s0.loss_bbox_cls: 0.0245, s0.loss_bbox_reg: 0.0484, s1.loss_cls: 0.0181, s1.acc: 98.6053, s1.loss_bbox_cls: 0.0201, s1.loss_bbox_reg: 0.0358, s2.loss_cls: 0.0129, s2.acc: 98.1659, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0202, loss: 0.2264, grad_norm: 5.4419\n",
            "2020-09-08 16:30:50,412 - mmdet - INFO - Epoch [15][3456/5332]\tlr: 1.000e-05, eta: 15:33:30, time: 1.974, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0222, s0.acc: 99.1058, s0.loss_bbox_cls: 0.0190, s0.loss_bbox_reg: 0.0418, s1.loss_cls: 0.0151, s1.acc: 98.8190, s1.loss_bbox_cls: 0.0162, s1.loss_bbox_reg: 0.0335, s2.loss_cls: 0.0092, s2.acc: 98.4741, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0196, loss: 0.1963, grad_norm: 5.3722\n",
            "2020-09-08 16:32:55,049 - mmdet - INFO - Epoch [15][3520/5332]\tlr: 1.000e-05, eta: 15:31:16, time: 1.947, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0242, s0.acc: 98.9868, s0.loss_bbox_cls: 0.0197, s0.loss_bbox_reg: 0.0422, s1.loss_cls: 0.0170, s1.acc: 98.5504, s1.loss_bbox_cls: 0.0151, s1.loss_bbox_reg: 0.0307, s2.loss_cls: 0.0101, s2.acc: 98.3704, s2.loss_bbox_cls: 0.0088, s2.loss_bbox_reg: 0.0188, loss: 0.1947, grad_norm: 5.3522\n",
            "2020-09-08 16:34:59,509 - mmdet - INFO - Epoch [15][3584/5332]\tlr: 1.000e-05, eta: 15:29:01, time: 1.945, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0023, s0.loss_cls: 0.0200, s0.acc: 99.2157, s0.loss_bbox_cls: 0.0196, s0.loss_bbox_reg: 0.0417, s1.loss_cls: 0.0133, s1.acc: 98.9746, s1.loss_bbox_cls: 0.0172, s1.loss_bbox_reg: 0.0339, s2.loss_cls: 0.0091, s2.acc: 98.6053, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0207, loss: 0.1908, grad_norm: 4.9313\n",
            "2020-09-08 16:37:03,962 - mmdet - INFO - Epoch [15][3648/5332]\tlr: 1.000e-05, eta: 15:26:47, time: 1.945, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0258, s0.acc: 98.8983, s0.loss_bbox_cls: 0.0220, s0.loss_bbox_reg: 0.0467, s1.loss_cls: 0.0188, s1.acc: 98.5107, s1.loss_bbox_cls: 0.0185, s1.loss_bbox_reg: 0.0348, s2.loss_cls: 0.0127, s2.acc: 97.9492, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0215, loss: 0.2204, grad_norm: 6.4572\n",
            "2020-09-08 16:39:07,785 - mmdet - INFO - Epoch [15][3712/5332]\tlr: 1.000e-05, eta: 15:24:28, time: 1.935, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0242, s0.acc: 99.0173, s0.loss_bbox_cls: 0.0219, s0.loss_bbox_reg: 0.0467, s1.loss_cls: 0.0181, s1.acc: 98.4680, s1.loss_bbox_cls: 0.0183, s1.loss_bbox_reg: 0.0364, s2.loss_cls: 0.0106, s2.acc: 98.2330, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0192, loss: 0.2107, grad_norm: 5.6867\n",
            "2020-09-08 16:41:11,193 - mmdet - INFO - Epoch [15][3776/5332]\tlr: 1.000e-05, eta: 15:22:07, time: 1.928, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0178, s0.acc: 99.3378, s0.loss_bbox_cls: 0.0195, s0.loss_bbox_reg: 0.0418, s1.loss_cls: 0.0145, s1.acc: 98.8525, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0338, s2.loss_cls: 0.0104, s2.acc: 98.0835, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0202, loss: 0.1892, grad_norm: 5.2730\n",
            "2020-09-08 16:43:17,134 - mmdet - INFO - Epoch [15][3840/5332]\tlr: 1.000e-05, eta: 15:20:05, time: 1.968, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0250, s0.acc: 98.9563, s0.loss_bbox_cls: 0.0197, s0.loss_bbox_reg: 0.0438, s1.loss_cls: 0.0189, s1.acc: 98.5626, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0126, s2.acc: 97.9523, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0203, loss: 0.2087, grad_norm: 5.8058\n",
            "2020-09-08 16:45:23,638 - mmdet - INFO - Epoch [15][3904/5332]\tlr: 1.000e-05, eta: 15:18:06, time: 1.977, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0279, s0.acc: 98.9014, s0.loss_bbox_cls: 0.0225, s0.loss_bbox_reg: 0.0480, s1.loss_cls: 0.0206, s1.acc: 98.4253, s1.loss_bbox_cls: 0.0189, s1.loss_bbox_reg: 0.0370, s2.loss_cls: 0.0127, s2.acc: 98.0621, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0215, loss: 0.2272, grad_norm: 5.8148\n",
            "2020-09-08 16:47:29,379 - mmdet - INFO - Epoch [15][3968/5332]\tlr: 1.000e-05, eta: 15:16:02, time: 1.965, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0215, s0.acc: 99.1730, s0.loss_bbox_cls: 0.0200, s0.loss_bbox_reg: 0.0452, s1.loss_cls: 0.0153, s1.acc: 98.7793, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0103, s2.acc: 98.2849, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0220, loss: 0.2054, grad_norm: 5.5619\n",
            "2020-09-08 16:49:33,654 - mmdet - INFO - Epoch [15][4032/5332]\tlr: 1.000e-05, eta: 15:13:48, time: 1.942, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0026, s0.loss_cls: 0.0213, s0.acc: 99.1425, s0.loss_bbox_cls: 0.0230, s0.loss_bbox_reg: 0.0461, s1.loss_cls: 0.0154, s1.acc: 98.7427, s1.loss_bbox_cls: 0.0211, s1.loss_bbox_reg: 0.0391, s2.loss_cls: 0.0132, s2.acc: 97.8729, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0220, loss: 0.2177, grad_norm: 5.4078\n",
            "2020-09-08 16:51:38,392 - mmdet - INFO - Epoch [15][4096/5332]\tlr: 1.000e-05, eta: 15:11:37, time: 1.949, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0201, s0.acc: 99.1974, s0.loss_bbox_cls: 0.0204, s0.loss_bbox_reg: 0.0421, s1.loss_cls: 0.0175, s1.acc: 98.5779, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0323, s2.loss_cls: 0.0116, s2.acc: 98.0621, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0205, loss: 0.1988, grad_norm: 5.5698\n",
            "2020-09-08 16:53:43,441 - mmdet - INFO - Epoch [15][4160/5332]\tlr: 1.000e-05, eta: 15:09:29, time: 1.954, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0245, s0.acc: 99.0356, s0.loss_bbox_cls: 0.0210, s0.loss_bbox_reg: 0.0436, s1.loss_cls: 0.0179, s1.acc: 98.5687, s1.loss_bbox_cls: 0.0161, s1.loss_bbox_reg: 0.0339, s2.loss_cls: 0.0110, s2.acc: 98.1964, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0205, loss: 0.2102, grad_norm: 5.4633\n",
            "2020-09-08 16:55:47,492 - mmdet - INFO - Epoch [15][4224/5332]\tlr: 1.000e-05, eta: 15:07:14, time: 1.938, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0232, s0.acc: 99.0479, s0.loss_bbox_cls: 0.0221, s0.loss_bbox_reg: 0.0448, s1.loss_cls: 0.0168, s1.acc: 98.6481, s1.loss_bbox_cls: 0.0196, s1.loss_bbox_reg: 0.0363, s2.loss_cls: 0.0117, s2.acc: 97.9431, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0214, loss: 0.2154, grad_norm: 6.0049\n",
            "2020-09-08 16:57:52,596 - mmdet - INFO - Epoch [15][4288/5332]\tlr: 1.000e-05, eta: 15:05:06, time: 1.955, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0237, s0.acc: 99.0173, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0421, s1.loss_cls: 0.0171, s1.acc: 98.6084, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0341, s2.loss_cls: 0.0109, s2.acc: 98.4344, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0201, loss: 0.2033, grad_norm: 5.3304\n",
            "2020-09-08 16:59:57,400 - mmdet - INFO - Epoch [15][4352/5332]\tlr: 1.000e-05, eta: 15:02:57, time: 1.950, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0231, s0.acc: 99.0387, s0.loss_bbox_cls: 0.0212, s0.loss_bbox_reg: 0.0442, s1.loss_cls: 0.0165, s1.acc: 98.6359, s1.loss_bbox_cls: 0.0163, s1.loss_bbox_reg: 0.0348, s2.loss_cls: 0.0104, s2.acc: 98.3856, s2.loss_bbox_cls: 0.0086, s2.loss_bbox_reg: 0.0184, loss: 0.2031, grad_norm: 5.1540\n",
            "2020-09-08 17:02:03,386 - mmdet - INFO - Epoch [15][4416/5332]\tlr: 1.000e-05, eta: 15:00:55, time: 1.969, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0207, s0.acc: 99.2096, s0.loss_bbox_cls: 0.0183, s0.loss_bbox_reg: 0.0404, s1.loss_cls: 0.0152, s1.acc: 98.7305, s1.loss_bbox_cls: 0.0157, s1.loss_bbox_reg: 0.0333, s2.loss_cls: 0.0087, s2.acc: 98.7762, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0210, loss: 0.1909, grad_norm: 5.6030\n",
            "2020-09-08 17:04:09,991 - mmdet - INFO - Epoch [15][4480/5332]\tlr: 1.000e-05, eta: 14:58:56, time: 1.978, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0073, s0.loss_cls: 0.0276, s0.acc: 98.9014, s0.loss_bbox_cls: 0.0232, s0.loss_bbox_reg: 0.0459, s1.loss_cls: 0.0201, s1.acc: 98.3704, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0340, s2.loss_cls: 0.0127, s2.acc: 97.8912, s2.loss_bbox_cls: 0.0087, s2.loss_bbox_reg: 0.0173, loss: 0.2177, grad_norm: 5.7829\n",
            "2020-09-08 17:06:15,745 - mmdet - INFO - Epoch [15][4544/5332]\tlr: 1.000e-05, eta: 14:56:53, time: 1.965, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0227, s0.acc: 99.0936, s0.loss_bbox_cls: 0.0182, s0.loss_bbox_reg: 0.0387, s1.loss_cls: 0.0169, s1.acc: 98.5931, s1.loss_bbox_cls: 0.0157, s1.loss_bbox_reg: 0.0313, s2.loss_cls: 0.0114, s2.acc: 97.9401, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0183, loss: 0.1897, grad_norm: 5.7151\n",
            "2020-09-08 17:08:21,066 - mmdet - INFO - Epoch [15][4608/5332]\tlr: 1.000e-05, eta: 14:54:46, time: 1.958, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0075, s0.loss_cls: 0.0199, s0.acc: 99.2676, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0460, s1.loss_cls: 0.0142, s1.acc: 98.8861, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0357, s2.loss_cls: 0.0086, s2.acc: 98.7274, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0208, loss: 0.2065, grad_norm: 5.7352\n",
            "2020-09-08 17:10:26,936 - mmdet - INFO - Epoch [15][4672/5332]\tlr: 1.000e-05, eta: 14:52:43, time: 1.967, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0115, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0209, s0.acc: 99.1394, s0.loss_bbox_cls: 0.0189, s0.loss_bbox_reg: 0.0423, s1.loss_cls: 0.0149, s1.acc: 98.7915, s1.loss_bbox_cls: 0.0165, s1.loss_bbox_reg: 0.0340, s2.loss_cls: 0.0098, s2.acc: 98.3246, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0204, loss: 0.2045, grad_norm: 5.4267\n",
            "2020-09-08 17:12:31,450 - mmdet - INFO - Epoch [15][4736/5332]\tlr: 1.000e-05, eta: 14:50:32, time: 1.946, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0247, s0.acc: 98.9258, s0.loss_bbox_cls: 0.0226, s0.loss_bbox_reg: 0.0445, s1.loss_cls: 0.0195, s1.acc: 98.2819, s1.loss_bbox_cls: 0.0198, s1.loss_bbox_reg: 0.0360, s2.loss_cls: 0.0122, s2.acc: 97.6624, s2.loss_bbox_cls: 0.0112, s2.loss_bbox_reg: 0.0215, loss: 0.2175, grad_norm: 5.6914\n",
            "2020-09-08 17:14:37,916 - mmdet - INFO - Epoch [15][4800/5332]\tlr: 1.000e-05, eta: 14:48:32, time: 1.976, data_time: 0.005, memory: 8979, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0254, s0.acc: 99.0753, s0.loss_bbox_cls: 0.0213, s0.loss_bbox_reg: 0.0439, s1.loss_cls: 0.0194, s1.acc: 98.6176, s1.loss_bbox_cls: 0.0153, s1.loss_bbox_reg: 0.0321, s2.loss_cls: 0.0107, s2.acc: 98.4680, s2.loss_bbox_cls: 0.0086, s2.loss_bbox_reg: 0.0180, loss: 0.2050, grad_norm: 5.3393\n",
            "2020-09-08 17:16:42,543 - mmdet - INFO - Epoch [15][4864/5332]\tlr: 1.000e-05, eta: 14:46:22, time: 1.947, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0263, s0.acc: 98.9899, s0.loss_bbox_cls: 0.0235, s0.loss_bbox_reg: 0.0467, s1.loss_cls: 0.0172, s1.acc: 98.6511, s1.loss_bbox_cls: 0.0199, s1.loss_bbox_reg: 0.0370, s2.loss_cls: 0.0097, s2.acc: 98.5748, s2.loss_bbox_cls: 0.0110, s2.loss_bbox_reg: 0.0211, loss: 0.2220, grad_norm: 5.5724\n",
            "2020-09-08 17:18:47,460 - mmdet - INFO - Epoch [15][4928/5332]\tlr: 1.000e-05, eta: 14:44:13, time: 1.952, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0240, s0.acc: 99.0295, s0.loss_bbox_cls: 0.0231, s0.loss_bbox_reg: 0.0494, s1.loss_cls: 0.0168, s1.acc: 98.6877, s1.loss_bbox_cls: 0.0184, s1.loss_bbox_reg: 0.0375, s2.loss_cls: 0.0109, s2.acc: 98.0713, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0216, loss: 0.2197, grad_norm: 5.4969\n",
            "2020-09-08 17:20:53,818 - mmdet - INFO - Epoch [15][4992/5332]\tlr: 1.000e-05, eta: 14:42:13, time: 1.974, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0238, s0.acc: 98.9838, s0.loss_bbox_cls: 0.0208, s0.loss_bbox_reg: 0.0447, s1.loss_cls: 0.0180, s1.acc: 98.4009, s1.loss_bbox_cls: 0.0160, s1.loss_bbox_reg: 0.0333, s2.loss_cls: 0.0117, s2.acc: 97.7386, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0216, loss: 0.2079, grad_norm: 5.6003\n",
            "2020-09-08 17:22:57,920 - mmdet - INFO - Epoch [15][5056/5332]\tlr: 1.000e-05, eta: 14:40:00, time: 1.939, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0234, s0.acc: 99.0356, s0.loss_bbox_cls: 0.0224, s0.loss_bbox_reg: 0.0490, s1.loss_cls: 0.0172, s1.acc: 98.7030, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0358, s2.loss_cls: 0.0109, s2.acc: 98.4009, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0222, loss: 0.2157, grad_norm: 5.4736\n",
            "2020-09-08 17:25:05,552 - mmdet - INFO - Epoch [15][5120/5332]\tlr: 1.000e-05, eta: 14:38:06, time: 1.994, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0025, s0.loss_cls: 0.0203, s0.acc: 99.1699, s0.loss_bbox_cls: 0.0175, s0.loss_bbox_reg: 0.0411, s1.loss_cls: 0.0145, s1.acc: 98.7946, s1.loss_bbox_cls: 0.0150, s1.loss_bbox_reg: 0.0339, s2.loss_cls: 0.0101, s2.acc: 98.2727, s2.loss_bbox_cls: 0.0083, s2.loss_bbox_reg: 0.0195, loss: 0.1854, grad_norm: 4.9887\n",
            "2020-09-08 17:27:08,178 - mmdet - INFO - Epoch [15][5184/5332]\tlr: 1.000e-05, eta: 14:35:46, time: 1.916, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0243, s0.acc: 99.0631, s0.loss_bbox_cls: 0.0260, s0.loss_bbox_reg: 0.0542, s1.loss_cls: 0.0174, s1.acc: 98.6572, s1.loss_bbox_cls: 0.0208, s1.loss_bbox_reg: 0.0415, s2.loss_cls: 0.0105, s2.acc: 98.3521, s2.loss_bbox_cls: 0.0118, s2.loss_bbox_reg: 0.0245, loss: 0.2388, grad_norm: 6.2238\n",
            "2020-09-08 17:29:13,075 - mmdet - INFO - Epoch [15][5248/5332]\tlr: 1.000e-05, eta: 14:33:38, time: 1.952, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0226, s0.acc: 99.1577, s0.loss_bbox_cls: 0.0192, s0.loss_bbox_reg: 0.0481, s1.loss_cls: 0.0130, s1.acc: 99.1333, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0395, s2.loss_cls: 0.0080, s2.acc: 98.9288, s2.loss_bbox_cls: 0.0116, s2.loss_bbox_reg: 0.0261, loss: 0.2132, grad_norm: 5.9750\n",
            "2020-09-08 17:31:17,319 - mmdet - INFO - Epoch [15][5312/5332]\tlr: 1.000e-05, eta: 14:31:26, time: 1.941, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0244, s0.acc: 99.0631, s0.loss_bbox_cls: 0.0176, s0.loss_bbox_reg: 0.0384, s1.loss_cls: 0.0190, s1.acc: 98.5992, s1.loss_bbox_cls: 0.0154, s1.loss_bbox_reg: 0.0311, s2.loss_cls: 0.0107, s2.acc: 98.3337, s2.loss_bbox_cls: 0.0077, s2.loss_bbox_reg: 0.0166, loss: 0.1880, grad_norm: 5.2651\n",
            "2020-09-08 17:31:57,322 - mmdet - INFO - Saving checkpoint at 15 epochs\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1131s, ETA:     0s2020-09-08 17:50:56,006 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 266  | 0.854  | 0.657 |\n",
            "| 3     | 22  | 62   | 0.727  | 0.604 |\n",
            "| 4     | 529 | 1232 | 0.921  | 0.833 |\n",
            "| 5     | 78  | 175  | 0.872  | 0.795 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.722 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-08 17:50:56,010 - mmdet - INFO - Epoch(val) [15][5332]\tmAP: 0.7223\n",
            "2020-09-08 17:53:05,365 - mmdet - INFO - Epoch [16][64/5332]\tlr: 1.000e-05, eta: 14:25:48, time: 2.021, data_time: 0.037, memory: 8979, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0226, s0.acc: 99.0814, s0.loss_bbox_cls: 0.0202, s0.loss_bbox_reg: 0.0438, s1.loss_cls: 0.0169, s1.acc: 98.5626, s1.loss_bbox_cls: 0.0156, s1.loss_bbox_reg: 0.0324, s2.loss_cls: 0.0101, s2.acc: 98.3276, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0191, loss: 0.1966, grad_norm: 5.3509\n",
            "2020-09-08 17:55:11,921 - mmdet - INFO - Epoch [16][128/5332]\tlr: 1.000e-05, eta: 14:23:50, time: 1.977, data_time: 0.004, memory: 8979, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0254, s0.acc: 98.9807, s0.loss_bbox_cls: 0.0202, s0.loss_bbox_reg: 0.0454, s1.loss_cls: 0.0181, s1.acc: 98.6938, s1.loss_bbox_cls: 0.0174, s1.loss_bbox_reg: 0.0353, s2.loss_cls: 0.0120, s2.acc: 98.0133, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0205, loss: 0.2138, grad_norm: 5.7755\n",
            "Process Process-7:\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa0670b80e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/local/lib/python3.7/threading.py\", line 1044, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/local/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2YA5M_oKWff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "58017484-5edc-4787-d867-bdeba37fb800"
      },
      "source": [
        "!python tools/train.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py --resume-from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_15.pth"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-09 09:47:35,175 - mmdet - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]\n",
            "CUDA available: True\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
            "GPU 0: Tesla P100-PCIE-16GB\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.4.0\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CUDA Runtime 10.0\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.1\n",
            "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "TorchVision: 0.5.0\n",
            "OpenCV: 4.4.0\n",
            "MMCV: 1.1.2\n",
            "MMDetection: 2.3.0+\n",
            "MMDetection Compiler: GCC 7.5\n",
            "MMDetection CUDA Compiler: 10.1\n",
            "------------------------------------------------------------\n",
            "\n",
            "2020-09-09 09:47:35,856 - mmdet - INFO - Distributed training: False\n",
            "2020-09-09 09:47:36,568 - mmdet - INFO - Config:\n",
            "model = dict(\n",
            "    type='CascadeRCNN',\n",
            "    pretrained='open-mmlab://resnext101_32x4d',\n",
            "    backbone=dict(\n",
            "        type='DetectoRS_ResNeXt',\n",
            "        depth=101,\n",
            "        groups=32,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch',\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(False, True, True, True),\n",
            "        output_img=True),\n",
            "    neck=dict(\n",
            "        type='RFP',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5,\n",
            "        rfp_steps=2,\n",
            "        aspp_out_channels=64,\n",
            "        aspp_dilations=(1, 3, 6, 1),\n",
            "        rfp_backbone=dict(\n",
            "            rfp_inplanes=256,\n",
            "            type='DetectoRS_ResNeXt',\n",
            "            depth=101,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(False, True, True, True),\n",
            "            pretrained='open-mmlab://resnext101_32x4d',\n",
            "            style='pytorch')),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(\n",
            "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='CascadeRoIHead',\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[1, 0.5, 0.25],\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='GenericRoIExtractor',\n",
            "            aggregation='sum',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32],\n",
            "            pre_cfg=dict(\n",
            "                type='ConvModule',\n",
            "                in_channels=256,\n",
            "                out_channels=256,\n",
            "                kernel_size=5,\n",
            "                padding=2,\n",
            "                inplace=False),\n",
            "            post_cfg=dict(\n",
            "                type='GeneralizedAttention',\n",
            "                in_channels=256,\n",
            "                spatial_range=-1,\n",
            "                num_heads=6,\n",
            "                attention_type='0100',\n",
            "                kv_stride=2)),\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.7),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.5),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.3),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0))\n",
            "        ]))\n",
            "train_cfg = dict(\n",
            "    rpn=dict(\n",
            "        assigner=dict(\n",
            "            type='MaxIoUAssigner',\n",
            "            pos_iou_thr=0.7,\n",
            "            neg_iou_thr=0.3,\n",
            "            min_pos_iou=0.3,\n",
            "            match_low_quality=True,\n",
            "            ignore_iof_thr=-1),\n",
            "        sampler=dict(\n",
            "            type='RandomSampler',\n",
            "            num=256,\n",
            "            pos_fraction=0.5,\n",
            "            neg_pos_ub=-1,\n",
            "            add_gt_as_proposals=False),\n",
            "        allowed_border=0,\n",
            "        pos_weight=-1,\n",
            "        debug=False),\n",
            "    rpn_proposal=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=2000,\n",
            "        nms_post=2000,\n",
            "        max_num=2000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=[\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.6,\n",
            "                neg_iou_thr=0.6,\n",
            "                min_pos_iou=0.6,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.7,\n",
            "                min_pos_iou=0.7,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)\n",
            "    ])\n",
            "test_cfg = dict(\n",
            "    rpn=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=1000,\n",
            "        nms_post=1000,\n",
            "        max_num=1000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=dict(\n",
            "        score_thr=0.05,\n",
            "        nms=dict(type='nms', iou_threshold=0.5),\n",
            "        max_per_img=100))\n",
            "dataset_type = 'CustomDataset'\n",
            "data_root = 'data/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "albu_train_transforms = [\n",
            "    dict(\n",
            "        type='ShiftScaleRotate',\n",
            "        shift_limit=0.0625,\n",
            "        scale_limit=0.0,\n",
            "        rotate_limit=0,\n",
            "        interpolation=1,\n",
            "        p=0.5),\n",
            "    dict(\n",
            "        type='RandomBrightnessContrast',\n",
            "        brightness_limit=[0.1, 0.3],\n",
            "        contrast_limit=[0.1, 0.3],\n",
            "        p=0.2),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='RGBShift',\n",
            "                r_shift_limit=10,\n",
            "                g_shift_limit=10,\n",
            "                b_shift_limit=10,\n",
            "                p=1.0),\n",
            "            dict(\n",
            "                type='HueSaturationValue',\n",
            "                hue_shift_limit=20,\n",
            "                sat_shift_limit=30,\n",
            "                val_shift_limit=20,\n",
            "                p=1.0)\n",
            "        ],\n",
            "        p=0.1),\n",
            "    dict(type='JpegCompression', quality_lower=85, quality_upper=95, p=0.2),\n",
            "    dict(type='ChannelShuffle', p=0.1),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "        ],\n",
            "        p=0.1)\n",
            "]\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        type='Resize',\n",
            "        multiscale_mode='range',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(\n",
            "        type='Albu',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='ShiftScaleRotate',\n",
            "                shift_limit=0.0625,\n",
            "                scale_limit=0.0,\n",
            "                rotate_limit=0,\n",
            "                interpolation=1,\n",
            "                p=0.5),\n",
            "            dict(\n",
            "                type='RandomBrightnessContrast',\n",
            "                brightness_limit=[0.1, 0.3],\n",
            "                contrast_limit=[0.1, 0.3],\n",
            "                p=0.2),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='RGBShift',\n",
            "                        r_shift_limit=10,\n",
            "                        g_shift_limit=10,\n",
            "                        b_shift_limit=10,\n",
            "                        p=1.0),\n",
            "                    dict(\n",
            "                        type='HueSaturationValue',\n",
            "                        hue_shift_limit=20,\n",
            "                        sat_shift_limit=30,\n",
            "                        val_shift_limit=20,\n",
            "                        p=1.0)\n",
            "                ],\n",
            "                p=0.1),\n",
            "            dict(\n",
            "                type='JpegCompression',\n",
            "                quality_lower=85,\n",
            "                quality_upper=95,\n",
            "                p=0.2),\n",
            "            dict(type='ChannelShuffle', p=0.1),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                    dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                ],\n",
            "                p=0.1)\n",
            "        ],\n",
            "        bbox_params=dict(\n",
            "            type='BboxParams',\n",
            "            format='pascal_voc',\n",
            "            label_fields=['gt_labels'],\n",
            "            min_visibility=0.0,\n",
            "            filter_lost_elements=True),\n",
            "        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "        update_pad_shape=False,\n",
            "        skip_img_without_anno=True),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(\n",
            "        type='Collect',\n",
            "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "        meta_keys=('filename', 'ori_shape', 'img_shape', 'img_norm_cfg',\n",
            "                   'pad_shape', 'scale_factor'))\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        transforms=[\n",
            "            dict(type='Resize', multiscale_mode='range', keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=1.0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=1,\n",
            "    workers_per_gpu=1,\n",
            "    train=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/train_80_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                multiscale_mode='range',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(\n",
            "                type='Albu',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='ShiftScaleRotate',\n",
            "                        shift_limit=0.0625,\n",
            "                        scale_limit=0.0,\n",
            "                        rotate_limit=0,\n",
            "                        interpolation=1,\n",
            "                        p=0.5),\n",
            "                    dict(\n",
            "                        type='RandomBrightnessContrast',\n",
            "                        brightness_limit=[0.1, 0.3],\n",
            "                        contrast_limit=[0.1, 0.3],\n",
            "                        p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(\n",
            "                                type='RGBShift',\n",
            "                                r_shift_limit=10,\n",
            "                                g_shift_limit=10,\n",
            "                                b_shift_limit=10,\n",
            "                                p=1.0),\n",
            "                            dict(\n",
            "                                type='HueSaturationValue',\n",
            "                                hue_shift_limit=20,\n",
            "                                sat_shift_limit=30,\n",
            "                                val_shift_limit=20,\n",
            "                                p=1.0)\n",
            "                        ],\n",
            "                        p=0.1),\n",
            "                    dict(\n",
            "                        type='JpegCompression',\n",
            "                        quality_lower=75,\n",
            "                        quality_upper=95,\n",
            "                        p=0.2),\n",
            "                    dict(type='ChannelShuffle', p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                        ],\n",
            "                        p=0.1)\n",
            "                ],\n",
            "                bbox_params=dict(\n",
            "                    type='BboxParams',\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=['gt_labels'],\n",
            "                    min_visibility=0.0,\n",
            "                    filter_lost_elements=True),\n",
            "                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "                update_pad_shape=False,\n",
            "                skip_img_without_anno=True),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "                meta_keys=('filename', 'ori_shape', 'img_shape',\n",
            "                           'img_norm_cfg', 'pad_shape', 'scale_factor'))\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/val_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/test_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 200), (1999, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=1, metric='mAP')\n",
            "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.3333333333333333,\n",
            "    step=[8, 11])\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=64, hooks=[dict(type='TextLoggerHook')])\n",
            "total_epochs = 20\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "work_dir = './work_dirs/cascade_rcnn_x101_32x4d_fpn_1x'\n",
            "load_from = None\n",
            "resume_from = 'work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_15.pth'\n",
            "workflow = [('train', 1)]\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "2020-09-09 09:47:40,555 - mmdet - INFO - load model from: open-mmlab://resnext101_32x4d\n",
            "Downloading: \"https://openmmlab.oss-accelerate.aliyuncs.com/pretrain/third_party/resnext101_32x4d-a5af3160.pth\" to /root/.cache/torch/checkpoints/resnext101_32x4d-a5af3160.pth\n",
            "100% 161M/161M [00:12<00:00, 13.4MB/s]\n",
            "2020-09-09 09:47:54,719 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "2020-09-09 09:47:55,246 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
            "size mismatch for layer1.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.2.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
            "size mismatch for layer2.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.0.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.1.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.1.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.2.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.2.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.2.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.3.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.3.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.3.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
            "size mismatch for layer3.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.2.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.3.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.3.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.3.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.4.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.4.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.4.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.5.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.5.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.5.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.6.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.6.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.6.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.7.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.7.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.7.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.8.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.8.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.8.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.9.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.9.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.9.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.10.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.10.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.10.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.11.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.11.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.11.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.12.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.12.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.12.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.13.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.13.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.13.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.14.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.14.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.14.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.15.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.15.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.15.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.16.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.16.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.16.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.17.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.17.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.17.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.18.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.18.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.18.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.19.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.19.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.19.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.20.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.20.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.20.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.21.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.21.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.21.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.22.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.22.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.22.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
            "size mismatch for layer4.0.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.0.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.1.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.1.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.2.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.2.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.2.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-09 09:48:01,096 - mmdet - INFO - load checkpoint from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_15.pth\n",
            "2020-09-09 09:48:15,059 - mmdet - INFO - resumed epoch 15, iter 79980\n",
            "2020-09-09 09:48:15,070 - mmdet - INFO - Start running, host: root@25aa13c3b0a1, work_dir: /content/drive/My Drive/mmdetection-master/work_dirs/cascade_rcnn_x101_32x4d_fpn_1x\n",
            "2020-09-09 09:48:15,070 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs\n",
            "2020-09-09 09:50:23,893 - mmdet - INFO - Epoch [16][64/5332]\tlr: 1.000e-05, eta: 14:52:06, time: 2.013, data_time: 0.051, memory: 8924, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0207, s0.acc: 99.1333, s0.loss_bbox_cls: 0.0187, s0.loss_bbox_reg: 0.0433, s1.loss_cls: 0.0171, s1.acc: 98.5840, s1.loss_bbox_cls: 0.0169, s1.loss_bbox_reg: 0.0364, s2.loss_cls: 0.0111, s2.acc: 98.1445, s2.loss_bbox_cls: 0.0114, s2.loss_bbox_reg: 0.0235, loss: 0.2064, grad_norm: 5.8905\n",
            "2020-09-09 09:52:26,925 - mmdet - INFO - Epoch [16][128/5332]\tlr: 1.000e-05, eta: 14:30:01, time: 1.922, data_time: 0.004, memory: 8924, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0250, s0.acc: 99.0051, s0.loss_bbox_cls: 0.0214, s0.loss_bbox_reg: 0.0443, s1.loss_cls: 0.0160, s1.acc: 98.8037, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0353, s2.loss_cls: 0.0093, s2.acc: 98.4589, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0212, loss: 0.2125, grad_norm: 5.1828\n",
            "2020-09-09 09:54:30,323 - mmdet - INFO - Epoch [16][192/5332]\tlr: 1.000e-05, eta: 14:22:08, time: 1.928, data_time: 0.004, memory: 8924, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0218, s0.acc: 99.1241, s0.loss_bbox_cls: 0.0183, s0.loss_bbox_reg: 0.0406, s1.loss_cls: 0.0167, s1.acc: 98.7335, s1.loss_bbox_cls: 0.0158, s1.loss_bbox_reg: 0.0316, s2.loss_cls: 0.0114, s2.acc: 98.1415, s2.loss_bbox_cls: 0.0085, s2.loss_bbox_reg: 0.0189, loss: 0.1912, grad_norm: 5.4582\n",
            "2020-09-09 09:56:33,963 - mmdet - INFO - Epoch [16][256/5332]\tlr: 1.000e-05, eta: 14:17:34, time: 1.932, data_time: 0.004, memory: 8924, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0236, s0.acc: 99.0112, s0.loss_bbox_cls: 0.0237, s0.loss_bbox_reg: 0.0500, s1.loss_cls: 0.0163, s1.acc: 98.6115, s1.loss_bbox_cls: 0.0198, s1.loss_bbox_reg: 0.0374, s2.loss_cls: 0.0101, s2.acc: 98.2635, s2.loss_bbox_cls: 0.0130, s2.loss_bbox_reg: 0.0240, loss: 0.2240, grad_norm: 6.2446\n",
            "2020-09-09 09:58:36,833 - mmdet - INFO - Epoch [16][320/5332]\tlr: 1.000e-05, eta: 14:12:57, time: 1.920, data_time: 0.004, memory: 8924, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0226, s0.acc: 99.1272, s0.loss_bbox_cls: 0.0173, s0.loss_bbox_reg: 0.0403, s1.loss_cls: 0.0163, s1.acc: 98.7274, s1.loss_bbox_cls: 0.0134, s1.loss_bbox_reg: 0.0301, s2.loss_cls: 0.0096, s2.acc: 98.4497, s2.loss_bbox_cls: 0.0078, s2.loss_bbox_reg: 0.0173, loss: 0.1814, grad_norm: 5.3363\n",
            "2020-09-09 10:00:40,668 - mmdet - INFO - Epoch [16][384/5332]\tlr: 1.000e-05, eta: 14:10:17, time: 1.935, data_time: 0.004, memory: 8924, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0216, s0.acc: 99.1455, s0.loss_bbox_cls: 0.0191, s0.loss_bbox_reg: 0.0399, s1.loss_cls: 0.0154, s1.acc: 98.8190, s1.loss_bbox_cls: 0.0159, s1.loss_bbox_reg: 0.0317, s2.loss_cls: 0.0101, s2.acc: 98.1506, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0197, loss: 0.1905, grad_norm: 5.2498\n",
            "2020-09-09 10:02:44,436 - mmdet - INFO - Epoch [16][448/5332]\tlr: 1.000e-05, eta: 14:07:44, time: 1.934, data_time: 0.004, memory: 8924, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0253, s0.acc: 99.0265, s0.loss_bbox_cls: 0.0228, s0.loss_bbox_reg: 0.0463, s1.loss_cls: 0.0202, s1.acc: 98.4253, s1.loss_bbox_cls: 0.0197, s1.loss_bbox_reg: 0.0372, s2.loss_cls: 0.0133, s2.acc: 97.8271, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0207, loss: 0.2254, grad_norm: 5.6839\n",
            "2020-09-09 10:04:49,233 - mmdet - INFO - Epoch [16][512/5332]\tlr: 1.000e-05, eta: 14:06:11, time: 1.950, data_time: 0.004, memory: 8924, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0244, s0.acc: 98.9685, s0.loss_bbox_cls: 0.0241, s0.loss_bbox_reg: 0.0494, s1.loss_cls: 0.0171, s1.acc: 98.6298, s1.loss_bbox_cls: 0.0180, s1.loss_bbox_reg: 0.0364, s2.loss_cls: 0.0105, s2.acc: 98.2574, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0213, loss: 0.2179, grad_norm: 5.8723\n",
            "2020-09-09 10:06:54,292 - mmdet - INFO - Epoch [16][576/5332]\tlr: 1.000e-05, eta: 14:04:42, time: 1.954, data_time: 0.004, memory: 8924, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0191, s0.acc: 99.2371, s0.loss_bbox_cls: 0.0204, s0.loss_bbox_reg: 0.0441, s1.loss_cls: 0.0136, s1.acc: 98.9777, s1.loss_bbox_cls: 0.0184, s1.loss_bbox_reg: 0.0361, s2.loss_cls: 0.0098, s2.acc: 98.3215, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0226, loss: 0.2021, grad_norm: 5.8296\n",
            "2020-09-09 10:08:57,360 - mmdet - INFO - Epoch [16][640/5332]\tlr: 1.000e-05, eta: 14:01:46, time: 1.923, data_time: 0.004, memory: 8924, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0245, s0.acc: 98.9471, s0.loss_bbox_cls: 0.0236, s0.loss_bbox_reg: 0.0481, s1.loss_cls: 0.0195, s1.acc: 98.4100, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0346, s2.loss_cls: 0.0115, s2.acc: 98.0103, s2.loss_bbox_cls: 0.0085, s2.loss_bbox_reg: 0.0191, loss: 0.2135, grad_norm: 5.7948\n",
            "2020-09-09 10:11:01,016 - mmdet - INFO - Epoch [16][704/5332]\tlr: 1.000e-05, eta: 13:59:20, time: 1.932, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0214, s0.acc: 99.1150, s0.loss_bbox_cls: 0.0197, s0.loss_bbox_reg: 0.0409, s1.loss_cls: 0.0177, s1.acc: 98.5107, s1.loss_bbox_cls: 0.0149, s1.loss_bbox_reg: 0.0299, s2.loss_cls: 0.0115, s2.acc: 97.8607, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0191, loss: 0.1916, grad_norm: 5.5516\n",
            "2020-09-09 10:13:05,118 - mmdet - INFO - Epoch [16][768/5332]\tlr: 1.000e-05, eta: 13:57:14, time: 1.939, data_time: 0.031, memory: 9012, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0237, s0.acc: 99.0601, s0.loss_bbox_cls: 0.0232, s0.loss_bbox_reg: 0.0514, s1.loss_cls: 0.0157, s1.acc: 98.6847, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0364, s2.loss_cls: 0.0103, s2.acc: 98.2697, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0212, loss: 0.2200, grad_norm: 5.8639\n",
            "2020-09-09 10:15:09,537 - mmdet - INFO - Epoch [16][832/5332]\tlr: 1.000e-05, eta: 13:55:17, time: 1.944, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0316, s0.acc: 98.9197, s0.loss_bbox_cls: 0.0265, s0.loss_bbox_reg: 0.0495, s1.loss_cls: 0.0196, s1.acc: 98.4467, s1.loss_bbox_cls: 0.0211, s1.loss_bbox_reg: 0.0374, s2.loss_cls: 0.0130, s2.acc: 98.1171, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0208, loss: 0.2387, grad_norm: 6.1506\n",
            "2020-09-09 10:17:14,521 - mmdet - INFO - Epoch [16][896/5332]\tlr: 1.000e-05, eta: 13:53:36, time: 1.953, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0244, s0.acc: 99.0509, s0.loss_bbox_cls: 0.0208, s0.loss_bbox_reg: 0.0435, s1.loss_cls: 0.0172, s1.acc: 98.6908, s1.loss_bbox_cls: 0.0168, s1.loss_bbox_reg: 0.0337, s2.loss_cls: 0.0101, s2.acc: 98.4314, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0201, loss: 0.2029, grad_norm: 5.6096\n",
            "2020-09-09 10:19:19,904 - mmdet - INFO - Epoch [16][960/5332]\tlr: 1.000e-05, eta: 13:52:02, time: 1.959, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0238, s0.acc: 99.0326, s0.loss_bbox_cls: 0.0254, s0.loss_bbox_reg: 0.0488, s1.loss_cls: 0.0179, s1.acc: 98.4955, s1.loss_bbox_cls: 0.0186, s1.loss_bbox_reg: 0.0356, s2.loss_cls: 0.0112, s2.acc: 98.1262, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0202, loss: 0.2199, grad_norm: 5.5892\n",
            "2020-09-09 10:21:22,625 - mmdet - INFO - Epoch [16][1024/5332]\tlr: 1.000e-05, eta: 13:49:18, time: 1.918, data_time: 0.005, memory: 9012, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0174, s0.acc: 99.3317, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0469, s1.loss_cls: 0.0128, s1.acc: 99.0692, s1.loss_bbox_cls: 0.0194, s1.loss_bbox_reg: 0.0376, s2.loss_cls: 0.0090, s2.acc: 98.6481, s2.loss_bbox_cls: 0.0112, s2.loss_bbox_reg: 0.0228, loss: 0.2044, grad_norm: 5.3122\n",
            "2020-09-09 10:23:26,426 - mmdet - INFO - Epoch [16][1088/5332]\tlr: 1.000e-05, eta: 13:47:04, time: 1.934, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0245, s0.acc: 98.9746, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0458, s1.loss_cls: 0.0164, s1.acc: 98.5809, s1.loss_bbox_cls: 0.0196, s1.loss_bbox_reg: 0.0394, s2.loss_cls: 0.0109, s2.acc: 98.2361, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0208, loss: 0.2139, grad_norm: 6.1166\n",
            "2020-09-09 10:25:30,964 - mmdet - INFO - Epoch [16][1152/5332]\tlr: 1.000e-05, eta: 13:45:07, time: 1.946, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0212, s0.acc: 99.1425, s0.loss_bbox_cls: 0.0211, s0.loss_bbox_reg: 0.0454, s1.loss_cls: 0.0189, s1.acc: 98.3795, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0361, s2.loss_cls: 0.0112, s2.acc: 98.0530, s2.loss_bbox_cls: 0.0086, s2.loss_bbox_reg: 0.0199, loss: 0.2078, grad_norm: 5.8405\n",
            "2020-09-09 10:27:35,545 - mmdet - INFO - Epoch [16][1216/5332]\tlr: 1.000e-05, eta: 13:43:10, time: 1.947, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0246, s0.acc: 99.0631, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0453, s1.loss_cls: 0.0188, s1.acc: 98.5168, s1.loss_bbox_cls: 0.0182, s1.loss_bbox_reg: 0.0355, s2.loss_cls: 0.0122, s2.acc: 97.8821, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0214, loss: 0.2138, grad_norm: 6.2520\n",
            "2020-09-09 10:29:40,245 - mmdet - INFO - Epoch [16][1280/5332]\tlr: 1.000e-05, eta: 13:41:15, time: 1.948, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0257, s0.acc: 98.9868, s0.loss_bbox_cls: 0.0200, s0.loss_bbox_reg: 0.0421, s1.loss_cls: 0.0174, s1.acc: 98.6176, s1.loss_bbox_cls: 0.0166, s1.loss_bbox_reg: 0.0331, s2.loss_cls: 0.0115, s2.acc: 98.1995, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0210, loss: 0.2069, grad_norm: 5.4845\n",
            "2020-09-09 10:31:44,562 - mmdet - INFO - Epoch [16][1344/5332]\tlr: 1.000e-05, eta: 13:39:12, time: 1.942, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0256, s0.acc: 98.9685, s0.loss_bbox_cls: 0.0210, s0.loss_bbox_reg: 0.0469, s1.loss_cls: 0.0169, s1.acc: 98.7885, s1.loss_bbox_cls: 0.0187, s1.loss_bbox_reg: 0.0386, s2.loss_cls: 0.0102, s2.acc: 98.3459, s2.loss_bbox_cls: 0.0112, s2.loss_bbox_reg: 0.0229, loss: 0.2202, grad_norm: 5.6633\n",
            "2020-09-09 10:33:48,276 - mmdet - INFO - Epoch [16][1408/5332]\tlr: 1.000e-05, eta: 13:36:58, time: 1.933, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0207, s0.acc: 99.1333, s0.loss_bbox_cls: 0.0225, s0.loss_bbox_reg: 0.0477, s1.loss_cls: 0.0146, s1.acc: 98.7305, s1.loss_bbox_cls: 0.0190, s1.loss_bbox_reg: 0.0392, s2.loss_cls: 0.0093, s2.acc: 98.4589, s2.loss_bbox_cls: 0.0124, s2.loss_bbox_reg: 0.0244, loss: 0.2192, grad_norm: 5.3911\n",
            "2020-09-09 10:35:52,347 - mmdet - INFO - Epoch [16][1472/5332]\tlr: 1.000e-05, eta: 13:34:51, time: 1.939, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0225, s0.acc: 99.2035, s0.loss_bbox_cls: 0.0223, s0.loss_bbox_reg: 0.0505, s1.loss_cls: 0.0164, s1.acc: 98.6481, s1.loss_bbox_cls: 0.0194, s1.loss_bbox_reg: 0.0398, s2.loss_cls: 0.0105, s2.acc: 98.2788, s2.loss_bbox_cls: 0.0115, s2.loss_bbox_reg: 0.0239, loss: 0.2243, grad_norm: 6.0014\n",
            "2020-09-09 10:37:56,565 - mmdet - INFO - Epoch [16][1536/5332]\tlr: 1.000e-05, eta: 13:32:47, time: 1.941, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0291, s0.acc: 98.8556, s0.loss_bbox_cls: 0.0237, s0.loss_bbox_reg: 0.0469, s1.loss_cls: 0.0221, s1.acc: 97.9462, s1.loss_bbox_cls: 0.0188, s1.loss_bbox_reg: 0.0363, s2.loss_cls: 0.0128, s2.acc: 98.0347, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0214, loss: 0.2307, grad_norm: 5.9000\n",
            "2020-09-09 10:40:00,412 - mmdet - INFO - Epoch [16][1600/5332]\tlr: 1.000e-05, eta: 13:30:37, time: 1.935, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0227, s0.acc: 99.0540, s0.loss_bbox_cls: 0.0216, s0.loss_bbox_reg: 0.0427, s1.loss_cls: 0.0179, s1.acc: 98.5229, s1.loss_bbox_cls: 0.0160, s1.loss_bbox_reg: 0.0319, s2.loss_cls: 0.0118, s2.acc: 97.9248, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0191, loss: 0.2001, grad_norm: 5.7695\n",
            "2020-09-09 10:42:05,191 - mmdet - INFO - Epoch [16][1664/5332]\tlr: 1.000e-05, eta: 13:28:41, time: 1.950, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0228, s0.acc: 99.0356, s0.loss_bbox_cls: 0.0224, s0.loss_bbox_reg: 0.0472, s1.loss_cls: 0.0164, s1.acc: 98.7091, s1.loss_bbox_cls: 0.0181, s1.loss_bbox_reg: 0.0372, s2.loss_cls: 0.0111, s2.acc: 98.1842, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0239, loss: 0.2202, grad_norm: 6.0131\n",
            "2020-09-09 10:44:09,429 - mmdet - INFO - Epoch [16][1728/5332]\tlr: 1.000e-05, eta: 13:26:37, time: 1.941, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0211, s0.acc: 99.1028, s0.loss_bbox_cls: 0.0225, s0.loss_bbox_reg: 0.0455, s1.loss_cls: 0.0160, s1.acc: 98.6908, s1.loss_bbox_cls: 0.0201, s1.loss_bbox_reg: 0.0370, s2.loss_cls: 0.0107, s2.acc: 97.9462, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0215, loss: 0.2136, grad_norm: 5.3107\n",
            "2020-09-09 10:46:15,118 - mmdet - INFO - Epoch [16][1792/5332]\tlr: 1.000e-05, eta: 13:24:53, time: 1.964, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0231, s0.acc: 99.1425, s0.loss_bbox_cls: 0.0193, s0.loss_bbox_reg: 0.0405, s1.loss_cls: 0.0166, s1.acc: 98.7701, s1.loss_bbox_cls: 0.0155, s1.loss_bbox_reg: 0.0298, s2.loss_cls: 0.0106, s2.acc: 98.3063, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0184, loss: 0.1922, grad_norm: 4.6943\n",
            "2020-09-09 10:48:18,446 - mmdet - INFO - Epoch [16][1856/5332]\tlr: 1.000e-05, eta: 13:22:35, time: 1.927, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0204, s0.acc: 99.1699, s0.loss_bbox_cls: 0.0239, s0.loss_bbox_reg: 0.0479, s1.loss_cls: 0.0155, s1.acc: 98.8556, s1.loss_bbox_cls: 0.0199, s1.loss_bbox_reg: 0.0393, s2.loss_cls: 0.0100, s2.acc: 98.4863, s2.loss_bbox_cls: 0.0119, s2.loss_bbox_reg: 0.0239, loss: 0.2193, grad_norm: 5.6494\n",
            "2020-09-09 10:50:22,446 - mmdet - INFO - Epoch [16][1920/5332]\tlr: 1.000e-05, eta: 13:20:28, time: 1.937, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0257, s0.acc: 98.8953, s0.loss_bbox_cls: 0.0205, s0.loss_bbox_reg: 0.0434, s1.loss_cls: 0.0186, s1.acc: 98.4192, s1.loss_bbox_cls: 0.0161, s1.loss_bbox_reg: 0.0333, s2.loss_cls: 0.0119, s2.acc: 97.7905, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0207, loss: 0.2115, grad_norm: 5.9334\n",
            "2020-09-09 10:52:26,398 - mmdet - INFO - Epoch [16][1984/5332]\tlr: 1.000e-05, eta: 13:18:20, time: 1.937, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0297, s0.acc: 98.7610, s0.loss_bbox_cls: 0.0254, s0.loss_bbox_reg: 0.0508, s1.loss_cls: 0.0224, s1.acc: 98.1812, s1.loss_bbox_cls: 0.0216, s1.loss_bbox_reg: 0.0379, s2.loss_cls: 0.0126, s2.acc: 97.9553, s2.loss_bbox_cls: 0.0116, s2.loss_bbox_reg: 0.0203, loss: 0.2390, grad_norm: 6.1330\n",
            "2020-09-09 10:54:30,666 - mmdet - INFO - Epoch [16][2048/5332]\tlr: 1.000e-05, eta: 13:16:16, time: 1.942, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0253, s0.acc: 98.9227, s0.loss_bbox_cls: 0.0235, s0.loss_bbox_reg: 0.0464, s1.loss_cls: 0.0167, s1.acc: 98.5229, s1.loss_bbox_cls: 0.0197, s1.loss_bbox_reg: 0.0369, s2.loss_cls: 0.0110, s2.acc: 98.0865, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0211, loss: 0.2203, grad_norm: 5.9570\n",
            "2020-09-09 10:56:34,394 - mmdet - INFO - Epoch [16][2112/5332]\tlr: 1.000e-05, eta: 13:14:06, time: 1.933, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0302, s0.acc: 98.7549, s0.loss_bbox_cls: 0.0220, s0.loss_bbox_reg: 0.0441, s1.loss_cls: 0.0220, s1.acc: 98.0804, s1.loss_bbox_cls: 0.0149, s1.loss_bbox_reg: 0.0308, s2.loss_cls: 0.0132, s2.acc: 97.8333, s2.loss_bbox_cls: 0.0079, s2.loss_bbox_reg: 0.0171, loss: 0.2105, grad_norm: 5.5551\n",
            "2020-09-09 10:58:40,002 - mmdet - INFO - Epoch [16][2176/5332]\tlr: 1.000e-05, eta: 13:12:17, time: 1.963, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0210, s0.acc: 99.2188, s0.loss_bbox_cls: 0.0202, s0.loss_bbox_reg: 0.0399, s1.loss_cls: 0.0159, s1.acc: 98.7427, s1.loss_bbox_cls: 0.0162, s1.loss_bbox_reg: 0.0301, s2.loss_cls: 0.0109, s2.acc: 98.2147, s2.loss_bbox_cls: 0.0085, s2.loss_bbox_reg: 0.0178, loss: 0.1868, grad_norm: 5.0979\n",
            "2020-09-09 11:00:44,000 - mmdet - INFO - Epoch [16][2240/5332]\tlr: 1.000e-05, eta: 13:10:10, time: 1.937, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0233, s0.acc: 99.1241, s0.loss_bbox_cls: 0.0221, s0.loss_bbox_reg: 0.0470, s1.loss_cls: 0.0153, s1.acc: 99.0143, s1.loss_bbox_cls: 0.0205, s1.loss_bbox_reg: 0.0382, s2.loss_cls: 0.0099, s2.acc: 98.5382, s2.loss_bbox_cls: 0.0125, s2.loss_bbox_reg: 0.0236, loss: 0.2194, grad_norm: 5.6520\n",
            "2020-09-09 11:02:46,893 - mmdet - INFO - Epoch [16][2304/5332]\tlr: 1.000e-05, eta: 13:07:52, time: 1.920, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0251, s0.acc: 98.9685, s0.loss_bbox_cls: 0.0212, s0.loss_bbox_reg: 0.0442, s1.loss_cls: 0.0193, s1.acc: 98.3276, s1.loss_bbox_cls: 0.0157, s1.loss_bbox_reg: 0.0330, s2.loss_cls: 0.0113, s2.acc: 98.1628, s2.loss_bbox_cls: 0.0082, s2.loss_bbox_reg: 0.0178, loss: 0.2049, grad_norm: 6.0018\n",
            "2020-09-09 11:04:51,075 - mmdet - INFO - Epoch [16][2368/5332]\tlr: 1.000e-05, eta: 13:05:47, time: 1.940, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0229, s0.acc: 99.1669, s0.loss_bbox_cls: 0.0213, s0.loss_bbox_reg: 0.0488, s1.loss_cls: 0.0151, s1.acc: 98.8220, s1.loss_bbox_cls: 0.0192, s1.loss_bbox_reg: 0.0415, s2.loss_cls: 0.0088, s2.acc: 98.5077, s2.loss_bbox_cls: 0.0123, s2.loss_bbox_reg: 0.0248, loss: 0.2199, grad_norm: 5.9832\n",
            "2020-09-09 11:06:56,880 - mmdet - INFO - Epoch [16][2432/5332]\tlr: 1.000e-05, eta: 13:03:59, time: 1.966, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0247, s0.acc: 98.9777, s0.loss_bbox_cls: 0.0196, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0181, s1.acc: 98.4924, s1.loss_bbox_cls: 0.0160, s1.loss_bbox_reg: 0.0340, s2.loss_cls: 0.0111, s2.acc: 98.0469, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0215, loss: 0.2088, grad_norm: 5.6673\n",
            "2020-09-09 11:09:02,048 - mmdet - INFO - Epoch [16][2496/5332]\tlr: 1.000e-05, eta: 13:02:03, time: 1.956, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0217, s0.acc: 99.1638, s0.loss_bbox_cls: 0.0179, s0.loss_bbox_reg: 0.0406, s1.loss_cls: 0.0164, s1.acc: 98.8068, s1.loss_bbox_cls: 0.0153, s1.loss_bbox_reg: 0.0316, s2.loss_cls: 0.0107, s2.acc: 98.2635, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0178, loss: 0.1879, grad_norm: 5.4921\n",
            "2020-09-09 11:11:06,365 - mmdet - INFO - Epoch [16][2560/5332]\tlr: 1.000e-05, eta: 12:59:59, time: 1.942, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0189, s0.acc: 99.2798, s0.loss_bbox_cls: 0.0193, s0.loss_bbox_reg: 0.0429, s1.loss_cls: 0.0135, s1.acc: 99.0234, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0350, s2.loss_cls: 0.0093, s2.acc: 98.5016, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0210, loss: 0.1954, grad_norm: 5.3112\n",
            "2020-09-09 11:13:10,177 - mmdet - INFO - Epoch [16][2624/5332]\tlr: 1.000e-05, eta: 12:57:51, time: 1.935, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0243, s0.acc: 99.0387, s0.loss_bbox_cls: 0.0190, s0.loss_bbox_reg: 0.0406, s1.loss_cls: 0.0163, s1.acc: 98.6633, s1.loss_bbox_cls: 0.0152, s1.loss_bbox_reg: 0.0316, s2.loss_cls: 0.0090, s2.acc: 98.6267, s2.loss_bbox_cls: 0.0087, s2.loss_bbox_reg: 0.0187, loss: 0.1935, grad_norm: 5.1196\n",
            "2020-09-09 11:15:14,365 - mmdet - INFO - Epoch [16][2688/5332]\tlr: 1.000e-05, eta: 12:55:46, time: 1.940, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0206, s0.acc: 99.1638, s0.loss_bbox_cls: 0.0176, s0.loss_bbox_reg: 0.0387, s1.loss_cls: 0.0140, s1.acc: 99.0540, s1.loss_bbox_cls: 0.0140, s1.loss_bbox_reg: 0.0298, s2.loss_cls: 0.0097, s2.acc: 98.3215, s2.loss_bbox_cls: 0.0085, s2.loss_bbox_reg: 0.0185, loss: 0.1788, grad_norm: 5.2106\n",
            "2020-09-09 11:17:19,820 - mmdet - INFO - Epoch [16][2752/5332]\tlr: 1.000e-05, eta: 12:53:52, time: 1.960, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0234, s0.acc: 99.0936, s0.loss_bbox_cls: 0.0192, s0.loss_bbox_reg: 0.0403, s1.loss_cls: 0.0155, s1.acc: 98.8190, s1.loss_bbox_cls: 0.0143, s1.loss_bbox_reg: 0.0312, s2.loss_cls: 0.0101, s2.acc: 98.4406, s2.loss_bbox_cls: 0.0076, s2.loss_bbox_reg: 0.0177, loss: 0.1900, grad_norm: 5.5141\n",
            "2020-09-09 11:19:23,470 - mmdet - INFO - Epoch [16][2816/5332]\tlr: 1.000e-05, eta: 12:51:42, time: 1.932, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0284, s0.acc: 98.7976, s0.loss_bbox_cls: 0.0238, s0.loss_bbox_reg: 0.0465, s1.loss_cls: 0.0201, s1.acc: 98.3917, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0346, s2.loss_cls: 0.0122, s2.acc: 97.9614, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0197, loss: 0.2237, grad_norm: 6.2226\n",
            "2020-09-09 11:21:27,888 - mmdet - INFO - Epoch [16][2880/5332]\tlr: 1.000e-05, eta: 12:49:39, time: 1.944, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0312, s0.acc: 98.8190, s0.loss_bbox_cls: 0.0225, s0.loss_bbox_reg: 0.0473, s1.loss_cls: 0.0236, s1.acc: 98.2391, s1.loss_bbox_cls: 0.0203, s1.loss_bbox_reg: 0.0387, s2.loss_cls: 0.0155, s2.acc: 97.5342, s2.loss_bbox_cls: 0.0127, s2.loss_bbox_reg: 0.0235, loss: 0.2454, grad_norm: 6.1257\n",
            "2020-09-09 11:23:32,648 - mmdet - INFO - Epoch [16][2944/5332]\tlr: 1.000e-05, eta: 12:47:38, time: 1.949, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0262, s0.acc: 98.9685, s0.loss_bbox_cls: 0.0241, s0.loss_bbox_reg: 0.0450, s1.loss_cls: 0.0190, s1.acc: 98.3978, s1.loss_bbox_cls: 0.0180, s1.loss_bbox_reg: 0.0322, s2.loss_cls: 0.0116, s2.acc: 97.8424, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0194, loss: 0.2129, grad_norm: 5.2466\n",
            "2020-09-09 11:25:35,453 - mmdet - INFO - Epoch [16][3008/5332]\tlr: 1.000e-05, eta: 12:45:22, time: 1.919, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0225, s0.acc: 99.1028, s0.loss_bbox_cls: 0.0181, s0.loss_bbox_reg: 0.0406, s1.loss_cls: 0.0167, s1.acc: 98.7610, s1.loss_bbox_cls: 0.0155, s1.loss_bbox_reg: 0.0326, s2.loss_cls: 0.0108, s2.acc: 98.4100, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0195, loss: 0.1932, grad_norm: 5.0317\n",
            "2020-09-09 11:27:38,619 - mmdet - INFO - Epoch [16][3072/5332]\tlr: 1.000e-05, eta: 12:43:10, time: 1.924, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0263, s0.acc: 99.1028, s0.loss_bbox_cls: 0.0218, s0.loss_bbox_reg: 0.0457, s1.loss_cls: 0.0182, s1.acc: 98.5687, s1.loss_bbox_cls: 0.0189, s1.loss_bbox_reg: 0.0365, s2.loss_cls: 0.0118, s2.acc: 97.8119, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0210, loss: 0.2171, grad_norm: 5.7776\n",
            "2020-09-09 11:29:41,201 - mmdet - INFO - Epoch [16][3136/5332]\tlr: 1.000e-05, eta: 12:40:53, time: 1.915, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0233, s0.acc: 98.9929, s0.loss_bbox_cls: 0.0197, s0.loss_bbox_reg: 0.0397, s1.loss_cls: 0.0183, s1.acc: 98.5565, s1.loss_bbox_cls: 0.0181, s1.loss_bbox_reg: 0.0320, s2.loss_cls: 0.0137, s2.acc: 97.9004, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0188, loss: 0.2037, grad_norm: 5.6364\n",
            "2020-09-09 11:31:45,477 - mmdet - INFO - Epoch [16][3200/5332]\tlr: 1.000e-05, eta: 12:38:49, time: 1.942, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0224, s0.acc: 99.0509, s0.loss_bbox_cls: 0.0179, s0.loss_bbox_reg: 0.0446, s1.loss_cls: 0.0174, s1.acc: 98.5657, s1.loss_bbox_cls: 0.0165, s1.loss_bbox_reg: 0.0365, s2.loss_cls: 0.0119, s2.acc: 97.8241, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0228, loss: 0.2087, grad_norm: 5.7911\n",
            "2020-09-09 11:33:52,517 - mmdet - INFO - Epoch [16][3264/5332]\tlr: 1.000e-05, eta: 12:37:05, time: 1.985, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0317, s0.acc: 98.8434, s0.loss_bbox_cls: 0.0251, s0.loss_bbox_reg: 0.0490, s1.loss_cls: 0.0235, s1.acc: 98.2147, s1.loss_bbox_cls: 0.0202, s1.loss_bbox_reg: 0.0377, s2.loss_cls: 0.0150, s2.acc: 97.6318, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0206, loss: 0.2439, grad_norm: 6.1144\n",
            "2020-09-09 11:35:57,322 - mmdet - INFO - Epoch [16][3328/5332]\tlr: 1.000e-05, eta: 12:35:05, time: 1.950, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0026, s0.loss_cls: 0.0264, s0.acc: 98.9441, s0.loss_bbox_cls: 0.0196, s0.loss_bbox_reg: 0.0423, s1.loss_cls: 0.0203, s1.acc: 98.2056, s1.loss_bbox_cls: 0.0157, s1.loss_bbox_reg: 0.0319, s2.loss_cls: 0.0115, s2.acc: 97.9187, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0191, loss: 0.2010, grad_norm: 5.8145\n",
            "2020-09-09 11:38:02,299 - mmdet - INFO - Epoch [16][3392/5332]\tlr: 1.000e-05, eta: 12:33:05, time: 1.953, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0194, s0.acc: 99.1638, s0.loss_bbox_cls: 0.0179, s0.loss_bbox_reg: 0.0418, s1.loss_cls: 0.0158, s1.acc: 98.7000, s1.loss_bbox_cls: 0.0165, s1.loss_bbox_reg: 0.0347, s2.loss_cls: 0.0099, s2.acc: 98.2758, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0219, loss: 0.1944, grad_norm: 5.0815\n",
            "2020-09-09 11:40:06,049 - mmdet - INFO - Epoch [16][3456/5332]\tlr: 1.000e-05, eta: 12:30:58, time: 1.934, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0074, s0.loss_cls: 0.0238, s0.acc: 99.0906, s0.loss_bbox_cls: 0.0214, s0.loss_bbox_reg: 0.0411, s1.loss_cls: 0.0176, s1.acc: 98.6725, s1.loss_bbox_cls: 0.0165, s1.loss_bbox_reg: 0.0303, s2.loss_cls: 0.0126, s2.acc: 98.0011, s2.loss_bbox_cls: 0.0087, s2.loss_bbox_reg: 0.0165, loss: 0.2001, grad_norm: 5.1198\n",
            "2020-09-09 11:42:10,682 - mmdet - INFO - Epoch [16][3520/5332]\tlr: 1.000e-05, eta: 12:28:56, time: 1.947, data_time: 0.005, memory: 9012, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0229, s0.acc: 99.0631, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0421, s1.loss_cls: 0.0171, s1.acc: 98.6176, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0318, s2.loss_cls: 0.0106, s2.acc: 98.2391, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0193, loss: 0.2001, grad_norm: 5.2893\n",
            "2020-09-09 11:44:15,681 - mmdet - INFO - Epoch [16][3584/5332]\tlr: 1.000e-05, eta: 12:26:56, time: 1.953, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0271, s0.acc: 98.9319, s0.loss_bbox_cls: 0.0239, s0.loss_bbox_reg: 0.0515, s1.loss_cls: 0.0203, s1.acc: 98.3307, s1.loss_bbox_cls: 0.0184, s1.loss_bbox_reg: 0.0384, s2.loss_cls: 0.0130, s2.acc: 97.9462, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0219, loss: 0.2319, grad_norm: 6.3285\n",
            "2020-09-09 11:46:20,974 - mmdet - INFO - Epoch [16][3648/5332]\tlr: 1.000e-05, eta: 12:24:58, time: 1.958, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0206, s0.acc: 99.1211, s0.loss_bbox_cls: 0.0191, s0.loss_bbox_reg: 0.0419, s1.loss_cls: 0.0141, s1.acc: 98.8251, s1.loss_bbox_cls: 0.0157, s1.loss_bbox_reg: 0.0325, s2.loss_cls: 0.0085, s2.acc: 98.5992, s2.loss_bbox_cls: 0.0087, s2.loss_bbox_reg: 0.0186, loss: 0.1873, grad_norm: 5.1315\n",
            "2020-09-09 11:48:25,973 - mmdet - INFO - Epoch [16][3712/5332]\tlr: 1.000e-05, eta: 12:22:58, time: 1.953, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0272, s0.acc: 98.9471, s0.loss_bbox_cls: 0.0291, s0.loss_bbox_reg: 0.0547, s1.loss_cls: 0.0191, s1.acc: 98.4497, s1.loss_bbox_cls: 0.0223, s1.loss_bbox_reg: 0.0417, s2.loss_cls: 0.0127, s2.acc: 97.8058, s2.loss_bbox_cls: 0.0110, s2.loss_bbox_reg: 0.0230, loss: 0.2504, grad_norm: 5.9682\n",
            "2020-09-09 11:50:29,942 - mmdet - INFO - Epoch [16][3776/5332]\tlr: 1.000e-05, eta: 12:20:51, time: 1.937, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0223, s0.acc: 99.1577, s0.loss_bbox_cls: 0.0223, s0.loss_bbox_reg: 0.0436, s1.loss_cls: 0.0171, s1.acc: 98.5809, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0338, s2.loss_cls: 0.0101, s2.acc: 98.2269, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0193, loss: 0.2049, grad_norm: 4.9825\n",
            "2020-09-09 11:52:34,326 - mmdet - INFO - Epoch [16][3840/5332]\tlr: 1.000e-05, eta: 12:18:47, time: 1.943, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0259, s0.acc: 99.0265, s0.loss_bbox_cls: 0.0247, s0.loss_bbox_reg: 0.0465, s1.loss_cls: 0.0213, s1.acc: 98.3948, s1.loss_bbox_cls: 0.0189, s1.loss_bbox_reg: 0.0352, s2.loss_cls: 0.0136, s2.acc: 97.9553, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0212, loss: 0.2259, grad_norm: 5.7229\n",
            "2020-09-09 11:54:38,138 - mmdet - INFO - Epoch [16][3904/5332]\tlr: 1.000e-05, eta: 12:16:40, time: 1.935, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0292, s0.acc: 98.7549, s0.loss_bbox_cls: 0.0263, s0.loss_bbox_reg: 0.0525, s1.loss_cls: 0.0199, s1.acc: 98.1567, s1.loss_bbox_cls: 0.0224, s1.loss_bbox_reg: 0.0401, s2.loss_cls: 0.0134, s2.acc: 97.7142, s2.loss_bbox_cls: 0.0124, s2.loss_bbox_reg: 0.0234, loss: 0.2479, grad_norm: 6.1516\n",
            "2020-09-09 11:56:43,476 - mmdet - INFO - Epoch [16][3968/5332]\tlr: 1.000e-05, eta: 12:14:42, time: 1.958, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0079, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0237, s0.acc: 99.0814, s0.loss_bbox_cls: 0.0216, s0.loss_bbox_reg: 0.0465, s1.loss_cls: 0.0143, s1.acc: 98.8922, s1.loss_bbox_cls: 0.0166, s1.loss_bbox_reg: 0.0361, s2.loss_cls: 0.0087, s2.acc: 98.6359, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0223, loss: 0.2123, grad_norm: 5.7094\n",
            "2020-09-09 11:58:48,349 - mmdet - INFO - Epoch [16][4032/5332]\tlr: 1.000e-05, eta: 12:12:40, time: 1.951, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0228, s0.acc: 99.0051, s0.loss_bbox_cls: 0.0195, s0.loss_bbox_reg: 0.0431, s1.loss_cls: 0.0179, s1.acc: 98.3734, s1.loss_bbox_cls: 0.0158, s1.loss_bbox_reg: 0.0333, s2.loss_cls: 0.0114, s2.acc: 98.1476, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0200, loss: 0.2001, grad_norm: 5.4486\n",
            "2020-09-09 12:00:53,270 - mmdet - INFO - Epoch [16][4096/5332]\tlr: 1.000e-05, eta: 12:10:39, time: 1.952, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0219, s0.acc: 99.1241, s0.loss_bbox_cls: 0.0201, s0.loss_bbox_reg: 0.0440, s1.loss_cls: 0.0178, s1.acc: 98.6572, s1.loss_bbox_cls: 0.0180, s1.loss_bbox_reg: 0.0378, s2.loss_cls: 0.0119, s2.acc: 97.9736, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0222, loss: 0.2115, grad_norm: 5.6259\n",
            "2020-09-09 12:02:58,789 - mmdet - INFO - Epoch [16][4160/5332]\tlr: 1.000e-05, eta: 12:08:41, time: 1.961, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0262, s0.acc: 99.0082, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0467, s1.loss_cls: 0.0183, s1.acc: 98.6298, s1.loss_bbox_cls: 0.0164, s1.loss_bbox_reg: 0.0343, s2.loss_cls: 0.0101, s2.acc: 98.3063, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0212, loss: 0.2110, grad_norm: 5.7987\n",
            "2020-09-09 12:05:04,673 - mmdet - INFO - Epoch [16][4224/5332]\tlr: 1.000e-05, eta: 12:06:45, time: 1.967, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0213, s0.acc: 99.1364, s0.loss_bbox_cls: 0.0234, s0.loss_bbox_reg: 0.0488, s1.loss_cls: 0.0138, s1.acc: 98.9349, s1.loss_bbox_cls: 0.0209, s1.loss_bbox_reg: 0.0400, s2.loss_cls: 0.0095, s2.acc: 98.3429, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0218, loss: 0.2182, grad_norm: 6.0747\n",
            "2020-09-09 12:07:08,523 - mmdet - INFO - Epoch [16][4288/5332]\tlr: 1.000e-05, eta: 12:04:38, time: 1.935, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0264, s0.acc: 99.0082, s0.loss_bbox_cls: 0.0232, s0.loss_bbox_reg: 0.0481, s1.loss_cls: 0.0183, s1.acc: 98.5443, s1.loss_bbox_cls: 0.0196, s1.loss_bbox_reg: 0.0383, s2.loss_cls: 0.0109, s2.acc: 98.3582, s2.loss_bbox_cls: 0.0116, s2.loss_bbox_reg: 0.0235, loss: 0.2273, grad_norm: 6.1393\n",
            "2020-09-09 12:09:13,358 - mmdet - INFO - Epoch [16][4352/5332]\tlr: 1.000e-05, eta: 12:02:36, time: 1.951, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0208, s0.acc: 99.1669, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0438, s1.loss_cls: 0.0149, s1.acc: 98.8068, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0349, s2.loss_cls: 0.0107, s2.acc: 98.1018, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0210, loss: 0.2023, grad_norm: 5.6326\n",
            "2020-09-09 12:11:19,467 - mmdet - INFO - Epoch [16][4416/5332]\tlr: 1.000e-05, eta: 12:00:40, time: 1.970, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0231, s0.acc: 99.1394, s0.loss_bbox_cls: 0.0202, s0.loss_bbox_reg: 0.0448, s1.loss_cls: 0.0174, s1.acc: 98.8190, s1.loss_bbox_cls: 0.0175, s1.loss_bbox_reg: 0.0358, s2.loss_cls: 0.0108, s2.acc: 98.6084, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0226, loss: 0.2118, grad_norm: 5.8630\n",
            "2020-09-09 12:13:23,049 - mmdet - INFO - Epoch [16][4480/5332]\tlr: 1.000e-05, eta: 11:58:32, time: 1.931, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0275, s0.acc: 98.9319, s0.loss_bbox_cls: 0.0232, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0198, s1.acc: 98.4100, s1.loss_bbox_cls: 0.0184, s1.loss_bbox_reg: 0.0339, s2.loss_cls: 0.0116, s2.acc: 98.2330, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0203, loss: 0.2187, grad_norm: 5.7265\n",
            "2020-09-09 12:15:29,033 - mmdet - INFO - Epoch [16][4544/5332]\tlr: 1.000e-05, eta: 11:56:35, time: 1.968, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0245, s0.acc: 99.1058, s0.loss_bbox_cls: 0.0243, s0.loss_bbox_reg: 0.0497, s1.loss_cls: 0.0201, s1.acc: 98.2971, s1.loss_bbox_cls: 0.0227, s1.loss_bbox_reg: 0.0404, s2.loss_cls: 0.0136, s2.acc: 97.5311, s2.loss_bbox_cls: 0.0121, s2.loss_bbox_reg: 0.0245, loss: 0.2396, grad_norm: 6.1293\n",
            "2020-09-09 12:17:33,956 - mmdet - INFO - Epoch [16][4608/5332]\tlr: 1.000e-05, eta: 11:54:33, time: 1.952, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0226, s0.acc: 99.0662, s0.loss_bbox_cls: 0.0185, s0.loss_bbox_reg: 0.0394, s1.loss_cls: 0.0160, s1.acc: 98.5718, s1.loss_bbox_cls: 0.0151, s1.loss_bbox_reg: 0.0316, s2.loss_cls: 0.0097, s2.acc: 98.5474, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0209, loss: 0.1923, grad_norm: 5.3481\n",
            "2020-09-09 12:19:37,800 - mmdet - INFO - Epoch [16][4672/5332]\tlr: 1.000e-05, eta: 11:52:26, time: 1.935, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0231, s0.acc: 99.1058, s0.loss_bbox_cls: 0.0197, s0.loss_bbox_reg: 0.0433, s1.loss_cls: 0.0172, s1.acc: 98.5626, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0350, s2.loss_cls: 0.0119, s2.acc: 98.2483, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0207, loss: 0.2067, grad_norm: 5.7595\n",
            "2020-09-09 12:21:41,239 - mmdet - INFO - Epoch [16][4736/5332]\tlr: 1.000e-05, eta: 11:50:17, time: 1.929, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0241, s0.acc: 99.1119, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0448, s1.loss_cls: 0.0143, s1.acc: 98.9319, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0334, s2.loss_cls: 0.0088, s2.acc: 98.8434, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0206, loss: 0.2015, grad_norm: 5.6807\n",
            "2020-09-09 12:23:44,418 - mmdet - INFO - Epoch [16][4800/5332]\tlr: 1.000e-05, eta: 11:48:07, time: 1.925, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0237, s0.acc: 99.0662, s0.loss_bbox_cls: 0.0242, s0.loss_bbox_reg: 0.0529, s1.loss_cls: 0.0158, s1.acc: 98.6938, s1.loss_bbox_cls: 0.0189, s1.loss_bbox_reg: 0.0390, s2.loss_cls: 0.0101, s2.acc: 98.3185, s2.loss_bbox_cls: 0.0110, s2.loss_bbox_reg: 0.0244, loss: 0.2278, grad_norm: 6.2672\n",
            "2020-09-09 12:25:47,657 - mmdet - INFO - Epoch [16][4864/5332]\tlr: 1.000e-05, eta: 11:45:57, time: 1.926, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0261, s0.acc: 99.0082, s0.loss_bbox_cls: 0.0269, s0.loss_bbox_reg: 0.0522, s1.loss_cls: 0.0188, s1.acc: 98.4192, s1.loss_bbox_cls: 0.0207, s1.loss_bbox_reg: 0.0394, s2.loss_cls: 0.0114, s2.acc: 98.2971, s2.loss_bbox_cls: 0.0122, s2.loss_bbox_reg: 0.0240, loss: 0.2426, grad_norm: 5.8308\n",
            "2020-09-09 12:27:52,218 - mmdet - INFO - Epoch [16][4928/5332]\tlr: 1.000e-05, eta: 11:43:54, time: 1.946, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0248, s0.acc: 99.0479, s0.loss_bbox_cls: 0.0257, s0.loss_bbox_reg: 0.0495, s1.loss_cls: 0.0181, s1.acc: 98.6694, s1.loss_bbox_cls: 0.0205, s1.loss_bbox_reg: 0.0374, s2.loss_cls: 0.0109, s2.acc: 98.4924, s2.loss_bbox_cls: 0.0115, s2.loss_bbox_reg: 0.0226, loss: 0.2289, grad_norm: 5.9369\n",
            "2020-09-09 12:29:56,895 - mmdet - INFO - Epoch [16][4992/5332]\tlr: 1.000e-05, eta: 11:41:50, time: 1.948, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0202, s0.acc: 99.2310, s0.loss_bbox_cls: 0.0203, s0.loss_bbox_reg: 0.0431, s1.loss_cls: 0.0181, s1.acc: 98.4619, s1.loss_bbox_cls: 0.0188, s1.loss_bbox_reg: 0.0364, s2.loss_cls: 0.0120, s2.acc: 97.8516, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0202, loss: 0.2070, grad_norm: 5.4459\n",
            "2020-09-09 12:31:59,064 - mmdet - INFO - Epoch [16][5056/5332]\tlr: 1.000e-05, eta: 11:39:37, time: 1.909, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0187, s0.acc: 99.3805, s0.loss_bbox_cls: 0.0187, s0.loss_bbox_reg: 0.0407, s1.loss_cls: 0.0145, s1.acc: 98.9777, s1.loss_bbox_cls: 0.0176, s1.loss_bbox_reg: 0.0339, s2.loss_cls: 0.0099, s2.acc: 98.5382, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0203, loss: 0.1912, grad_norm: 5.1474\n",
            "2020-09-09 12:34:04,276 - mmdet - INFO - Epoch [16][5120/5332]\tlr: 1.000e-05, eta: 11:37:36, time: 1.956, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0181, s0.acc: 99.3103, s0.loss_bbox_cls: 0.0178, s0.loss_bbox_reg: 0.0436, s1.loss_cls: 0.0135, s1.acc: 98.9960, s1.loss_bbox_cls: 0.0168, s1.loss_bbox_reg: 0.0365, s2.loss_cls: 0.0089, s2.acc: 98.6359, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0232, loss: 0.1972, grad_norm: 5.8759\n",
            "2020-09-09 12:36:09,152 - mmdet - INFO - Epoch [16][5184/5332]\tlr: 1.000e-05, eta: 11:35:34, time: 1.951, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0245, s0.acc: 99.0540, s0.loss_bbox_cls: 0.0230, s0.loss_bbox_reg: 0.0431, s1.loss_cls: 0.0215, s1.acc: 98.2605, s1.loss_bbox_cls: 0.0175, s1.loss_bbox_reg: 0.0335, s2.loss_cls: 0.0148, s2.acc: 97.4121, s2.loss_bbox_cls: 0.0092, s2.loss_bbox_reg: 0.0182, loss: 0.2135, grad_norm: 5.7747\n",
            "2020-09-09 12:38:11,685 - mmdet - INFO - Epoch [16][5248/5332]\tlr: 1.000e-05, eta: 11:33:22, time: 1.915, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0234, s0.acc: 99.2310, s0.loss_bbox_cls: 0.0172, s0.loss_bbox_reg: 0.0387, s1.loss_cls: 0.0170, s1.acc: 98.8586, s1.loss_bbox_cls: 0.0151, s1.loss_bbox_reg: 0.0329, s2.loss_cls: 0.0095, s2.acc: 98.5504, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0210, loss: 0.1964, grad_norm: 5.3397\n",
            "2020-09-09 12:40:16,149 - mmdet - INFO - Epoch [16][5312/5332]\tlr: 1.000e-05, eta: 11:31:18, time: 1.945, data_time: 0.004, memory: 9012, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0220, s0.acc: 99.1302, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0429, s1.loss_cls: 0.0168, s1.acc: 98.6298, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0342, s2.loss_cls: 0.0119, s2.acc: 98.0957, s2.loss_bbox_cls: 0.0082, s2.loss_bbox_reg: 0.0184, loss: 0.2003, grad_norm: 5.0687\n",
            "2020-09-09 12:40:55,341 - mmdet - INFO - Saving checkpoint at 16 epochs\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1129s, ETA:     0s2020-09-09 12:59:51,855 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 270  | 0.841  | 0.668 |\n",
            "| 3     | 22  | 63   | 0.773  | 0.664 |\n",
            "| 4     | 529 | 1233 | 0.922  | 0.832 |\n",
            "| 5     | 78  | 178  | 0.872  | 0.782 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.737 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-09 12:59:51,859 - mmdet - INFO - Epoch(val) [16][5332]\tmAP: 0.7367\n",
            "Process Process-7:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/local/lib/python3.7/threading.py\", line 1044, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/local/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waaf7HDz9J1e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "6dfa9dd5-33bc-4b53-88af-79bdea11b724"
      },
      "source": [
        "!python tools/test.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_16.pth --eval mAP"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1149s, ETA:     0s\n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 86  | 312  | 0.849  | 0.668 |\n",
            "| 3     | 20  | 59   | 0.850  | 0.839 |\n",
            "| 4     | 547 | 1351 | 0.916  | 0.812 |\n",
            "| 5     | 64  | 162  | 1.000  | 0.920 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.810 |\n",
            "+-------+-----+------+--------+-------+\n",
            "{'mAP': 0.8097518682479858}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyJwvD1r-uM_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a42d4e10-dfaf-455c-e42b-778e06b8da8c"
      },
      "source": [
        "!python tools/train.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py --resume-from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_16.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-09 13:20:47,178 - mmdet - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]\n",
            "CUDA available: True\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
            "GPU 0: Tesla P100-PCIE-16GB\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.4.0\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CUDA Runtime 10.0\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.1\n",
            "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "TorchVision: 0.5.0\n",
            "OpenCV: 4.4.0\n",
            "MMCV: 1.1.2\n",
            "MMDetection: 2.3.0+\n",
            "MMDetection Compiler: GCC 7.5\n",
            "MMDetection CUDA Compiler: 10.1\n",
            "------------------------------------------------------------\n",
            "\n",
            "2020-09-09 13:20:47,843 - mmdet - INFO - Distributed training: False\n",
            "2020-09-09 13:20:48,522 - mmdet - INFO - Config:\n",
            "model = dict(\n",
            "    type='CascadeRCNN',\n",
            "    pretrained='open-mmlab://resnext101_32x4d',\n",
            "    backbone=dict(\n",
            "        type='DetectoRS_ResNeXt',\n",
            "        depth=101,\n",
            "        groups=32,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch',\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(False, True, True, True),\n",
            "        output_img=True),\n",
            "    neck=dict(\n",
            "        type='RFP',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5,\n",
            "        rfp_steps=2,\n",
            "        aspp_out_channels=64,\n",
            "        aspp_dilations=(1, 3, 6, 1),\n",
            "        rfp_backbone=dict(\n",
            "            rfp_inplanes=256,\n",
            "            type='DetectoRS_ResNeXt',\n",
            "            depth=101,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(False, True, True, True),\n",
            "            pretrained='open-mmlab://resnext101_32x4d',\n",
            "            style='pytorch')),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(\n",
            "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='CascadeRoIHead',\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[1, 0.5, 0.25],\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='GenericRoIExtractor',\n",
            "            aggregation='sum',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32],\n",
            "            pre_cfg=dict(\n",
            "                type='ConvModule',\n",
            "                in_channels=256,\n",
            "                out_channels=256,\n",
            "                kernel_size=5,\n",
            "                padding=2,\n",
            "                inplace=False),\n",
            "            post_cfg=dict(\n",
            "                type='GeneralizedAttention',\n",
            "                in_channels=256,\n",
            "                spatial_range=-1,\n",
            "                num_heads=6,\n",
            "                attention_type='0100',\n",
            "                kv_stride=2)),\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.7),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.5),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.3),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0))\n",
            "        ]))\n",
            "train_cfg = dict(\n",
            "    rpn=dict(\n",
            "        assigner=dict(\n",
            "            type='MaxIoUAssigner',\n",
            "            pos_iou_thr=0.7,\n",
            "            neg_iou_thr=0.3,\n",
            "            min_pos_iou=0.3,\n",
            "            match_low_quality=True,\n",
            "            ignore_iof_thr=-1),\n",
            "        sampler=dict(\n",
            "            type='RandomSampler',\n",
            "            num=256,\n",
            "            pos_fraction=0.5,\n",
            "            neg_pos_ub=-1,\n",
            "            add_gt_as_proposals=False),\n",
            "        allowed_border=0,\n",
            "        pos_weight=-1,\n",
            "        debug=False),\n",
            "    rpn_proposal=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=2000,\n",
            "        nms_post=2000,\n",
            "        max_num=2000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=[\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.6,\n",
            "                neg_iou_thr=0.6,\n",
            "                min_pos_iou=0.6,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.7,\n",
            "                min_pos_iou=0.7,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)\n",
            "    ])\n",
            "test_cfg = dict(\n",
            "    rpn=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=1000,\n",
            "        nms_post=1000,\n",
            "        max_num=1000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=dict(\n",
            "        score_thr=0.05,\n",
            "        nms=dict(type='nms', iou_threshold=0.5),\n",
            "        max_per_img=100))\n",
            "dataset_type = 'CustomDataset'\n",
            "data_root = 'data/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "albu_train_transforms = [\n",
            "    dict(\n",
            "        type='ShiftScaleRotate',\n",
            "        shift_limit=0.0625,\n",
            "        scale_limit=0.0,\n",
            "        rotate_limit=0,\n",
            "        interpolation=1,\n",
            "        p=0.5),\n",
            "    dict(\n",
            "        type='RandomBrightnessContrast',\n",
            "        brightness_limit=[0.1, 0.3],\n",
            "        contrast_limit=[0.1, 0.3],\n",
            "        p=0.2),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='RGBShift',\n",
            "                r_shift_limit=10,\n",
            "                g_shift_limit=10,\n",
            "                b_shift_limit=10,\n",
            "                p=1.0),\n",
            "            dict(\n",
            "                type='HueSaturationValue',\n",
            "                hue_shift_limit=20,\n",
            "                sat_shift_limit=30,\n",
            "                val_shift_limit=20,\n",
            "                p=1.0)\n",
            "        ],\n",
            "        p=0.1),\n",
            "    dict(type='JpegCompression', quality_lower=85, quality_upper=95, p=0.2),\n",
            "    dict(type='ChannelShuffle', p=0.1),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "        ],\n",
            "        p=0.1)\n",
            "]\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        type='Resize',\n",
            "        multiscale_mode='range',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(\n",
            "        type='Albu',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='ShiftScaleRotate',\n",
            "                shift_limit=0.0625,\n",
            "                scale_limit=0.0,\n",
            "                rotate_limit=0,\n",
            "                interpolation=1,\n",
            "                p=0.5),\n",
            "            dict(\n",
            "                type='RandomBrightnessContrast',\n",
            "                brightness_limit=[0.1, 0.3],\n",
            "                contrast_limit=[0.1, 0.3],\n",
            "                p=0.2),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='RGBShift',\n",
            "                        r_shift_limit=10,\n",
            "                        g_shift_limit=10,\n",
            "                        b_shift_limit=10,\n",
            "                        p=1.0),\n",
            "                    dict(\n",
            "                        type='HueSaturationValue',\n",
            "                        hue_shift_limit=20,\n",
            "                        sat_shift_limit=30,\n",
            "                        val_shift_limit=20,\n",
            "                        p=1.0)\n",
            "                ],\n",
            "                p=0.1),\n",
            "            dict(\n",
            "                type='JpegCompression',\n",
            "                quality_lower=85,\n",
            "                quality_upper=95,\n",
            "                p=0.2),\n",
            "            dict(type='ChannelShuffle', p=0.1),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                    dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                ],\n",
            "                p=0.1)\n",
            "        ],\n",
            "        bbox_params=dict(\n",
            "            type='BboxParams',\n",
            "            format='pascal_voc',\n",
            "            label_fields=['gt_labels'],\n",
            "            min_visibility=0.0,\n",
            "            filter_lost_elements=True),\n",
            "        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "        update_pad_shape=False,\n",
            "        skip_img_without_anno=True),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(\n",
            "        type='Collect',\n",
            "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "        meta_keys=('filename', 'ori_shape', 'img_shape', 'img_norm_cfg',\n",
            "                   'pad_shape', 'scale_factor'))\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        transforms=[\n",
            "            dict(type='Resize', multiscale_mode='range', keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=1.0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=1,\n",
            "    workers_per_gpu=1,\n",
            "    train=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/train_80_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                multiscale_mode='range',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(\n",
            "                type='Albu',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='ShiftScaleRotate',\n",
            "                        shift_limit=0.0625,\n",
            "                        scale_limit=0.0,\n",
            "                        rotate_limit=0,\n",
            "                        interpolation=1,\n",
            "                        p=0.5),\n",
            "                    dict(\n",
            "                        type='RandomBrightnessContrast',\n",
            "                        brightness_limit=[0.1, 0.3],\n",
            "                        contrast_limit=[0.1, 0.3],\n",
            "                        p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(\n",
            "                                type='RGBShift',\n",
            "                                r_shift_limit=10,\n",
            "                                g_shift_limit=10,\n",
            "                                b_shift_limit=10,\n",
            "                                p=1.0),\n",
            "                            dict(\n",
            "                                type='HueSaturationValue',\n",
            "                                hue_shift_limit=20,\n",
            "                                sat_shift_limit=30,\n",
            "                                val_shift_limit=20,\n",
            "                                p=1.0)\n",
            "                        ],\n",
            "                        p=0.1),\n",
            "                    dict(\n",
            "                        type='JpegCompression',\n",
            "                        quality_lower=75,\n",
            "                        quality_upper=95,\n",
            "                        p=0.2),\n",
            "                    dict(type='ChannelShuffle', p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                        ],\n",
            "                        p=0.1)\n",
            "                ],\n",
            "                bbox_params=dict(\n",
            "                    type='BboxParams',\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=['gt_labels'],\n",
            "                    min_visibility=0.0,\n",
            "                    filter_lost_elements=True),\n",
            "                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "                update_pad_shape=False,\n",
            "                skip_img_without_anno=True),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "                meta_keys=('filename', 'ori_shape', 'img_shape',\n",
            "                           'img_norm_cfg', 'pad_shape', 'scale_factor'))\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/val_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/test_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 200), (1999, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=1, metric='mAP')\n",
            "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.3333333333333333,\n",
            "    step=[8, 11])\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=64, hooks=[dict(type='TextLoggerHook')])\n",
            "total_epochs = 20\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "work_dir = './work_dirs/cascade_rcnn_x101_32x4d_fpn_1x'\n",
            "load_from = None\n",
            "resume_from = 'work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_16.pth'\n",
            "workflow = [('train', 1)]\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "2020-09-09 13:20:51,963 - mmdet - INFO - load model from: open-mmlab://resnext101_32x4d\n",
            "2020-09-09 13:20:52,486 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "2020-09-09 13:20:53,088 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
            "size mismatch for layer1.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.2.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
            "size mismatch for layer2.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.0.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.1.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.1.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.2.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.2.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.2.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.3.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.3.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.3.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
            "size mismatch for layer3.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.2.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.3.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.3.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.3.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.4.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.4.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.4.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.5.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.5.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.5.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.6.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.6.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.6.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.7.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.7.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.7.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.8.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.8.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.8.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.9.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.9.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.9.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.10.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.10.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.10.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.11.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.11.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.11.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.12.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.12.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.12.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.13.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.13.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.13.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.14.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.14.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.14.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.15.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.15.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.15.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.16.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.16.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.16.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.17.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.17.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.17.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.18.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.18.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.18.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.19.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.19.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.19.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.20.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.20.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.20.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.21.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.21.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.21.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.22.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.22.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.22.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
            "size mismatch for layer4.0.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.0.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.1.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.1.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.2.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.2.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.2.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-09 13:20:56,554 - mmdet - INFO - load checkpoint from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_16.pth\n",
            "2020-09-09 13:21:00,157 - mmdet - INFO - resumed epoch 16, iter 85312\n",
            "2020-09-09 13:21:00,164 - mmdet - INFO - Start running, host: root@25aa13c3b0a1, work_dir: /content/drive/My Drive/mmdetection-master/work_dirs/cascade_rcnn_x101_32x4d_fpn_1x\n",
            "2020-09-09 13:21:00,164 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs\n",
            "2020-09-09 13:23:09,185 - mmdet - INFO - Epoch [17][64/5332]\tlr: 1.000e-05, eta: 11:54:23, time: 2.016, data_time: 0.037, memory: 8999, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0265, s0.acc: 98.9777, s0.loss_bbox_cls: 0.0199, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0201, s1.acc: 98.3917, s1.loss_bbox_cls: 0.0157, s1.loss_bbox_reg: 0.0339, s2.loss_cls: 0.0121, s2.acc: 98.0560, s2.loss_bbox_cls: 0.0092, s2.loss_bbox_reg: 0.0205, loss: 0.2110, grad_norm: 5.8967\n",
            "2020-09-09 13:25:14,702 - mmdet - INFO - Epoch [17][128/5332]\tlr: 1.000e-05, eta: 11:42:35, time: 1.961, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0288, s0.acc: 98.9807, s0.loss_bbox_cls: 0.0225, s0.loss_bbox_reg: 0.0480, s1.loss_cls: 0.0192, s1.acc: 98.6145, s1.loss_bbox_cls: 0.0193, s1.loss_bbox_reg: 0.0377, s2.loss_cls: 0.0121, s2.acc: 98.2208, s2.loss_bbox_cls: 0.0119, s2.loss_bbox_reg: 0.0240, loss: 0.2308, grad_norm: 5.8792\n",
            "2020-09-09 13:27:19,966 - mmdet - INFO - Epoch [17][192/5332]\tlr: 1.000e-05, eta: 11:36:48, time: 1.957, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0173, s0.acc: 99.3256, s0.loss_bbox_cls: 0.0182, s0.loss_bbox_reg: 0.0383, s1.loss_cls: 0.0123, s1.acc: 98.9624, s1.loss_bbox_cls: 0.0164, s1.loss_bbox_reg: 0.0311, s2.loss_cls: 0.0083, s2.acc: 98.5657, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0184, loss: 0.1770, grad_norm: 4.9143\n",
            "2020-09-09 13:29:25,572 - mmdet - INFO - Epoch [17][256/5332]\tlr: 1.000e-05, eta: 11:33:20, time: 1.963, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0244, s0.acc: 99.1760, s0.loss_bbox_cls: 0.0185, s0.loss_bbox_reg: 0.0423, s1.loss_cls: 0.0155, s1.acc: 98.8007, s1.loss_bbox_cls: 0.0145, s1.loss_bbox_reg: 0.0320, s2.loss_cls: 0.0092, s2.acc: 98.5382, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0210, loss: 0.1958, grad_norm: 5.5538\n",
            "2020-09-09 13:31:31,514 - mmdet - INFO - Epoch [17][320/5332]\tlr: 1.000e-05, eta: 11:30:47, time: 1.968, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0218, s0.acc: 99.1364, s0.loss_bbox_cls: 0.0197, s0.loss_bbox_reg: 0.0453, s1.loss_cls: 0.0154, s1.acc: 98.8068, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0386, s2.loss_cls: 0.0095, s2.acc: 98.4741, s2.loss_bbox_cls: 0.0110, s2.loss_bbox_reg: 0.0240, loss: 0.2099, grad_norm: 5.8564\n",
            "2020-09-09 13:33:37,627 - mmdet - INFO - Epoch [17][384/5332]\tlr: 1.000e-05, eta: 11:28:32, time: 1.971, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0229, s0.acc: 99.0997, s0.loss_bbox_cls: 0.0186, s0.loss_bbox_reg: 0.0403, s1.loss_cls: 0.0162, s1.acc: 98.6572, s1.loss_bbox_cls: 0.0137, s1.loss_bbox_reg: 0.0301, s2.loss_cls: 0.0094, s2.acc: 98.6206, s2.loss_bbox_cls: 0.0084, s2.loss_bbox_reg: 0.0184, loss: 0.1842, grad_norm: 5.1328\n",
            "2020-09-09 13:35:44,818 - mmdet - INFO - Epoch [17][448/5332]\tlr: 1.000e-05, eta: 11:27:10, time: 1.987, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0022, s0.loss_cls: 0.0238, s0.acc: 99.0143, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0471, s1.loss_cls: 0.0160, s1.acc: 98.7488, s1.loss_bbox_cls: 0.0172, s1.loss_bbox_reg: 0.0370, s2.loss_cls: 0.0105, s2.acc: 98.3063, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0215, loss: 0.2097, grad_norm: 5.9341\n",
            "2020-09-09 13:37:50,182 - mmdet - INFO - Epoch [17][512/5332]\tlr: 1.000e-05, eta: 11:24:22, time: 1.959, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0229, s0.acc: 99.0814, s0.loss_bbox_cls: 0.0250, s0.loss_bbox_reg: 0.0477, s1.loss_cls: 0.0154, s1.acc: 98.7610, s1.loss_bbox_cls: 0.0194, s1.loss_bbox_reg: 0.0375, s2.loss_cls: 0.0097, s2.acc: 98.4833, s2.loss_bbox_cls: 0.0112, s2.loss_bbox_reg: 0.0223, loss: 0.2182, grad_norm: 5.8450\n",
            "2020-09-09 13:39:55,227 - mmdet - INFO - Epoch [17][576/5332]\tlr: 1.000e-05, eta: 11:21:33, time: 1.954, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0255, s0.acc: 99.0265, s0.loss_bbox_cls: 0.0222, s0.loss_bbox_reg: 0.0459, s1.loss_cls: 0.0198, s1.acc: 98.4039, s1.loss_bbox_cls: 0.0174, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0124, s2.acc: 98.0560, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0207, loss: 0.2183, grad_norm: 5.8186\n",
            "2020-09-09 13:42:00,592 - mmdet - INFO - Epoch [17][640/5332]\tlr: 1.000e-05, eta: 11:19:02, time: 1.959, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0063, s0.loss_cls: 0.0277, s0.acc: 98.8922, s0.loss_bbox_cls: 0.0278, s0.loss_bbox_reg: 0.0526, s1.loss_cls: 0.0213, s1.acc: 98.2697, s1.loss_bbox_cls: 0.0210, s1.loss_bbox_reg: 0.0391, s2.loss_cls: 0.0131, s2.acc: 97.9736, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0209, loss: 0.2448, grad_norm: 6.0585\n",
            "2020-09-09 13:44:06,946 - mmdet - INFO - Epoch [17][704/5332]\tlr: 1.000e-05, eta: 11:17:05, time: 1.974, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0203, s0.acc: 99.1882, s0.loss_bbox_cls: 0.0191, s0.loss_bbox_reg: 0.0453, s1.loss_cls: 0.0165, s1.acc: 98.5748, s1.loss_bbox_cls: 0.0180, s1.loss_bbox_reg: 0.0361, s2.loss_cls: 0.0102, s2.acc: 98.1171, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0230, loss: 0.2060, grad_norm: 5.9590\n",
            "2020-09-09 13:46:12,378 - mmdet - INFO - Epoch [17][768/5332]\tlr: 1.000e-05, eta: 11:14:42, time: 1.960, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0244, s0.acc: 99.0295, s0.loss_bbox_cls: 0.0199, s0.loss_bbox_reg: 0.0445, s1.loss_cls: 0.0170, s1.acc: 98.7762, s1.loss_bbox_cls: 0.0165, s1.loss_bbox_reg: 0.0349, s2.loss_cls: 0.0114, s2.acc: 98.3337, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0219, loss: 0.2083, grad_norm: 5.4337\n",
            "2020-09-09 13:48:16,614 - mmdet - INFO - Epoch [17][832/5332]\tlr: 1.000e-05, eta: 11:11:52, time: 1.941, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0243, s0.acc: 99.0601, s0.loss_bbox_cls: 0.0238, s0.loss_bbox_reg: 0.0465, s1.loss_cls: 0.0180, s1.acc: 98.5840, s1.loss_bbox_cls: 0.0194, s1.loss_bbox_reg: 0.0372, s2.loss_cls: 0.0132, s2.acc: 98.0042, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0208, loss: 0.2223, grad_norm: 5.9466\n",
            "2020-09-09 13:50:22,180 - mmdet - INFO - Epoch [17][896/5332]\tlr: 1.000e-05, eta: 11:09:39, time: 1.962, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0234, s0.acc: 99.1302, s0.loss_bbox_cls: 0.0214, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0189, s1.acc: 98.4650, s1.loss_bbox_cls: 0.0186, s1.loss_bbox_reg: 0.0353, s2.loss_cls: 0.0128, s2.acc: 97.9187, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0209, loss: 0.2118, grad_norm: 5.7152\n",
            "2020-09-09 13:52:27,500 - mmdet - INFO - Epoch [17][960/5332]\tlr: 1.000e-05, eta: 11:07:22, time: 1.958, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0213, s0.acc: 99.1455, s0.loss_bbox_cls: 0.0192, s0.loss_bbox_reg: 0.0434, s1.loss_cls: 0.0166, s1.acc: 98.5413, s1.loss_bbox_cls: 0.0172, s1.loss_bbox_reg: 0.0337, s2.loss_cls: 0.0110, s2.acc: 98.0377, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0189, loss: 0.1966, grad_norm: 5.5217\n",
            "2020-09-09 13:54:32,799 - mmdet - INFO - Epoch [17][1024/5332]\tlr: 1.000e-05, eta: 11:05:06, time: 1.958, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0234, s0.acc: 99.1272, s0.loss_bbox_cls: 0.0235, s0.loss_bbox_reg: 0.0479, s1.loss_cls: 0.0159, s1.acc: 98.7457, s1.loss_bbox_cls: 0.0201, s1.loss_bbox_reg: 0.0376, s2.loss_cls: 0.0102, s2.acc: 98.2941, s2.loss_bbox_cls: 0.0115, s2.loss_bbox_reg: 0.0229, loss: 0.2210, grad_norm: 5.5645\n",
            "2020-09-09 13:56:38,225 - mmdet - INFO - Epoch [17][1088/5332]\tlr: 1.000e-05, eta: 11:02:53, time: 1.960, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0268, s0.acc: 98.9288, s0.loss_bbox_cls: 0.0241, s0.loss_bbox_reg: 0.0507, s1.loss_cls: 0.0175, s1.acc: 98.6572, s1.loss_bbox_cls: 0.0186, s1.loss_bbox_reg: 0.0372, s2.loss_cls: 0.0114, s2.acc: 98.0621, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0220, loss: 0.2271, grad_norm: 6.1110\n",
            "2020-09-09 13:58:44,522 - mmdet - INFO - Epoch [17][1152/5332]\tlr: 1.000e-05, eta: 11:00:57, time: 1.973, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0252, s0.acc: 99.0173, s0.loss_bbox_cls: 0.0217, s0.loss_bbox_reg: 0.0470, s1.loss_cls: 0.0165, s1.acc: 98.6633, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0356, s2.loss_cls: 0.0100, s2.acc: 98.3765, s2.loss_bbox_cls: 0.0114, s2.loss_bbox_reg: 0.0234, loss: 0.2171, grad_norm: 5.8622\n",
            "2020-09-09 14:00:51,543 - mmdet - INFO - Epoch [17][1216/5332]\tlr: 1.000e-05, eta: 10:59:11, time: 1.985, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0263, s0.acc: 98.9502, s0.loss_bbox_cls: 0.0232, s0.loss_bbox_reg: 0.0466, s1.loss_cls: 0.0178, s1.acc: 98.6145, s1.loss_bbox_cls: 0.0166, s1.loss_bbox_reg: 0.0340, s2.loss_cls: 0.0107, s2.acc: 98.1049, s2.loss_bbox_cls: 0.0091, s2.loss_bbox_reg: 0.0200, loss: 0.2145, grad_norm: 5.6010\n",
            "2020-09-09 14:02:55,981 - mmdet - INFO - Epoch [17][1280/5332]\tlr: 1.000e-05, eta: 10:56:43, time: 1.944, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0219, s0.acc: 99.1272, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0414, s1.loss_cls: 0.0159, s1.acc: 98.7366, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0327, s2.loss_cls: 0.0103, s2.acc: 98.2880, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0188, loss: 0.1943, grad_norm: 5.4908\n",
            "2020-09-09 14:05:01,320 - mmdet - INFO - Epoch [17][1344/5332]\tlr: 1.000e-05, eta: 10:54:31, time: 1.958, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0066, s0.loss_cls: 0.0244, s0.acc: 99.1089, s0.loss_bbox_cls: 0.0241, s0.loss_bbox_reg: 0.0486, s1.loss_cls: 0.0199, s1.acc: 98.5016, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0358, s2.loss_cls: 0.0126, s2.acc: 97.9034, s2.loss_bbox_cls: 0.0084, s2.loss_bbox_reg: 0.0198, loss: 0.2225, grad_norm: 5.7337\n",
            "2020-09-09 14:07:07,862 - mmdet - INFO - Epoch [17][1408/5332]\tlr: 1.000e-05, eta: 10:52:36, time: 1.977, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0192, s0.acc: 99.2188, s0.loss_bbox_cls: 0.0201, s0.loss_bbox_reg: 0.0440, s1.loss_cls: 0.0150, s1.acc: 98.7823, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0347, s2.loss_cls: 0.0101, s2.acc: 98.2849, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0204, loss: 0.1970, grad_norm: 5.5842\n",
            "2020-09-09 14:09:13,172 - mmdet - INFO - Epoch [17][1472/5332]\tlr: 1.000e-05, eta: 10:50:23, time: 1.958, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0273, s0.acc: 98.8525, s0.loss_bbox_cls: 0.0259, s0.loss_bbox_reg: 0.0512, s1.loss_cls: 0.0183, s1.acc: 98.5138, s1.loss_bbox_cls: 0.0219, s1.loss_bbox_reg: 0.0374, s2.loss_cls: 0.0113, s2.acc: 97.9309, s2.loss_bbox_cls: 0.0132, s2.loss_bbox_reg: 0.0223, loss: 0.2358, grad_norm: 5.8470\n",
            "2020-09-09 14:11:20,351 - mmdet - INFO - Epoch [17][1536/5332]\tlr: 1.000e-05, eta: 10:48:36, time: 1.987, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0074, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0233, s0.acc: 99.0448, s0.loss_bbox_cls: 0.0213, s0.loss_bbox_reg: 0.0443, s1.loss_cls: 0.0161, s1.acc: 98.7549, s1.loss_bbox_cls: 0.0174, s1.loss_bbox_reg: 0.0338, s2.loss_cls: 0.0097, s2.acc: 98.3734, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0197, loss: 0.2070, grad_norm: 5.6286\n",
            "2020-09-09 14:13:26,086 - mmdet - INFO - Epoch [17][1600/5332]\tlr: 1.000e-05, eta: 10:46:28, time: 1.965, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0233, s0.acc: 99.0479, s0.loss_bbox_cls: 0.0230, s0.loss_bbox_reg: 0.0450, s1.loss_cls: 0.0178, s1.acc: 98.4406, s1.loss_bbox_cls: 0.0186, s1.loss_bbox_reg: 0.0361, s2.loss_cls: 0.0103, s2.acc: 98.0560, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0219, loss: 0.2159, grad_norm: 5.8403\n",
            "2020-09-09 14:15:32,211 - mmdet - INFO - Epoch [17][1664/5332]\tlr: 1.000e-05, eta: 10:44:26, time: 1.971, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0196, s0.acc: 99.2035, s0.loss_bbox_cls: 0.0173, s0.loss_bbox_reg: 0.0393, s1.loss_cls: 0.0144, s1.acc: 98.9136, s1.loss_bbox_cls: 0.0158, s1.loss_bbox_reg: 0.0322, s2.loss_cls: 0.0101, s2.acc: 98.3032, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0198, loss: 0.1849, grad_norm: 5.3218\n",
            "2020-09-09 14:17:38,414 - mmdet - INFO - Epoch [17][1728/5332]\tlr: 1.000e-05, eta: 10:42:24, time: 1.972, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0201, s0.acc: 99.1882, s0.loss_bbox_cls: 0.0179, s0.loss_bbox_reg: 0.0418, s1.loss_cls: 0.0152, s1.acc: 98.7061, s1.loss_bbox_cls: 0.0172, s1.loss_bbox_reg: 0.0354, s2.loss_cls: 0.0092, s2.acc: 98.6298, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0220, loss: 0.1953, grad_norm: 5.2568\n",
            "2020-09-09 14:19:43,640 - mmdet - INFO - Epoch [17][1792/5332]\tlr: 1.000e-05, eta: 10:40:11, time: 1.957, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0230, s0.acc: 99.1516, s0.loss_bbox_cls: 0.0218, s0.loss_bbox_reg: 0.0442, s1.loss_cls: 0.0144, s1.acc: 98.8831, s1.loss_bbox_cls: 0.0161, s1.loss_bbox_reg: 0.0320, s2.loss_cls: 0.0089, s2.acc: 98.4833, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0203, loss: 0.1987, grad_norm: 5.4764\n",
            "2020-09-09 14:21:51,250 - mmdet - INFO - Epoch [17][1856/5332]\tlr: 1.000e-05, eta: 10:38:24, time: 1.994, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0218, s0.acc: 99.1577, s0.loss_bbox_cls: 0.0220, s0.loss_bbox_reg: 0.0497, s1.loss_cls: 0.0143, s1.acc: 98.8983, s1.loss_bbox_cls: 0.0184, s1.loss_bbox_reg: 0.0368, s2.loss_cls: 0.0088, s2.acc: 98.5657, s2.loss_bbox_cls: 0.0119, s2.loss_bbox_reg: 0.0217, loss: 0.2111, grad_norm: 5.6724\n",
            "2020-09-09 14:23:56,137 - mmdet - INFO - Epoch [17][1920/5332]\tlr: 1.000e-05, eta: 10:36:08, time: 1.951, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0223, s0.acc: 99.1455, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0450, s1.loss_cls: 0.0150, s1.acc: 98.8831, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0365, s2.loss_cls: 0.0098, s2.acc: 98.5077, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0217, loss: 0.2074, grad_norm: 5.3976\n",
            "2020-09-09 14:26:02,777 - mmdet - INFO - Epoch [17][1984/5332]\tlr: 1.000e-05, eta: 10:34:10, time: 1.979, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0025, s0.loss_cls: 0.0192, s0.acc: 99.2584, s0.loss_bbox_cls: 0.0177, s0.loss_bbox_reg: 0.0387, s1.loss_cls: 0.0126, s1.acc: 98.9960, s1.loss_bbox_cls: 0.0154, s1.loss_bbox_reg: 0.0315, s2.loss_cls: 0.0077, s2.acc: 98.7854, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0197, loss: 0.1794, grad_norm: 5.1638\n",
            "2020-09-09 14:28:06,990 - mmdet - INFO - Epoch [17][2048/5332]\tlr: 1.000e-05, eta: 10:31:48, time: 1.941, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0296, s0.acc: 98.8556, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0480, s1.loss_cls: 0.0209, s1.acc: 98.5382, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0353, s2.loss_cls: 0.0126, s2.acc: 98.1171, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0212, loss: 0.2244, grad_norm: 6.2688\n",
            "2020-09-09 14:30:11,746 - mmdet - INFO - Epoch [17][2112/5332]\tlr: 1.000e-05, eta: 10:29:32, time: 1.949, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0064, s0.loss_cls: 0.0208, s0.acc: 99.0967, s0.loss_bbox_cls: 0.0204, s0.loss_bbox_reg: 0.0428, s1.loss_cls: 0.0164, s1.acc: 98.6084, s1.loss_bbox_cls: 0.0156, s1.loss_bbox_reg: 0.0324, s2.loss_cls: 0.0106, s2.acc: 98.2086, s2.loss_bbox_cls: 0.0092, s2.loss_bbox_reg: 0.0190, loss: 0.1951, grad_norm: 5.5179\n",
            "2020-09-09 14:32:18,421 - mmdet - INFO - Epoch [17][2176/5332]\tlr: 1.000e-05, eta: 10:27:34, time: 1.979, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0212, s0.acc: 99.1394, s0.loss_bbox_cls: 0.0178, s0.loss_bbox_reg: 0.0426, s1.loss_cls: 0.0154, s1.acc: 98.7305, s1.loss_bbox_cls: 0.0145, s1.loss_bbox_reg: 0.0329, s2.loss_cls: 0.0102, s2.acc: 98.3002, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0210, loss: 0.1922, grad_norm: 5.1157\n",
            "2020-09-09 14:34:23,988 - mmdet - INFO - Epoch [17][2240/5332]\tlr: 1.000e-05, eta: 10:25:26, time: 1.962, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0068, s0.loss_cls: 0.0252, s0.acc: 98.9197, s0.loss_bbox_cls: 0.0216, s0.loss_bbox_reg: 0.0458, s1.loss_cls: 0.0177, s1.acc: 98.4711, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0367, s2.loss_cls: 0.0118, s2.acc: 97.8912, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0198, loss: 0.2170, grad_norm: 5.8180\n",
            "2020-09-09 14:36:31,188 - mmdet - INFO - Epoch [17][2304/5332]\tlr: 1.000e-05, eta: 10:23:32, time: 1.988, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0230, s0.acc: 99.0265, s0.loss_bbox_cls: 0.0212, s0.loss_bbox_reg: 0.0456, s1.loss_cls: 0.0172, s1.acc: 98.4985, s1.loss_bbox_cls: 0.0176, s1.loss_bbox_reg: 0.0363, s2.loss_cls: 0.0107, s2.acc: 97.9462, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0213, loss: 0.2124, grad_norm: 5.6209\n",
            "2020-09-09 14:38:37,522 - mmdet - INFO - Epoch [17][2368/5332]\tlr: 1.000e-05, eta: 10:21:30, time: 1.974, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0245, s0.acc: 99.0479, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0445, s1.loss_cls: 0.0177, s1.acc: 98.5535, s1.loss_bbox_cls: 0.0175, s1.loss_bbox_reg: 0.0340, s2.loss_cls: 0.0122, s2.acc: 97.9126, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0218, loss: 0.2143, grad_norm: 6.0826\n",
            "2020-09-09 14:40:42,916 - mmdet - INFO - Epoch [17][2432/5332]\tlr: 1.000e-05, eta: 10:19:20, time: 1.959, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0264, s0.acc: 98.9319, s0.loss_bbox_cls: 0.0223, s0.loss_bbox_reg: 0.0460, s1.loss_cls: 0.0158, s1.acc: 98.7885, s1.loss_bbox_cls: 0.0147, s1.loss_bbox_reg: 0.0307, s2.loss_cls: 0.0086, s2.acc: 98.7396, s2.loss_bbox_cls: 0.0088, s2.loss_bbox_reg: 0.0180, loss: 0.2009, grad_norm: 5.3784\n",
            "2020-09-09 14:42:49,888 - mmdet - INFO - Epoch [17][2496/5332]\tlr: 1.000e-05, eta: 10:17:23, time: 1.984, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0025, s0.loss_cls: 0.0230, s0.acc: 98.9899, s0.loss_bbox_cls: 0.0224, s0.loss_bbox_reg: 0.0453, s1.loss_cls: 0.0190, s1.acc: 98.1750, s1.loss_bbox_cls: 0.0202, s1.loss_bbox_reg: 0.0370, s2.loss_cls: 0.0122, s2.acc: 97.8668, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0206, loss: 0.2154, grad_norm: 5.9523\n",
            "2020-09-09 14:44:54,225 - mmdet - INFO - Epoch [17][2560/5332]\tlr: 1.000e-05, eta: 10:15:05, time: 1.943, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0251, s0.acc: 99.0875, s0.loss_bbox_cls: 0.0197, s0.loss_bbox_reg: 0.0422, s1.loss_cls: 0.0188, s1.acc: 98.5260, s1.loss_bbox_cls: 0.0164, s1.loss_bbox_reg: 0.0338, s2.loss_cls: 0.0113, s2.acc: 97.9706, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0207, loss: 0.2072, grad_norm: 5.3686\n",
            "2020-09-09 14:47:00,211 - mmdet - INFO - Epoch [17][2624/5332]\tlr: 1.000e-05, eta: 10:13:00, time: 1.969, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0233, s0.acc: 99.0875, s0.loss_bbox_cls: 0.0254, s0.loss_bbox_reg: 0.0531, s1.loss_cls: 0.0172, s1.acc: 98.6176, s1.loss_bbox_cls: 0.0220, s1.loss_bbox_reg: 0.0424, s2.loss_cls: 0.0120, s2.acc: 97.8394, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0233, loss: 0.2395, grad_norm: 6.3227\n",
            "2020-09-09 14:49:06,969 - mmdet - INFO - Epoch [17][2688/5332]\tlr: 1.000e-05, eta: 10:11:01, time: 1.981, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0243, s0.acc: 98.9899, s0.loss_bbox_cls: 0.0211, s0.loss_bbox_reg: 0.0466, s1.loss_cls: 0.0161, s1.acc: 98.6511, s1.loss_bbox_cls: 0.0191, s1.loss_bbox_reg: 0.0367, s2.loss_cls: 0.0105, s2.acc: 98.2819, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0224, loss: 0.2160, grad_norm: 5.8172\n",
            "2020-09-09 14:51:14,305 - mmdet - INFO - Epoch [17][2752/5332]\tlr: 1.000e-05, eta: 10:09:05, time: 1.990, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0259, s0.acc: 98.9410, s0.loss_bbox_cls: 0.0217, s0.loss_bbox_reg: 0.0467, s1.loss_cls: 0.0197, s1.acc: 98.3246, s1.loss_bbox_cls: 0.0186, s1.loss_bbox_reg: 0.0375, s2.loss_cls: 0.0128, s2.acc: 97.6807, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0217, loss: 0.2230, grad_norm: 5.8141\n",
            "2020-09-09 14:53:20,396 - mmdet - INFO - Epoch [17][2816/5332]\tlr: 1.000e-05, eta: 10:07:00, time: 1.970, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0067, s0.loss_cls: 0.0254, s0.acc: 98.9716, s0.loss_bbox_cls: 0.0228, s0.loss_bbox_reg: 0.0481, s1.loss_cls: 0.0187, s1.acc: 98.5474, s1.loss_bbox_cls: 0.0189, s1.loss_bbox_reg: 0.0387, s2.loss_cls: 0.0118, s2.acc: 98.0011, s2.loss_bbox_cls: 0.0112, s2.loss_bbox_reg: 0.0224, loss: 0.2284, grad_norm: 6.4112\n",
            "2020-09-09 14:55:26,413 - mmdet - INFO - Epoch [17][2880/5332]\tlr: 1.000e-05, eta: 10:04:55, time: 1.969, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0256, s0.acc: 98.9655, s0.loss_bbox_cls: 0.0188, s0.loss_bbox_reg: 0.0403, s1.loss_cls: 0.0220, s1.acc: 98.1445, s1.loss_bbox_cls: 0.0145, s1.loss_bbox_reg: 0.0309, s2.loss_cls: 0.0133, s2.acc: 97.5586, s2.loss_bbox_cls: 0.0082, s2.loss_bbox_reg: 0.0187, loss: 0.1997, grad_norm: 6.2009\n",
            "2020-09-09 14:57:34,583 - mmdet - INFO - Epoch [17][2944/5332]\tlr: 1.000e-05, eta: 10:03:03, time: 2.003, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0201, s0.acc: 99.2218, s0.loss_bbox_cls: 0.0198, s0.loss_bbox_reg: 0.0433, s1.loss_cls: 0.0149, s1.acc: 98.8312, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0345, s2.loss_cls: 0.0099, s2.acc: 98.2208, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0201, loss: 0.1970, grad_norm: 5.5696\n",
            "2020-09-09 14:59:40,925 - mmdet - INFO - Epoch [17][3008/5332]\tlr: 1.000e-05, eta: 10:00:59, time: 1.974, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0265, s0.acc: 99.0265, s0.loss_bbox_cls: 0.0205, s0.loss_bbox_reg: 0.0432, s1.loss_cls: 0.0162, s1.acc: 98.8037, s1.loss_bbox_cls: 0.0154, s1.loss_bbox_reg: 0.0322, s2.loss_cls: 0.0100, s2.acc: 98.4406, s2.loss_bbox_cls: 0.0084, s2.loss_bbox_reg: 0.0179, loss: 0.2009, grad_norm: 5.6284\n",
            "2020-09-09 15:01:45,545 - mmdet - INFO - Epoch [17][3072/5332]\tlr: 1.000e-05, eta: 9:58:45, time: 1.947, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0274, s0.acc: 98.8647, s0.loss_bbox_cls: 0.0239, s0.loss_bbox_reg: 0.0506, s1.loss_cls: 0.0189, s1.acc: 98.2269, s1.loss_bbox_cls: 0.0191, s1.loss_bbox_reg: 0.0370, s2.loss_cls: 0.0121, s2.acc: 97.8455, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0218, loss: 0.2290, grad_norm: 6.0653\n",
            "2020-09-09 15:03:51,330 - mmdet - INFO - Epoch [17][3136/5332]\tlr: 1.000e-05, eta: 9:56:38, time: 1.965, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0204, s0.acc: 99.1821, s0.loss_bbox_cls: 0.0221, s0.loss_bbox_reg: 0.0444, s1.loss_cls: 0.0154, s1.acc: 98.7579, s1.loss_bbox_cls: 0.0184, s1.loss_bbox_reg: 0.0339, s2.loss_cls: 0.0102, s2.acc: 98.5199, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0199, loss: 0.2034, grad_norm: 5.2406\n",
            "2020-09-09 15:05:57,866 - mmdet - INFO - Epoch [17][3200/5332]\tlr: 1.000e-05, eta: 9:54:36, time: 1.977, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0245, s0.acc: 99.1028, s0.loss_bbox_cls: 0.0213, s0.loss_bbox_reg: 0.0462, s1.loss_cls: 0.0170, s1.acc: 98.7579, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0359, s2.loss_cls: 0.0105, s2.acc: 98.1750, s2.loss_bbox_cls: 0.0114, s2.loss_bbox_reg: 0.0222, loss: 0.2164, grad_norm: 5.7185\n",
            "2020-09-09 15:08:06,222 - mmdet - INFO - Epoch [17][3264/5332]\tlr: 1.000e-05, eta: 9:52:43, time: 2.006, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0226, s0.acc: 99.2310, s0.loss_bbox_cls: 0.0166, s0.loss_bbox_reg: 0.0369, s1.loss_cls: 0.0160, s1.acc: 98.7579, s1.loss_bbox_cls: 0.0139, s1.loss_bbox_reg: 0.0288, s2.loss_cls: 0.0101, s2.acc: 98.4924, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0193, loss: 0.1810, grad_norm: 5.2791\n",
            "2020-09-09 15:10:11,364 - mmdet - INFO - Epoch [17][3328/5332]\tlr: 1.000e-05, eta: 9:50:32, time: 1.955, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0082, s0.loss_cls: 0.0270, s0.acc: 98.9471, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0417, s1.loss_cls: 0.0187, s1.acc: 98.4711, s1.loss_bbox_cls: 0.0152, s1.loss_bbox_reg: 0.0294, s2.loss_cls: 0.0116, s2.acc: 98.0011, s2.loss_bbox_cls: 0.0078, s2.loss_bbox_reg: 0.0166, loss: 0.2021, grad_norm: 5.1419\n",
            "2020-09-09 15:12:16,781 - mmdet - INFO - Epoch [17][3392/5332]\tlr: 1.000e-05, eta: 9:48:23, time: 1.960, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0236, s0.acc: 99.0723, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0467, s1.loss_cls: 0.0182, s1.acc: 98.4528, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0371, s2.loss_cls: 0.0111, s2.acc: 98.1781, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0222, loss: 0.2170, grad_norm: 5.9930\n",
            "2020-09-09 15:14:22,301 - mmdet - INFO - Epoch [17][3456/5332]\tlr: 1.000e-05, eta: 9:46:15, time: 1.961, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0226, s0.acc: 99.0723, s0.loss_bbox_cls: 0.0227, s0.loss_bbox_reg: 0.0487, s1.loss_cls: 0.0169, s1.acc: 98.6877, s1.loss_bbox_cls: 0.0201, s1.loss_bbox_reg: 0.0399, s2.loss_cls: 0.0111, s2.acc: 98.2147, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0224, loss: 0.2233, grad_norm: 5.5388\n",
            "2020-09-09 15:16:29,853 - mmdet - INFO - Epoch [17][3520/5332]\tlr: 1.000e-05, eta: 9:44:17, time: 1.993, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0213, s0.acc: 99.1516, s0.loss_bbox_cls: 0.0221, s0.loss_bbox_reg: 0.0420, s1.loss_cls: 0.0158, s1.acc: 98.6053, s1.loss_bbox_cls: 0.0188, s1.loss_bbox_reg: 0.0340, s2.loss_cls: 0.0110, s2.acc: 98.1628, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0193, loss: 0.2009, grad_norm: 5.5570\n",
            "2020-09-09 15:18:34,913 - mmdet - INFO - Epoch [17][3584/5332]\tlr: 1.000e-05, eta: 9:42:07, time: 1.954, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0275, s0.acc: 98.9655, s0.loss_bbox_cls: 0.0225, s0.loss_bbox_reg: 0.0425, s1.loss_cls: 0.0212, s1.acc: 98.2391, s1.loss_bbox_cls: 0.0186, s1.loss_bbox_reg: 0.0340, s2.loss_cls: 0.0137, s2.acc: 97.5189, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0199, loss: 0.2169, grad_norm: 5.8804\n",
            "2020-09-09 15:20:41,214 - mmdet - INFO - Epoch [17][3648/5332]\tlr: 1.000e-05, eta: 9:40:02, time: 1.973, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0240, s0.acc: 99.0479, s0.loss_bbox_cls: 0.0210, s0.loss_bbox_reg: 0.0460, s1.loss_cls: 0.0173, s1.acc: 98.5718, s1.loss_bbox_cls: 0.0175, s1.loss_bbox_reg: 0.0369, s2.loss_cls: 0.0102, s2.acc: 98.1689, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0216, loss: 0.2123, grad_norm: 5.7440\n",
            "2020-09-09 15:22:47,322 - mmdet - INFO - Epoch [17][3712/5332]\tlr: 1.000e-05, eta: 9:37:57, time: 1.970, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0228, s0.acc: 99.0753, s0.loss_bbox_cls: 0.0205, s0.loss_bbox_reg: 0.0467, s1.loss_cls: 0.0178, s1.acc: 98.3734, s1.loss_bbox_cls: 0.0186, s1.loss_bbox_reg: 0.0377, s2.loss_cls: 0.0113, s2.acc: 98.0591, s2.loss_bbox_cls: 0.0115, s2.loss_bbox_reg: 0.0231, loss: 0.2161, grad_norm: 5.8716\n",
            "2020-09-09 15:24:52,077 - mmdet - INFO - Epoch [17][3776/5332]\tlr: 1.000e-05, eta: 9:35:45, time: 1.949, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0281, s0.acc: 98.8922, s0.loss_bbox_cls: 0.0268, s0.loss_bbox_reg: 0.0545, s1.loss_cls: 0.0194, s1.acc: 98.5046, s1.loss_bbox_cls: 0.0220, s1.loss_bbox_reg: 0.0422, s2.loss_cls: 0.0139, s2.acc: 97.8516, s2.loss_bbox_cls: 0.0118, s2.loss_bbox_reg: 0.0234, loss: 0.2502, grad_norm: 6.3618\n",
            "2020-09-09 15:26:58,689 - mmdet - INFO - Epoch [17][3840/5332]\tlr: 1.000e-05, eta: 9:33:42, time: 1.978, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0026, s0.loss_cls: 0.0207, s0.acc: 99.1699, s0.loss_bbox_cls: 0.0214, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0143, s1.acc: 98.8647, s1.loss_bbox_cls: 0.0185, s1.loss_bbox_reg: 0.0352, s2.loss_cls: 0.0097, s2.acc: 98.4528, s2.loss_bbox_cls: 0.0117, s2.loss_bbox_reg: 0.0218, loss: 0.2033, grad_norm: 5.6693\n",
            "2020-09-09 15:29:04,933 - mmdet - INFO - Epoch [17][3904/5332]\tlr: 1.000e-05, eta: 9:31:37, time: 1.973, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0238, s0.acc: 99.0814, s0.loss_bbox_cls: 0.0238, s0.loss_bbox_reg: 0.0450, s1.loss_cls: 0.0147, s1.acc: 98.8739, s1.loss_bbox_cls: 0.0205, s1.loss_bbox_reg: 0.0361, s2.loss_cls: 0.0098, s2.acc: 98.3521, s2.loss_bbox_cls: 0.0116, s2.loss_bbox_reg: 0.0210, loss: 0.2154, grad_norm: 5.8319\n",
            "2020-09-09 15:31:11,728 - mmdet - INFO - Epoch [17][3968/5332]\tlr: 1.000e-05, eta: 9:29:35, time: 1.981, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0199, s0.acc: 99.2188, s0.loss_bbox_cls: 0.0211, s0.loss_bbox_reg: 0.0421, s1.loss_cls: 0.0161, s1.acc: 98.7610, s1.loss_bbox_cls: 0.0164, s1.loss_bbox_reg: 0.0313, s2.loss_cls: 0.0097, s2.acc: 98.5168, s2.loss_bbox_cls: 0.0084, s2.loss_bbox_reg: 0.0180, loss: 0.1915, grad_norm: 5.3074\n",
            "2020-09-09 15:33:19,123 - mmdet - INFO - Epoch [17][4032/5332]\tlr: 1.000e-05, eta: 9:27:35, time: 1.991, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0189, s0.acc: 99.2706, s0.loss_bbox_cls: 0.0191, s0.loss_bbox_reg: 0.0432, s1.loss_cls: 0.0151, s1.acc: 98.8617, s1.loss_bbox_cls: 0.0175, s1.loss_bbox_reg: 0.0377, s2.loss_cls: 0.0109, s2.acc: 98.2819, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0235, loss: 0.2036, grad_norm: 5.4073\n",
            "2020-09-09 15:35:25,006 - mmdet - INFO - Epoch [17][4096/5332]\tlr: 1.000e-05, eta: 9:25:28, time: 1.967, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0204, s0.acc: 99.2340, s0.loss_bbox_cls: 0.0165, s0.loss_bbox_reg: 0.0379, s1.loss_cls: 0.0139, s1.acc: 98.9288, s1.loss_bbox_cls: 0.0160, s1.loss_bbox_reg: 0.0328, s2.loss_cls: 0.0087, s2.acc: 98.7976, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0194, loss: 0.1805, grad_norm: 5.3806\n",
            "2020-09-09 15:37:31,754 - mmdet - INFO - Epoch [17][4160/5332]\tlr: 1.000e-05, eta: 9:23:25, time: 1.980, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0208, s0.acc: 99.2645, s0.loss_bbox_cls: 0.0181, s0.loss_bbox_reg: 0.0399, s1.loss_cls: 0.0165, s1.acc: 98.6938, s1.loss_bbox_cls: 0.0145, s1.loss_bbox_reg: 0.0317, s2.loss_cls: 0.0095, s2.acc: 98.4711, s2.loss_bbox_cls: 0.0078, s2.loss_bbox_reg: 0.0179, loss: 0.1840, grad_norm: 5.2245\n",
            "2020-09-09 15:39:37,527 - mmdet - INFO - Epoch [17][4224/5332]\tlr: 1.000e-05, eta: 9:21:18, time: 1.965, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0071, s0.loss_cls: 0.0258, s0.acc: 98.9502, s0.loss_bbox_cls: 0.0229, s0.loss_bbox_reg: 0.0486, s1.loss_cls: 0.0190, s1.acc: 98.4039, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0361, s2.loss_cls: 0.0117, s2.acc: 97.9187, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0214, loss: 0.2229, grad_norm: 6.0432\n",
            "2020-09-09 15:41:45,221 - mmdet - INFO - Epoch [17][4288/5332]\tlr: 1.000e-05, eta: 9:19:19, time: 1.995, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0212, s0.acc: 99.1364, s0.loss_bbox_cls: 0.0200, s0.loss_bbox_reg: 0.0431, s1.loss_cls: 0.0157, s1.acc: 98.8251, s1.loss_bbox_cls: 0.0165, s1.loss_bbox_reg: 0.0353, s2.loss_cls: 0.0107, s2.acc: 98.4680, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0214, loss: 0.2008, grad_norm: 5.5405\n",
            "2020-09-09 15:43:51,947 - mmdet - INFO - Epoch [17][4352/5332]\tlr: 1.000e-05, eta: 9:17:16, time: 1.980, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0272, s0.acc: 99.0265, s0.loss_bbox_cls: 0.0228, s0.loss_bbox_reg: 0.0445, s1.loss_cls: 0.0202, s1.acc: 98.5535, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0346, s2.loss_cls: 0.0120, s2.acc: 98.0499, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0212, loss: 0.2154, grad_norm: 5.6880\n",
            "2020-09-09 15:46:01,141 - mmdet - INFO - Epoch [17][4416/5332]\tlr: 1.000e-05, eta: 9:15:22, time: 2.019, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0263, s0.acc: 98.8403, s0.loss_bbox_cls: 0.0205, s0.loss_bbox_reg: 0.0456, s1.loss_cls: 0.0193, s1.acc: 98.2483, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0364, s2.loss_cls: 0.0120, s2.acc: 97.8241, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0217, loss: 0.2196, grad_norm: 6.2516\n",
            "2020-09-09 15:48:07,262 - mmdet - INFO - Epoch [17][4480/5332]\tlr: 1.000e-05, eta: 9:13:16, time: 1.971, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0203, s0.acc: 99.2188, s0.loss_bbox_cls: 0.0155, s0.loss_bbox_reg: 0.0365, s1.loss_cls: 0.0150, s1.acc: 98.6603, s1.loss_bbox_cls: 0.0136, s1.loss_bbox_reg: 0.0299, s2.loss_cls: 0.0091, s2.acc: 98.5382, s2.loss_bbox_cls: 0.0085, s2.loss_bbox_reg: 0.0183, loss: 0.1747, grad_norm: 5.2986\n",
            "2020-09-09 15:50:13,369 - mmdet - INFO - Epoch [17][4544/5332]\tlr: 1.000e-05, eta: 9:11:09, time: 1.970, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0237, s0.acc: 99.1486, s0.loss_bbox_cls: 0.0194, s0.loss_bbox_reg: 0.0423, s1.loss_cls: 0.0180, s1.acc: 98.5779, s1.loss_bbox_cls: 0.0156, s1.loss_bbox_reg: 0.0344, s2.loss_cls: 0.0114, s2.acc: 98.0896, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0204, loss: 0.2010, grad_norm: 5.9229\n",
            "2020-09-09 15:52:21,057 - mmdet - INFO - Epoch [17][4608/5332]\tlr: 1.000e-05, eta: 9:09:09, time: 1.995, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0234, s0.acc: 99.1333, s0.loss_bbox_cls: 0.0182, s0.loss_bbox_reg: 0.0386, s1.loss_cls: 0.0163, s1.acc: 98.6725, s1.loss_bbox_cls: 0.0145, s1.loss_bbox_reg: 0.0296, s2.loss_cls: 0.0100, s2.acc: 98.2513, s2.loss_bbox_cls: 0.0085, s2.loss_bbox_reg: 0.0180, loss: 0.1869, grad_norm: 5.0824\n",
            "2020-09-09 15:54:27,103 - mmdet - INFO - Epoch [17][4672/5332]\tlr: 1.000e-05, eta: 9:07:03, time: 1.969, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0222, s0.acc: 99.1364, s0.loss_bbox_cls: 0.0189, s0.loss_bbox_reg: 0.0428, s1.loss_cls: 0.0156, s1.acc: 98.8403, s1.loss_bbox_cls: 0.0156, s1.loss_bbox_reg: 0.0335, s2.loss_cls: 0.0105, s2.acc: 98.3551, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0203, loss: 0.1970, grad_norm: 5.4840\n",
            "2020-09-09 15:56:33,863 - mmdet - INFO - Epoch [17][4736/5332]\tlr: 1.000e-05, eta: 9:04:59, time: 1.981, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0260, s0.acc: 99.0356, s0.loss_bbox_cls: 0.0239, s0.loss_bbox_reg: 0.0480, s1.loss_cls: 0.0194, s1.acc: 98.3795, s1.loss_bbox_cls: 0.0197, s1.loss_bbox_reg: 0.0364, s2.loss_cls: 0.0119, s2.acc: 97.9614, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0216, loss: 0.2280, grad_norm: 6.0589\n",
            "2020-09-09 15:58:39,439 - mmdet - INFO - Epoch [17][4800/5332]\tlr: 1.000e-05, eta: 9:02:51, time: 1.962, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0260, s0.acc: 98.9960, s0.loss_bbox_cls: 0.0190, s0.loss_bbox_reg: 0.0415, s1.loss_cls: 0.0229, s1.acc: 98.3307, s1.loss_bbox_cls: 0.0149, s1.loss_bbox_reg: 0.0322, s2.loss_cls: 0.0136, s2.acc: 98.0652, s2.loss_bbox_cls: 0.0088, s2.loss_bbox_reg: 0.0189, loss: 0.2056, grad_norm: 5.7388\n",
            "2020-09-09 16:00:48,458 - mmdet - INFO - Epoch [17][4864/5332]\tlr: 1.000e-05, eta: 9:00:54, time: 2.016, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0237, s0.acc: 99.1028, s0.loss_bbox_cls: 0.0219, s0.loss_bbox_reg: 0.0455, s1.loss_cls: 0.0169, s1.acc: 98.6145, s1.loss_bbox_cls: 0.0193, s1.loss_bbox_reg: 0.0359, s2.loss_cls: 0.0100, s2.acc: 98.2178, s2.loss_bbox_cls: 0.0116, s2.loss_bbox_reg: 0.0219, loss: 0.2160, grad_norm: 6.2729\n",
            "2020-09-09 16:02:55,914 - mmdet - INFO - Epoch [17][4928/5332]\tlr: 1.000e-05, eta: 8:58:53, time: 1.991, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0224, s0.acc: 99.0326, s0.loss_bbox_cls: 0.0216, s0.loss_bbox_reg: 0.0455, s1.loss_cls: 0.0172, s1.acc: 98.6359, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0352, s2.loss_cls: 0.0111, s2.acc: 98.0713, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0209, loss: 0.2091, grad_norm: 5.5838\n",
            "2020-09-09 16:05:02,229 - mmdet - INFO - Epoch [17][4992/5332]\tlr: 1.000e-05, eta: 8:56:47, time: 1.974, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0208, s0.acc: 99.1577, s0.loss_bbox_cls: 0.0172, s0.loss_bbox_reg: 0.0395, s1.loss_cls: 0.0130, s1.acc: 99.0143, s1.loss_bbox_cls: 0.0139, s1.loss_bbox_reg: 0.0303, s2.loss_cls: 0.0089, s2.acc: 98.4802, s2.loss_bbox_cls: 0.0083, s2.loss_bbox_reg: 0.0189, loss: 0.1798, grad_norm: 5.5146\n",
            "2020-09-09 16:07:09,112 - mmdet - INFO - Epoch [17][5056/5332]\tlr: 1.000e-05, eta: 8:54:43, time: 1.983, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0221, s0.acc: 99.0906, s0.loss_bbox_cls: 0.0167, s0.loss_bbox_reg: 0.0396, s1.loss_cls: 0.0142, s1.acc: 98.8129, s1.loss_bbox_cls: 0.0150, s1.loss_bbox_reg: 0.0323, s2.loss_cls: 0.0089, s2.acc: 98.3368, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0206, loss: 0.1848, grad_norm: 5.4305\n",
            "2020-09-09 16:09:15,323 - mmdet - INFO - Epoch [17][5120/5332]\tlr: 1.000e-05, eta: 8:52:37, time: 1.972, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0242, s0.acc: 98.9990, s0.loss_bbox_cls: 0.0237, s0.loss_bbox_reg: 0.0493, s1.loss_cls: 0.0176, s1.acc: 98.5016, s1.loss_bbox_cls: 0.0204, s1.loss_bbox_reg: 0.0373, s2.loss_cls: 0.0116, s2.acc: 97.8302, s2.loss_bbox_cls: 0.0115, s2.loss_bbox_reg: 0.0212, loss: 0.2258, grad_norm: 6.0753\n",
            "2020-09-09 16:11:21,001 - mmdet - INFO - Epoch [17][5184/5332]\tlr: 1.000e-05, eta: 8:50:29, time: 1.964, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0249, s0.acc: 98.9899, s0.loss_bbox_cls: 0.0245, s0.loss_bbox_reg: 0.0518, s1.loss_cls: 0.0174, s1.acc: 98.5962, s1.loss_bbox_cls: 0.0217, s1.loss_bbox_reg: 0.0422, s2.loss_cls: 0.0110, s2.acc: 97.9614, s2.loss_bbox_cls: 0.0142, s2.loss_bbox_reg: 0.0264, loss: 0.2436, grad_norm: 6.3085\n",
            "2020-09-09 16:13:26,647 - mmdet - INFO - Epoch [17][5248/5332]\tlr: 1.000e-05, eta: 8:48:21, time: 1.963, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0270, s0.acc: 98.8342, s0.loss_bbox_cls: 0.0219, s0.loss_bbox_reg: 0.0470, s1.loss_cls: 0.0198, s1.acc: 98.4192, s1.loss_bbox_cls: 0.0184, s1.loss_bbox_reg: 0.0358, s2.loss_cls: 0.0108, s2.acc: 98.2300, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0202, loss: 0.2233, grad_norm: 6.5470\n",
            "2020-09-09 16:15:33,788 - mmdet - INFO - Epoch [17][5312/5332]\tlr: 1.000e-05, eta: 8:46:18, time: 1.987, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0219, s0.acc: 99.0997, s0.loss_bbox_cls: 0.0217, s0.loss_bbox_reg: 0.0447, s1.loss_cls: 0.0144, s1.acc: 98.9960, s1.loss_bbox_cls: 0.0190, s1.loss_bbox_reg: 0.0373, s2.loss_cls: 0.0097, s2.acc: 98.5748, s2.loss_bbox_cls: 0.0110, s2.loss_bbox_reg: 0.0217, loss: 0.2095, grad_norm: 5.7535\n",
            "2020-09-09 16:16:13,061 - mmdet - INFO - Saving checkpoint at 17 epochs\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1136s, ETA:     0s2020-09-09 16:35:16,354 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 266  | 0.829  | 0.660 |\n",
            "| 3     | 22  | 64   | 0.818  | 0.675 |\n",
            "| 4     | 529 | 1233 | 0.921  | 0.833 |\n",
            "| 5     | 78  | 181  | 0.885  | 0.800 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.742 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-09 16:35:16,358 - mmdet - INFO - Epoch(val) [17][5332]\tmAP: 0.7423\n",
            "2020-09-09 16:37:24,599 - mmdet - INFO - Epoch [18][64/5332]\tlr: 1.000e-05, eta: 8:41:42, time: 2.003, data_time: 0.038, memory: 8999, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0242, s0.acc: 98.9685, s0.loss_bbox_cls: 0.0218, s0.loss_bbox_reg: 0.0444, s1.loss_cls: 0.0197, s1.acc: 98.3795, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0341, s2.loss_cls: 0.0126, s2.acc: 97.8241, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0202, loss: 0.2110, grad_norm: 5.6626\n",
            "2020-09-09 16:39:29,639 - mmdet - INFO - Epoch [18][128/5332]\tlr: 1.000e-05, eta: 8:39:34, time: 1.954, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0302, s0.acc: 98.7823, s0.loss_bbox_cls: 0.0243, s0.loss_bbox_reg: 0.0494, s1.loss_cls: 0.0208, s1.acc: 98.3978, s1.loss_bbox_cls: 0.0186, s1.loss_bbox_reg: 0.0367, s2.loss_cls: 0.0140, s2.acc: 97.8943, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0211, loss: 0.2338, grad_norm: 6.6120\n",
            "2020-09-09 16:41:33,553 - mmdet - INFO - Epoch [18][192/5332]\tlr: 1.000e-05, eta: 8:37:23, time: 1.936, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0218, s0.acc: 99.1089, s0.loss_bbox_cls: 0.0211, s0.loss_bbox_reg: 0.0443, s1.loss_cls: 0.0150, s1.acc: 98.7946, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0339, s2.loss_cls: 0.0093, s2.acc: 98.5260, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0197, loss: 0.2030, grad_norm: 5.2425\n",
            "2020-09-09 16:43:39,985 - mmdet - INFO - Epoch [18][256/5332]\tlr: 1.000e-05, eta: 8:35:19, time: 1.975, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0267, s0.acc: 99.0417, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0416, s1.loss_cls: 0.0203, s1.acc: 98.6115, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0314, s2.loss_cls: 0.0121, s2.acc: 98.2178, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0205, loss: 0.2081, grad_norm: 5.3979\n",
            "2020-09-09 16:45:47,115 - mmdet - INFO - Epoch [18][320/5332]\tlr: 1.000e-05, eta: 8:33:18, time: 1.986, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0256, s0.acc: 99.0234, s0.loss_bbox_cls: 0.0255, s0.loss_bbox_reg: 0.0479, s1.loss_cls: 0.0160, s1.acc: 98.7976, s1.loss_bbox_cls: 0.0200, s1.loss_bbox_reg: 0.0371, s2.loss_cls: 0.0102, s2.acc: 98.3887, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0226, loss: 0.2243, grad_norm: 5.8406\n",
            "2020-09-09 16:47:51,727 - mmdet - INFO - Epoch [18][384/5332]\tlr: 1.000e-05, eta: 8:31:09, time: 1.947, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0216, s0.acc: 99.1028, s0.loss_bbox_cls: 0.0216, s0.loss_bbox_reg: 0.0463, s1.loss_cls: 0.0165, s1.acc: 98.6603, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0373, s2.loss_cls: 0.0108, s2.acc: 98.3063, s2.loss_bbox_cls: 0.0119, s2.loss_bbox_reg: 0.0227, loss: 0.2122, grad_norm: 5.8993\n",
            "2020-09-09 16:49:56,482 - mmdet - INFO - Epoch [18][448/5332]\tlr: 1.000e-05, eta: 8:29:00, time: 1.949, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0258, s0.acc: 98.9746, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0443, s1.loss_cls: 0.0192, s1.acc: 98.4680, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0335, s2.loss_cls: 0.0119, s2.acc: 97.8912, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0207, loss: 0.2139, grad_norm: 5.9246\n",
            "2020-09-09 16:52:01,915 - mmdet - INFO - Epoch [18][512/5332]\tlr: 1.000e-05, eta: 8:26:54, time: 1.960, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0221, s0.acc: 99.1241, s0.loss_bbox_cls: 0.0185, s0.loss_bbox_reg: 0.0390, s1.loss_cls: 0.0161, s1.acc: 98.6847, s1.loss_bbox_cls: 0.0169, s1.loss_bbox_reg: 0.0325, s2.loss_cls: 0.0110, s2.acc: 98.0408, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0191, loss: 0.1936, grad_norm: 5.4904\n",
            "2020-09-09 16:54:07,291 - mmdet - INFO - Epoch [18][576/5332]\tlr: 1.000e-05, eta: 8:24:47, time: 1.959, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0254, s0.acc: 98.9563, s0.loss_bbox_cls: 0.0221, s0.loss_bbox_reg: 0.0450, s1.loss_cls: 0.0178, s1.acc: 98.5535, s1.loss_bbox_cls: 0.0187, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0114, s2.acc: 97.9767, s2.loss_bbox_cls: 0.0117, s2.loss_bbox_reg: 0.0227, loss: 0.2189, grad_norm: 5.5904\n",
            "2020-09-09 16:56:14,345 - mmdet - INFO - Epoch [18][640/5332]\tlr: 1.000e-05, eta: 8:22:45, time: 1.985, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0233, s0.acc: 99.0540, s0.loss_bbox_cls: 0.0198, s0.loss_bbox_reg: 0.0411, s1.loss_cls: 0.0159, s1.acc: 98.6664, s1.loss_bbox_cls: 0.0180, s1.loss_bbox_reg: 0.0332, s2.loss_cls: 0.0105, s2.acc: 98.0072, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0207, loss: 0.1993, grad_norm: 5.6804\n",
            "2020-09-09 16:58:21,654 - mmdet - INFO - Epoch [18][704/5332]\tlr: 1.000e-05, eta: 8:20:43, time: 1.989, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0283, s0.acc: 98.8281, s0.loss_bbox_cls: 0.0231, s0.loss_bbox_reg: 0.0473, s1.loss_cls: 0.0239, s1.acc: 98.1598, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0154, s2.acc: 97.4731, s2.loss_bbox_cls: 0.0085, s2.loss_bbox_reg: 0.0195, loss: 0.2249, grad_norm: 5.9150\n",
            "2020-09-09 17:00:26,784 - mmdet - INFO - Epoch [18][768/5332]\tlr: 1.000e-05, eta: 8:18:36, time: 1.955, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0285, s0.acc: 98.8342, s0.loss_bbox_cls: 0.0228, s0.loss_bbox_reg: 0.0445, s1.loss_cls: 0.0202, s1.acc: 98.2391, s1.loss_bbox_cls: 0.0169, s1.loss_bbox_reg: 0.0312, s2.loss_cls: 0.0133, s2.acc: 97.7539, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0182, loss: 0.2121, grad_norm: 5.7194\n",
            "2020-09-09 17:02:32,281 - mmdet - INFO - Epoch [18][832/5332]\tlr: 1.000e-05, eta: 8:16:30, time: 1.961, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0255, s0.acc: 99.0265, s0.loss_bbox_cls: 0.0181, s0.loss_bbox_reg: 0.0417, s1.loss_cls: 0.0174, s1.acc: 98.7427, s1.loss_bbox_cls: 0.0164, s1.loss_bbox_reg: 0.0359, s2.loss_cls: 0.0111, s2.acc: 98.2117, s2.loss_bbox_cls: 0.0092, s2.loss_bbox_reg: 0.0204, loss: 0.2041, grad_norm: 5.5874\n",
            "2020-09-09 17:04:37,514 - mmdet - INFO - Epoch [18][896/5332]\tlr: 1.000e-05, eta: 8:14:23, time: 1.957, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0236, s0.acc: 99.0509, s0.loss_bbox_cls: 0.0222, s0.loss_bbox_reg: 0.0465, s1.loss_cls: 0.0182, s1.acc: 98.4833, s1.loss_bbox_cls: 0.0191, s1.loss_bbox_reg: 0.0370, s2.loss_cls: 0.0118, s2.acc: 98.1598, s2.loss_bbox_cls: 0.0122, s2.loss_bbox_reg: 0.0218, loss: 0.2193, grad_norm: 6.1567\n",
            "2020-09-09 17:06:43,358 - mmdet - INFO - Epoch [18][960/5332]\tlr: 1.000e-05, eta: 8:12:18, time: 1.966, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0227, s0.acc: 99.0601, s0.loss_bbox_cls: 0.0201, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0150, s1.acc: 98.7274, s1.loss_bbox_cls: 0.0162, s1.loss_bbox_reg: 0.0329, s2.loss_cls: 0.0102, s2.acc: 98.4833, s2.loss_bbox_cls: 0.0085, s2.loss_bbox_reg: 0.0187, loss: 0.1968, grad_norm: 5.5466\n",
            "2020-09-09 17:08:50,212 - mmdet - INFO - Epoch [18][1024/5332]\tlr: 1.000e-05, eta: 8:10:14, time: 1.982, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0245, s0.acc: 99.0692, s0.loss_bbox_cls: 0.0232, s0.loss_bbox_reg: 0.0491, s1.loss_cls: 0.0176, s1.acc: 98.6053, s1.loss_bbox_cls: 0.0192, s1.loss_bbox_reg: 0.0388, s2.loss_cls: 0.0092, s2.acc: 98.5413, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0229, loss: 0.2248, grad_norm: 6.2145\n",
            "2020-09-09 17:10:55,766 - mmdet - INFO - Epoch [18][1088/5332]\tlr: 1.000e-05, eta: 8:08:08, time: 1.962, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0217, s0.acc: 99.1516, s0.loss_bbox_cls: 0.0189, s0.loss_bbox_reg: 0.0405, s1.loss_cls: 0.0154, s1.acc: 98.8037, s1.loss_bbox_cls: 0.0180, s1.loss_bbox_reg: 0.0340, s2.loss_cls: 0.0106, s2.acc: 98.3765, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0185, loss: 0.1936, grad_norm: 5.4274\n",
            "2020-09-09 17:13:00,192 - mmdet - INFO - Epoch [18][1152/5332]\tlr: 1.000e-05, eta: 8:06:00, time: 1.944, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0207, s0.acc: 99.1577, s0.loss_bbox_cls: 0.0251, s0.loss_bbox_reg: 0.0470, s1.loss_cls: 0.0150, s1.acc: 98.7213, s1.loss_bbox_cls: 0.0212, s1.loss_bbox_reg: 0.0391, s2.loss_cls: 0.0123, s2.acc: 97.7509, s2.loss_bbox_cls: 0.0118, s2.loss_bbox_reg: 0.0223, loss: 0.2230, grad_norm: 5.4878\n",
            "2020-09-09 17:15:05,290 - mmdet - INFO - Epoch [18][1216/5332]\tlr: 1.000e-05, eta: 8:03:52, time: 1.955, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0251, s0.acc: 99.0540, s0.loss_bbox_cls: 0.0217, s0.loss_bbox_reg: 0.0469, s1.loss_cls: 0.0169, s1.acc: 98.7976, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0361, s2.loss_cls: 0.0099, s2.acc: 98.5565, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0217, loss: 0.2159, grad_norm: 5.8565\n",
            "2020-09-09 17:17:09,518 - mmdet - INFO - Epoch [18][1280/5332]\tlr: 1.000e-05, eta: 8:01:43, time: 1.941, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0210, s0.acc: 99.1272, s0.loss_bbox_cls: 0.0166, s0.loss_bbox_reg: 0.0387, s1.loss_cls: 0.0161, s1.acc: 98.6420, s1.loss_bbox_cls: 0.0152, s1.loss_bbox_reg: 0.0314, s2.loss_cls: 0.0098, s2.acc: 98.3521, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0199, loss: 0.1842, grad_norm: 5.5104\n",
            "2020-09-09 17:19:16,239 - mmdet - INFO - Epoch [18][1344/5332]\tlr: 1.000e-05, eta: 7:59:40, time: 1.980, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0187, s0.acc: 99.2706, s0.loss_bbox_cls: 0.0186, s0.loss_bbox_reg: 0.0432, s1.loss_cls: 0.0128, s1.acc: 98.9929, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0363, s2.loss_cls: 0.0077, s2.acc: 98.8220, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0214, loss: 0.1934, grad_norm: 5.3337\n",
            "2020-09-09 17:21:21,989 - mmdet - INFO - Epoch [18][1408/5332]\tlr: 1.000e-05, eta: 7:57:34, time: 1.965, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0244, s0.acc: 98.9807, s0.loss_bbox_cls: 0.0206, s0.loss_bbox_reg: 0.0429, s1.loss_cls: 0.0189, s1.acc: 98.5535, s1.loss_bbox_cls: 0.0160, s1.loss_bbox_reg: 0.0300, s2.loss_cls: 0.0126, s2.acc: 97.8241, s2.loss_bbox_cls: 0.0082, s2.loss_bbox_reg: 0.0176, loss: 0.1977, grad_norm: 5.9561\n",
            "2020-09-09 17:23:29,276 - mmdet - INFO - Epoch [18][1472/5332]\tlr: 1.000e-05, eta: 7:55:32, time: 1.989, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0271, s0.acc: 98.9746, s0.loss_bbox_cls: 0.0244, s0.loss_bbox_reg: 0.0493, s1.loss_cls: 0.0183, s1.acc: 98.6511, s1.loss_bbox_cls: 0.0195, s1.loss_bbox_reg: 0.0361, s2.loss_cls: 0.0103, s2.acc: 98.3887, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0205, loss: 0.2243, grad_norm: 5.7702\n",
            "2020-09-09 17:25:34,338 - mmdet - INFO - Epoch [18][1536/5332]\tlr: 1.000e-05, eta: 7:53:25, time: 1.954, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0232, s0.acc: 99.0326, s0.loss_bbox_cls: 0.0176, s0.loss_bbox_reg: 0.0395, s1.loss_cls: 0.0174, s1.acc: 98.5260, s1.loss_bbox_cls: 0.0155, s1.loss_bbox_reg: 0.0331, s2.loss_cls: 0.0104, s2.acc: 98.3551, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0204, loss: 0.1939, grad_norm: 5.6022\n",
            "2020-09-09 17:27:39,367 - mmdet - INFO - Epoch [18][1600/5332]\tlr: 1.000e-05, eta: 7:51:18, time: 1.954, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0266, s0.acc: 98.9258, s0.loss_bbox_cls: 0.0193, s0.loss_bbox_reg: 0.0392, s1.loss_cls: 0.0209, s1.acc: 98.3490, s1.loss_bbox_cls: 0.0129, s1.loss_bbox_reg: 0.0276, s2.loss_cls: 0.0123, s2.acc: 98.0133, s2.loss_bbox_cls: 0.0069, s2.loss_bbox_reg: 0.0164, loss: 0.1926, grad_norm: 5.9810\n",
            "2020-09-09 17:29:45,800 - mmdet - INFO - Epoch [18][1664/5332]\tlr: 1.000e-05, eta: 7:49:13, time: 1.976, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0219, s0.acc: 99.1211, s0.loss_bbox_cls: 0.0206, s0.loss_bbox_reg: 0.0446, s1.loss_cls: 0.0148, s1.acc: 98.8617, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0348, s2.loss_cls: 0.0104, s2.acc: 98.1049, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0221, loss: 0.2051, grad_norm: 5.6424\n",
            "2020-09-09 17:31:49,205 - mmdet - INFO - Epoch [18][1728/5332]\tlr: 1.000e-05, eta: 7:47:03, time: 1.928, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0255, s0.acc: 98.9777, s0.loss_bbox_cls: 0.0219, s0.loss_bbox_reg: 0.0442, s1.loss_cls: 0.0181, s1.acc: 98.4589, s1.loss_bbox_cls: 0.0175, s1.loss_bbox_reg: 0.0348, s2.loss_cls: 0.0118, s2.acc: 97.8271, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0214, loss: 0.2128, grad_norm: 5.6716\n",
            "2020-09-09 17:33:54,124 - mmdet - INFO - Epoch [18][1792/5332]\tlr: 1.000e-05, eta: 7:44:56, time: 1.952, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0216, s0.acc: 99.1150, s0.loss_bbox_cls: 0.0170, s0.loss_bbox_reg: 0.0388, s1.loss_cls: 0.0160, s1.acc: 98.7518, s1.loss_bbox_cls: 0.0130, s1.loss_bbox_reg: 0.0296, s2.loss_cls: 0.0101, s2.acc: 98.3673, s2.loss_bbox_cls: 0.0080, s2.loss_bbox_reg: 0.0181, loss: 0.1792, grad_norm: 5.5210\n",
            "2020-09-09 17:36:00,361 - mmdet - INFO - Epoch [18][1856/5332]\tlr: 1.000e-05, eta: 7:42:51, time: 1.972, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0202, s0.acc: 99.1699, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0438, s1.loss_cls: 0.0141, s1.acc: 98.8861, s1.loss_bbox_cls: 0.0181, s1.loss_bbox_reg: 0.0342, s2.loss_cls: 0.0093, s2.acc: 98.3978, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0207, loss: 0.1974, grad_norm: 5.3129\n",
            "2020-09-09 17:38:05,752 - mmdet - INFO - Epoch [18][1920/5332]\tlr: 1.000e-05, eta: 7:40:45, time: 1.959, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0189, s0.acc: 99.3195, s0.loss_bbox_cls: 0.0204, s0.loss_bbox_reg: 0.0433, s1.loss_cls: 0.0157, s1.acc: 98.7671, s1.loss_bbox_cls: 0.0162, s1.loss_bbox_reg: 0.0354, s2.loss_cls: 0.0106, s2.acc: 98.0743, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0223, loss: 0.2002, grad_norm: 5.4845\n",
            "2020-09-09 17:40:12,143 - mmdet - INFO - Epoch [18][1984/5332]\tlr: 1.000e-05, eta: 7:38:40, time: 1.975, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0025, s0.loss_cls: 0.0247, s0.acc: 99.0051, s0.loss_bbox_cls: 0.0181, s0.loss_bbox_reg: 0.0418, s1.loss_cls: 0.0172, s1.acc: 98.6572, s1.loss_bbox_cls: 0.0140, s1.loss_bbox_reg: 0.0320, s2.loss_cls: 0.0102, s2.acc: 98.3887, s2.loss_bbox_cls: 0.0080, s2.loss_bbox_reg: 0.0191, loss: 0.1905, grad_norm: 5.3344\n",
            "2020-09-09 17:42:16,795 - mmdet - INFO - Epoch [18][2048/5332]\tlr: 1.000e-05, eta: 7:36:33, time: 1.948, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0205, s0.acc: 99.2310, s0.loss_bbox_cls: 0.0183, s0.loss_bbox_reg: 0.0407, s1.loss_cls: 0.0155, s1.acc: 98.8525, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0348, s2.loss_cls: 0.0102, s2.acc: 98.4222, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0213, loss: 0.1949, grad_norm: 5.3122\n",
            "2020-09-09 17:44:21,511 - mmdet - INFO - Epoch [18][2112/5332]\tlr: 1.000e-05, eta: 7:34:25, time: 1.949, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0198, s0.acc: 99.2523, s0.loss_bbox_cls: 0.0195, s0.loss_bbox_reg: 0.0414, s1.loss_cls: 0.0136, s1.acc: 98.9471, s1.loss_bbox_cls: 0.0165, s1.loss_bbox_reg: 0.0315, s2.loss_cls: 0.0095, s2.acc: 98.3612, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0210, loss: 0.1892, grad_norm: 5.2336\n",
            "2020-09-09 17:46:26,643 - mmdet - INFO - Epoch [18][2176/5332]\tlr: 1.000e-05, eta: 7:32:18, time: 1.955, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0250, s0.acc: 98.9990, s0.loss_bbox_cls: 0.0190, s0.loss_bbox_reg: 0.0393, s1.loss_cls: 0.0190, s1.acc: 98.5565, s1.loss_bbox_cls: 0.0160, s1.loss_bbox_reg: 0.0314, s2.loss_cls: 0.0120, s2.acc: 98.0591, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0192, loss: 0.1976, grad_norm: 5.6994\n",
            "2020-09-09 17:48:34,150 - mmdet - INFO - Epoch [18][2240/5332]\tlr: 1.000e-05, eta: 7:30:16, time: 1.992, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0292, s0.acc: 98.8892, s0.loss_bbox_cls: 0.0272, s0.loss_bbox_reg: 0.0527, s1.loss_cls: 0.0191, s1.acc: 98.4497, s1.loss_bbox_cls: 0.0195, s1.loss_bbox_reg: 0.0378, s2.loss_cls: 0.0123, s2.acc: 97.8607, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0214, loss: 0.2385, grad_norm: 6.2679\n",
            "2020-09-09 17:50:38,906 - mmdet - INFO - Epoch [18][2304/5332]\tlr: 1.000e-05, eta: 7:28:09, time: 1.949, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0278, s0.acc: 98.9136, s0.loss_bbox_cls: 0.0213, s0.loss_bbox_reg: 0.0396, s1.loss_cls: 0.0235, s1.acc: 98.0896, s1.loss_bbox_cls: 0.0165, s1.loss_bbox_reg: 0.0290, s2.loss_cls: 0.0137, s2.acc: 97.5647, s2.loss_bbox_cls: 0.0086, s2.loss_bbox_reg: 0.0165, loss: 0.2025, grad_norm: 5.5467\n",
            "2020-09-09 17:52:44,869 - mmdet - INFO - Epoch [18][2368/5332]\tlr: 1.000e-05, eta: 7:26:04, time: 1.968, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0224, s0.acc: 99.1150, s0.loss_bbox_cls: 0.0233, s0.loss_bbox_reg: 0.0481, s1.loss_cls: 0.0154, s1.acc: 98.7396, s1.loss_bbox_cls: 0.0205, s1.loss_bbox_reg: 0.0381, s2.loss_cls: 0.0118, s2.acc: 98.2422, s2.loss_bbox_cls: 0.0115, s2.loss_bbox_reg: 0.0223, loss: 0.2201, grad_norm: 6.5737\n",
            "2020-09-09 17:54:49,470 - mmdet - INFO - Epoch [18][2432/5332]\tlr: 1.000e-05, eta: 7:23:56, time: 1.947, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0228, s0.acc: 99.1333, s0.loss_bbox_cls: 0.0222, s0.loss_bbox_reg: 0.0478, s1.loss_cls: 0.0169, s1.acc: 98.6359, s1.loss_bbox_cls: 0.0194, s1.loss_bbox_reg: 0.0373, s2.loss_cls: 0.0106, s2.acc: 98.0774, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0212, loss: 0.2165, grad_norm: 5.6298\n",
            "2020-09-09 17:56:54,442 - mmdet - INFO - Epoch [18][2496/5332]\tlr: 1.000e-05, eta: 7:21:49, time: 1.953, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0229, s0.acc: 99.0112, s0.loss_bbox_cls: 0.0180, s0.loss_bbox_reg: 0.0399, s1.loss_cls: 0.0172, s1.acc: 98.6420, s1.loss_bbox_cls: 0.0157, s1.loss_bbox_reg: 0.0317, s2.loss_cls: 0.0113, s2.acc: 98.1018, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0187, loss: 0.1915, grad_norm: 5.4913\n",
            "2020-09-09 17:59:00,365 - mmdet - INFO - Epoch [18][2560/5332]\tlr: 1.000e-05, eta: 7:19:44, time: 1.968, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0281, s0.acc: 98.8800, s0.loss_bbox_cls: 0.0264, s0.loss_bbox_reg: 0.0559, s1.loss_cls: 0.0191, s1.acc: 98.6053, s1.loss_bbox_cls: 0.0226, s1.loss_bbox_reg: 0.0446, s2.loss_cls: 0.0119, s2.acc: 98.2971, s2.loss_bbox_cls: 0.0117, s2.loss_bbox_reg: 0.0267, loss: 0.2566, grad_norm: 6.6637\n",
            "2020-09-09 18:01:05,363 - mmdet - INFO - Epoch [18][2624/5332]\tlr: 1.000e-05, eta: 7:17:37, time: 1.953, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0232, s0.acc: 99.0784, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0448, s1.loss_cls: 0.0168, s1.acc: 98.6572, s1.loss_bbox_cls: 0.0184, s1.loss_bbox_reg: 0.0377, s2.loss_cls: 0.0126, s2.acc: 97.9309, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0225, loss: 0.2161, grad_norm: 5.9764\n",
            "2020-09-09 18:03:10,665 - mmdet - INFO - Epoch [18][2688/5332]\tlr: 1.000e-05, eta: 7:15:31, time: 1.958, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0236, s0.acc: 99.0417, s0.loss_bbox_cls: 0.0188, s0.loss_bbox_reg: 0.0431, s1.loss_cls: 0.0176, s1.acc: 98.5901, s1.loss_bbox_cls: 0.0169, s1.loss_bbox_reg: 0.0366, s2.loss_cls: 0.0114, s2.acc: 98.0957, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0223, loss: 0.2098, grad_norm: 5.9620\n",
            "2020-09-09 18:05:14,488 - mmdet - INFO - Epoch [18][2752/5332]\tlr: 1.000e-05, eta: 7:13:22, time: 1.935, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0234, s0.acc: 99.1669, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0446, s1.loss_cls: 0.0160, s1.acc: 98.8129, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0339, s2.loss_cls: 0.0095, s2.acc: 98.4924, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0206, loss: 0.2080, grad_norm: 5.4584\n",
            "2020-09-09 18:07:22,035 - mmdet - INFO - Epoch [18][2816/5332]\tlr: 1.000e-05, eta: 7:11:19, time: 1.993, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0253, s0.acc: 99.0448, s0.loss_bbox_cls: 0.0222, s0.loss_bbox_reg: 0.0457, s1.loss_cls: 0.0162, s1.acc: 98.7152, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0342, s2.loss_cls: 0.0100, s2.acc: 98.4619, s2.loss_bbox_cls: 0.0094, s2.loss_bbox_reg: 0.0195, loss: 0.2082, grad_norm: 5.5878\n",
            "2020-09-09 18:09:26,560 - mmdet - INFO - Epoch [18][2880/5332]\tlr: 1.000e-05, eta: 7:09:12, time: 1.946, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0190, s0.acc: 99.2676, s0.loss_bbox_cls: 0.0174, s0.loss_bbox_reg: 0.0430, s1.loss_cls: 0.0125, s1.acc: 99.0021, s1.loss_bbox_cls: 0.0156, s1.loss_bbox_reg: 0.0333, s2.loss_cls: 0.0078, s2.acc: 98.8617, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0212, loss: 0.1880, grad_norm: 5.6520\n",
            "2020-09-09 18:11:33,311 - mmdet - INFO - Epoch [18][2944/5332]\tlr: 1.000e-05, eta: 7:07:08, time: 1.980, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0201, s0.acc: 99.2493, s0.loss_bbox_cls: 0.0224, s0.loss_bbox_reg: 0.0462, s1.loss_cls: 0.0179, s1.acc: 98.5260, s1.loss_bbox_cls: 0.0180, s1.loss_bbox_reg: 0.0358, s2.loss_cls: 0.0116, s2.acc: 97.9797, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0216, loss: 0.2124, grad_norm: 5.6110\n",
            "2020-09-09 18:13:39,050 - mmdet - INFO - Epoch [18][3008/5332]\tlr: 1.000e-05, eta: 7:05:02, time: 1.965, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0230, s0.acc: 99.1180, s0.loss_bbox_cls: 0.0191, s0.loss_bbox_reg: 0.0432, s1.loss_cls: 0.0177, s1.acc: 98.5504, s1.loss_bbox_cls: 0.0160, s1.loss_bbox_reg: 0.0334, s2.loss_cls: 0.0113, s2.acc: 98.1415, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0215, loss: 0.2057, grad_norm: 5.8009\n",
            "2020-09-09 18:15:44,225 - mmdet - INFO - Epoch [18][3072/5332]\tlr: 1.000e-05, eta: 7:02:56, time: 1.956, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0212, s0.acc: 99.0967, s0.loss_bbox_cls: 0.0183, s0.loss_bbox_reg: 0.0406, s1.loss_cls: 0.0171, s1.acc: 98.6481, s1.loss_bbox_cls: 0.0157, s1.loss_bbox_reg: 0.0325, s2.loss_cls: 0.0107, s2.acc: 98.2758, s2.loss_bbox_cls: 0.0092, s2.loss_bbox_reg: 0.0190, loss: 0.1908, grad_norm: 5.7021\n",
            "2020-09-09 18:17:48,998 - mmdet - INFO - Epoch [18][3136/5332]\tlr: 1.000e-05, eta: 7:00:49, time: 1.950, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0214, s0.acc: 99.1608, s0.loss_bbox_cls: 0.0180, s0.loss_bbox_reg: 0.0421, s1.loss_cls: 0.0146, s1.acc: 98.8770, s1.loss_bbox_cls: 0.0150, s1.loss_bbox_reg: 0.0331, s2.loss_cls: 0.0091, s2.acc: 98.5138, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0225, loss: 0.1927, grad_norm: 5.1922\n",
            "2020-09-09 18:19:52,886 - mmdet - INFO - Epoch [18][3200/5332]\tlr: 1.000e-05, eta: 6:58:41, time: 1.936, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0250, s0.acc: 98.9868, s0.loss_bbox_cls: 0.0213, s0.loss_bbox_reg: 0.0454, s1.loss_cls: 0.0183, s1.acc: 98.4955, s1.loss_bbox_cls: 0.0158, s1.loss_bbox_reg: 0.0323, s2.loss_cls: 0.0106, s2.acc: 98.2422, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0193, loss: 0.2050, grad_norm: 5.7129\n",
            "2020-09-09 18:21:58,323 - mmdet - INFO - Epoch [18][3264/5332]\tlr: 1.000e-05, eta: 6:56:35, time: 1.960, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0231, s0.acc: 99.0723, s0.loss_bbox_cls: 0.0213, s0.loss_bbox_reg: 0.0440, s1.loss_cls: 0.0163, s1.acc: 98.6328, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0353, s2.loss_cls: 0.0099, s2.acc: 98.3246, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0224, loss: 0.2073, grad_norm: 5.6709\n",
            "2020-09-09 18:24:03,916 - mmdet - INFO - Epoch [18][3328/5332]\tlr: 1.000e-05, eta: 6:54:29, time: 1.962, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0257, s0.acc: 99.0662, s0.loss_bbox_cls: 0.0233, s0.loss_bbox_reg: 0.0506, s1.loss_cls: 0.0184, s1.acc: 98.5474, s1.loss_bbox_cls: 0.0213, s1.loss_bbox_reg: 0.0394, s2.loss_cls: 0.0133, s2.acc: 97.8577, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0228, loss: 0.2352, grad_norm: 6.1436\n",
            "2020-09-09 18:26:09,752 - mmdet - INFO - Epoch [18][3392/5332]\tlr: 1.000e-05, eta: 6:52:24, time: 1.966, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0202, s0.acc: 99.2096, s0.loss_bbox_cls: 0.0196, s0.loss_bbox_reg: 0.0438, s1.loss_cls: 0.0149, s1.acc: 98.8251, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0359, s2.loss_cls: 0.0089, s2.acc: 98.6511, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0223, loss: 0.2002, grad_norm: 5.7871\n",
            "2020-09-09 18:28:16,290 - mmdet - INFO - Epoch [18][3456/5332]\tlr: 1.000e-05, eta: 6:50:19, time: 1.977, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0217, s0.acc: 99.0936, s0.loss_bbox_cls: 0.0189, s0.loss_bbox_reg: 0.0422, s1.loss_cls: 0.0172, s1.acc: 98.5291, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0343, s2.loss_cls: 0.0108, s2.acc: 98.2697, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0219, loss: 0.2006, grad_norm: 5.7618\n",
            "2020-09-09 18:30:20,997 - mmdet - INFO - Epoch [18][3520/5332]\tlr: 1.000e-05, eta: 6:48:12, time: 1.949, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0306, s0.acc: 98.8068, s0.loss_bbox_cls: 0.0237, s0.loss_bbox_reg: 0.0488, s1.loss_cls: 0.0213, s1.acc: 98.3368, s1.loss_bbox_cls: 0.0172, s1.loss_bbox_reg: 0.0347, s2.loss_cls: 0.0128, s2.acc: 97.8516, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0212, loss: 0.2291, grad_norm: 6.2137\n",
            "2020-09-09 18:32:28,459 - mmdet - INFO - Epoch [18][3584/5332]\tlr: 1.000e-05, eta: 6:46:09, time: 1.992, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0237, s0.acc: 98.9868, s0.loss_bbox_cls: 0.0251, s0.loss_bbox_reg: 0.0495, s1.loss_cls: 0.0195, s1.acc: 98.3246, s1.loss_bbox_cls: 0.0192, s1.loss_bbox_reg: 0.0368, s2.loss_cls: 0.0130, s2.acc: 97.7570, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0203, loss: 0.2253, grad_norm: 5.9145\n",
            "2020-09-09 18:34:32,952 - mmdet - INFO - Epoch [18][3648/5332]\tlr: 1.000e-05, eta: 6:44:02, time: 1.945, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0219, s0.acc: 99.0936, s0.loss_bbox_cls: 0.0203, s0.loss_bbox_reg: 0.0448, s1.loss_cls: 0.0152, s1.acc: 98.8983, s1.loss_bbox_cls: 0.0185, s1.loss_bbox_reg: 0.0368, s2.loss_cls: 0.0100, s2.acc: 98.3917, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0222, loss: 0.2093, grad_norm: 5.8709\n",
            "2020-09-09 18:36:38,574 - mmdet - INFO - Epoch [18][3712/5332]\tlr: 1.000e-05, eta: 6:41:56, time: 1.963, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0296, s0.acc: 98.9441, s0.loss_bbox_cls: 0.0203, s0.loss_bbox_reg: 0.0432, s1.loss_cls: 0.0207, s1.acc: 98.4253, s1.loss_bbox_cls: 0.0163, s1.loss_bbox_reg: 0.0343, s2.loss_cls: 0.0123, s2.acc: 98.0255, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0189, loss: 0.2140, grad_norm: 5.7952\n",
            "2020-09-09 18:38:41,771 - mmdet - INFO - Epoch [18][3776/5332]\tlr: 1.000e-05, eta: 6:39:47, time: 1.925, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0225, s0.acc: 99.1608, s0.loss_bbox_cls: 0.0198, s0.loss_bbox_reg: 0.0458, s1.loss_cls: 0.0151, s1.acc: 98.7610, s1.loss_bbox_cls: 0.0163, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0096, s2.acc: 98.1903, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0208, loss: 0.2030, grad_norm: 6.2807\n",
            "2020-09-09 18:40:46,323 - mmdet - INFO - Epoch [18][3840/5332]\tlr: 1.000e-05, eta: 6:37:40, time: 1.946, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0244, s0.acc: 99.0173, s0.loss_bbox_cls: 0.0220, s0.loss_bbox_reg: 0.0429, s1.loss_cls: 0.0185, s1.acc: 98.5046, s1.loss_bbox_cls: 0.0166, s1.loss_bbox_reg: 0.0320, s2.loss_cls: 0.0120, s2.acc: 98.0682, s2.loss_bbox_cls: 0.0092, s2.loss_bbox_reg: 0.0192, loss: 0.2075, grad_norm: 5.3374\n",
            "2020-09-09 18:42:51,782 - mmdet - INFO - Epoch [18][3904/5332]\tlr: 1.000e-05, eta: 6:35:34, time: 1.960, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0227, s0.acc: 99.0021, s0.loss_bbox_cls: 0.0212, s0.loss_bbox_reg: 0.0445, s1.loss_cls: 0.0164, s1.acc: 98.6877, s1.loss_bbox_cls: 0.0184, s1.loss_bbox_reg: 0.0369, s2.loss_cls: 0.0105, s2.acc: 98.2483, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0215, loss: 0.2101, grad_norm: 5.6782\n",
            "2020-09-09 18:44:57,543 - mmdet - INFO - Epoch [18][3968/5332]\tlr: 1.000e-05, eta: 6:33:29, time: 1.965, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0212, s0.acc: 99.1516, s0.loss_bbox_cls: 0.0152, s0.loss_bbox_reg: 0.0387, s1.loss_cls: 0.0153, s1.acc: 98.7732, s1.loss_bbox_cls: 0.0130, s1.loss_bbox_reg: 0.0308, s2.loss_cls: 0.0088, s2.acc: 98.7885, s2.loss_bbox_cls: 0.0082, s2.loss_bbox_reg: 0.0200, loss: 0.1800, grad_norm: 5.7544\n",
            "2020-09-09 18:47:02,873 - mmdet - INFO - Epoch [18][4032/5332]\tlr: 1.000e-05, eta: 6:31:23, time: 1.958, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0243, s0.acc: 99.0967, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0467, s1.loss_cls: 0.0150, s1.acc: 98.8342, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0371, s2.loss_cls: 0.0096, s2.acc: 98.4680, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0220, loss: 0.2099, grad_norm: 5.8546\n",
            "2020-09-09 18:49:09,286 - mmdet - INFO - Epoch [18][4096/5332]\tlr: 1.000e-05, eta: 6:29:18, time: 1.975, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0090, loss_rpn_bbox: 0.0069, s0.loss_cls: 0.0222, s0.acc: 99.1425, s0.loss_bbox_cls: 0.0216, s0.loss_bbox_reg: 0.0458, s1.loss_cls: 0.0169, s1.acc: 98.7488, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0351, s2.loss_cls: 0.0110, s2.acc: 97.9767, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0214, loss: 0.2174, grad_norm: 5.9625\n",
            "2020-09-09 18:51:14,312 - mmdet - INFO - Epoch [18][4160/5332]\tlr: 1.000e-05, eta: 6:27:12, time: 1.954, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0195, s0.acc: 99.1913, s0.loss_bbox_cls: 0.0186, s0.loss_bbox_reg: 0.0403, s1.loss_cls: 0.0154, s1.acc: 98.7122, s1.loss_bbox_cls: 0.0155, s1.loss_bbox_reg: 0.0321, s2.loss_cls: 0.0105, s2.acc: 98.2819, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0206, loss: 0.1896, grad_norm: 5.8621\n",
            "2020-09-09 18:53:18,799 - mmdet - INFO - Epoch [18][4224/5332]\tlr: 1.000e-05, eta: 6:25:05, time: 1.945, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0200, s0.acc: 99.1882, s0.loss_bbox_cls: 0.0175, s0.loss_bbox_reg: 0.0393, s1.loss_cls: 0.0143, s1.acc: 98.8892, s1.loss_bbox_cls: 0.0137, s1.loss_bbox_reg: 0.0290, s2.loss_cls: 0.0082, s2.acc: 98.8647, s2.loss_bbox_cls: 0.0080, s2.loss_bbox_reg: 0.0177, loss: 0.1774, grad_norm: 4.9673\n",
            "2020-09-09 18:55:23,854 - mmdet - INFO - Epoch [18][4288/5332]\tlr: 1.000e-05, eta: 6:22:59, time: 1.954, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0226, s0.acc: 99.1394, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0438, s1.loss_cls: 0.0180, s1.acc: 98.6023, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0345, s2.loss_cls: 0.0109, s2.acc: 98.2452, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0200, loss: 0.2043, grad_norm: 5.4501\n",
            "2020-09-09 18:57:29,441 - mmdet - INFO - Epoch [18][4352/5332]\tlr: 1.000e-05, eta: 6:20:53, time: 1.962, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0276, s0.acc: 98.9227, s0.loss_bbox_cls: 0.0218, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0184, s1.acc: 98.5077, s1.loss_bbox_cls: 0.0175, s1.loss_bbox_reg: 0.0343, s2.loss_cls: 0.0114, s2.acc: 98.1750, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0193, loss: 0.2125, grad_norm: 5.7011\n",
            "2020-09-09 18:59:34,109 - mmdet - INFO - Epoch [18][4416/5332]\tlr: 1.000e-05, eta: 6:18:46, time: 1.948, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0295, s0.acc: 98.8708, s0.loss_bbox_cls: 0.0297, s0.loss_bbox_reg: 0.0564, s1.loss_cls: 0.0204, s1.acc: 98.3429, s1.loss_bbox_cls: 0.0251, s1.loss_bbox_reg: 0.0455, s2.loss_cls: 0.0134, s2.acc: 97.7692, s2.loss_bbox_cls: 0.0134, s2.loss_bbox_reg: 0.0237, loss: 0.2655, grad_norm: 6.8028\n",
            "2020-09-09 19:01:39,827 - mmdet - INFO - Epoch [18][4480/5332]\tlr: 1.000e-05, eta: 6:16:41, time: 1.964, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0217, s0.acc: 99.2065, s0.loss_bbox_cls: 0.0187, s0.loss_bbox_reg: 0.0409, s1.loss_cls: 0.0156, s1.acc: 98.8007, s1.loss_bbox_cls: 0.0151, s1.loss_bbox_reg: 0.0293, s2.loss_cls: 0.0099, s2.acc: 98.3734, s2.loss_bbox_cls: 0.0087, s2.loss_bbox_reg: 0.0184, loss: 0.1870, grad_norm: 5.2851\n",
            "2020-09-09 19:03:43,921 - mmdet - INFO - Epoch [18][4544/5332]\tlr: 1.000e-05, eta: 6:14:33, time: 1.939, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0226, s0.acc: 99.1516, s0.loss_bbox_cls: 0.0219, s0.loss_bbox_reg: 0.0430, s1.loss_cls: 0.0157, s1.acc: 98.7152, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0306, s2.loss_cls: 0.0111, s2.acc: 97.9156, s2.loss_bbox_cls: 0.0088, s2.loss_bbox_reg: 0.0169, loss: 0.1986, grad_norm: 5.4419\n",
            "2020-09-09 19:05:49,679 - mmdet - INFO - Epoch [18][4608/5332]\tlr: 1.000e-05, eta: 6:12:28, time: 1.965, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0263, s0.acc: 98.8495, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0454, s1.loss_cls: 0.0188, s1.acc: 98.3551, s1.loss_bbox_cls: 0.0169, s1.loss_bbox_reg: 0.0334, s2.loss_cls: 0.0119, s2.acc: 97.8607, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0203, loss: 0.2124, grad_norm: 5.9046\n",
            "2020-09-09 19:07:53,745 - mmdet - INFO - Epoch [18][4672/5332]\tlr: 1.000e-05, eta: 6:10:21, time: 1.939, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0284, s0.acc: 98.8251, s0.loss_bbox_cls: 0.0226, s0.loss_bbox_reg: 0.0441, s1.loss_cls: 0.0216, s1.acc: 98.1232, s1.loss_bbox_cls: 0.0174, s1.loss_bbox_reg: 0.0345, s2.loss_cls: 0.0136, s2.acc: 97.5525, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0197, loss: 0.2196, grad_norm: 6.5353\n",
            "2020-09-09 19:09:59,735 - mmdet - INFO - Epoch [18][4736/5332]\tlr: 1.000e-05, eta: 6:08:16, time: 1.969, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0252, s0.acc: 99.0295, s0.loss_bbox_cls: 0.0224, s0.loss_bbox_reg: 0.0470, s1.loss_cls: 0.0195, s1.acc: 98.4467, s1.loss_bbox_cls: 0.0195, s1.loss_bbox_reg: 0.0380, s2.loss_cls: 0.0121, s2.acc: 98.1842, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0218, loss: 0.2234, grad_norm: 6.0379\n",
            "2020-09-09 19:12:05,542 - mmdet - INFO - Epoch [18][4800/5332]\tlr: 1.000e-05, eta: 6:06:10, time: 1.966, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0227, s0.acc: 99.0845, s0.loss_bbox_cls: 0.0236, s0.loss_bbox_reg: 0.0465, s1.loss_cls: 0.0164, s1.acc: 98.4741, s1.loss_bbox_cls: 0.0211, s1.loss_bbox_reg: 0.0369, s2.loss_cls: 0.0102, s2.acc: 98.0225, s2.loss_bbox_cls: 0.0134, s2.loss_bbox_reg: 0.0221, loss: 0.2194, grad_norm: 5.7166\n",
            "2020-09-09 19:14:10,962 - mmdet - INFO - Epoch [18][4864/5332]\tlr: 1.000e-05, eta: 6:04:04, time: 1.960, data_time: 0.005, memory: 8999, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0232, s0.acc: 99.0692, s0.loss_bbox_cls: 0.0244, s0.loss_bbox_reg: 0.0481, s1.loss_cls: 0.0159, s1.acc: 98.6725, s1.loss_bbox_cls: 0.0191, s1.loss_bbox_reg: 0.0390, s2.loss_cls: 0.0097, s2.acc: 98.3795, s2.loss_bbox_cls: 0.0115, s2.loss_bbox_reg: 0.0235, loss: 0.2226, grad_norm: 5.8691\n",
            "2020-09-09 19:16:16,284 - mmdet - INFO - Epoch [18][4928/5332]\tlr: 1.000e-05, eta: 6:01:58, time: 1.958, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0220, s0.acc: 99.1302, s0.loss_bbox_cls: 0.0196, s0.loss_bbox_reg: 0.0422, s1.loss_cls: 0.0159, s1.acc: 98.7488, s1.loss_bbox_cls: 0.0163, s1.loss_bbox_reg: 0.0337, s2.loss_cls: 0.0095, s2.acc: 98.4619, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0204, loss: 0.1966, grad_norm: 5.6103\n",
            "2020-09-09 19:18:21,487 - mmdet - INFO - Epoch [18][4992/5332]\tlr: 1.000e-05, eta: 5:59:52, time: 1.956, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0223, s0.acc: 99.1425, s0.loss_bbox_cls: 0.0229, s0.loss_bbox_reg: 0.0451, s1.loss_cls: 0.0157, s1.acc: 98.8129, s1.loss_bbox_cls: 0.0191, s1.loss_bbox_reg: 0.0358, s2.loss_cls: 0.0107, s2.acc: 98.0408, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0214, loss: 0.2113, grad_norm: 5.8908\n",
            "2020-09-09 19:20:26,042 - mmdet - INFO - Epoch [18][5056/5332]\tlr: 1.000e-05, eta: 5:57:46, time: 1.946, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0248, s0.acc: 98.9563, s0.loss_bbox_cls: 0.0232, s0.loss_bbox_reg: 0.0475, s1.loss_cls: 0.0188, s1.acc: 98.3582, s1.loss_bbox_cls: 0.0182, s1.loss_bbox_reg: 0.0360, s2.loss_cls: 0.0115, s2.acc: 98.1049, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0197, loss: 0.2183, grad_norm: 5.4517\n",
            "2020-09-09 19:22:31,743 - mmdet - INFO - Epoch [18][5120/5332]\tlr: 1.000e-05, eta: 5:55:40, time: 1.964, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0262, s0.acc: 98.9258, s0.loss_bbox_cls: 0.0202, s0.loss_bbox_reg: 0.0445, s1.loss_cls: 0.0200, s1.acc: 98.3704, s1.loss_bbox_cls: 0.0181, s1.loss_bbox_reg: 0.0361, s2.loss_cls: 0.0137, s2.acc: 97.7448, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0214, loss: 0.2192, grad_norm: 6.1756\n",
            "2020-09-09 19:24:38,879 - mmdet - INFO - Epoch [18][5184/5332]\tlr: 1.000e-05, eta: 5:53:36, time: 1.986, data_time: 0.004, memory: 8999, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0255, s0.acc: 98.9655, s0.loss_bbox_cls: 0.0214, s0.loss_bbox_reg: 0.0459, s1.loss_cls: 0.0169, s1.acc: 98.4589, s1.loss_bbox_cls: 0.0181, s1.loss_bbox_reg: 0.0362, s2.loss_cls: 0.0109, s2.acc: 98.2147, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0221, loss: 0.2150, grad_norm: 6.0882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUaWav8qVXDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9bec1d12-1ea1-4b29-d359-a81fe58f65f8"
      },
      "source": [
        "!python tools/train.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py --resume-from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_19.pth"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-10 14:25:14,857 - mmdet - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]\n",
            "CUDA available: True\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
            "GPU 0: Tesla T4\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.4.0\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CUDA Runtime 10.0\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.1\n",
            "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "TorchVision: 0.5.0\n",
            "OpenCV: 4.4.0\n",
            "MMCV: 1.1.2\n",
            "MMDetection: 2.3.0+\n",
            "MMDetection Compiler: GCC 7.5\n",
            "MMDetection CUDA Compiler: 10.1\n",
            "------------------------------------------------------------\n",
            "\n",
            "2020-09-10 14:25:15,616 - mmdet - INFO - Distributed training: False\n",
            "2020-09-10 14:25:16,401 - mmdet - INFO - Config:\n",
            "model = dict(\n",
            "    type='CascadeRCNN',\n",
            "    pretrained='open-mmlab://resnext101_32x4d',\n",
            "    backbone=dict(\n",
            "        type='DetectoRS_ResNeXt',\n",
            "        depth=101,\n",
            "        groups=32,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch',\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(False, True, True, True),\n",
            "        output_img=True),\n",
            "    neck=dict(\n",
            "        type='RFP',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5,\n",
            "        rfp_steps=2,\n",
            "        aspp_out_channels=64,\n",
            "        aspp_dilations=(1, 3, 6, 1),\n",
            "        rfp_backbone=dict(\n",
            "            rfp_inplanes=256,\n",
            "            type='DetectoRS_ResNeXt',\n",
            "            depth=101,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(False, True, True, True),\n",
            "            pretrained='open-mmlab://resnext101_32x4d',\n",
            "            style='pytorch')),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(\n",
            "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='CascadeRoIHead',\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[1, 0.5, 0.25],\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='GenericRoIExtractor',\n",
            "            aggregation='sum',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32],\n",
            "            pre_cfg=dict(\n",
            "                type='ConvModule',\n",
            "                in_channels=256,\n",
            "                out_channels=256,\n",
            "                kernel_size=5,\n",
            "                padding=2,\n",
            "                inplace=False),\n",
            "            post_cfg=dict(\n",
            "                type='GeneralizedAttention',\n",
            "                in_channels=256,\n",
            "                spatial_range=-1,\n",
            "                num_heads=6,\n",
            "                attention_type='0100',\n",
            "                kv_stride=2)),\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.7),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.5),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='SABLHead',\n",
            "                num_classes=10,\n",
            "                cls_in_channels=256,\n",
            "                reg_in_channels=256,\n",
            "                roi_feat_size=7,\n",
            "                reg_feat_up_ratio=2,\n",
            "                reg_pre_kernel=3,\n",
            "                reg_post_kernel=3,\n",
            "                reg_pre_num=2,\n",
            "                reg_post_num=1,\n",
            "                cls_out_channels=1024,\n",
            "                reg_offset_out_channels=256,\n",
            "                reg_cls_out_channels=256,\n",
            "                num_cls_fcs=1,\n",
            "                num_reg_fcs=0,\n",
            "                reg_class_agnostic=False,\n",
            "                norm_cfg=None,\n",
            "                bbox_coder=dict(\n",
            "                    type='BucketingBBoxCoder',\n",
            "                    num_buckets=14,\n",
            "                    scale_factor=1.3),\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_cls=dict(\n",
            "                    type='CrossEntropyLoss', use_sigmoid=True,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox_reg=dict(\n",
            "                    type='SmoothL1Loss', beta=0.1, loss_weight=1.0))\n",
            "        ]))\n",
            "train_cfg = dict(\n",
            "    rpn=dict(\n",
            "        assigner=dict(\n",
            "            type='MaxIoUAssigner',\n",
            "            pos_iou_thr=0.7,\n",
            "            neg_iou_thr=0.3,\n",
            "            min_pos_iou=0.3,\n",
            "            match_low_quality=True,\n",
            "            ignore_iof_thr=-1),\n",
            "        sampler=dict(\n",
            "            type='RandomSampler',\n",
            "            num=256,\n",
            "            pos_fraction=0.5,\n",
            "            neg_pos_ub=-1,\n",
            "            add_gt_as_proposals=False),\n",
            "        allowed_border=0,\n",
            "        pos_weight=-1,\n",
            "        debug=False),\n",
            "    rpn_proposal=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=2000,\n",
            "        nms_post=2000,\n",
            "        max_num=2000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=[\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.6,\n",
            "                neg_iou_thr=0.6,\n",
            "                min_pos_iou=0.6,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.7,\n",
            "                min_pos_iou=0.7,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)\n",
            "    ])\n",
            "test_cfg = dict(\n",
            "    rpn=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=1000,\n",
            "        nms_post=1000,\n",
            "        max_num=1000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=dict(\n",
            "        score_thr=0.05,\n",
            "        nms=dict(type='nms', iou_threshold=0.5),\n",
            "        max_per_img=100))\n",
            "dataset_type = 'CustomDataset'\n",
            "data_root = 'data/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "albu_train_transforms = [\n",
            "    dict(\n",
            "        type='ShiftScaleRotate',\n",
            "        shift_limit=0.0625,\n",
            "        scale_limit=0.0,\n",
            "        rotate_limit=0,\n",
            "        interpolation=1,\n",
            "        p=0.5),\n",
            "    dict(\n",
            "        type='RandomBrightnessContrast',\n",
            "        brightness_limit=[0.1, 0.3],\n",
            "        contrast_limit=[0.1, 0.3],\n",
            "        p=0.2),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='RGBShift',\n",
            "                r_shift_limit=10,\n",
            "                g_shift_limit=10,\n",
            "                b_shift_limit=10,\n",
            "                p=1.0),\n",
            "            dict(\n",
            "                type='HueSaturationValue',\n",
            "                hue_shift_limit=20,\n",
            "                sat_shift_limit=30,\n",
            "                val_shift_limit=20,\n",
            "                p=1.0)\n",
            "        ],\n",
            "        p=0.1),\n",
            "    dict(type='JpegCompression', quality_lower=85, quality_upper=95, p=0.2),\n",
            "    dict(type='ChannelShuffle', p=0.1),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "        ],\n",
            "        p=0.1)\n",
            "]\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        type='Resize',\n",
            "        multiscale_mode='range',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(\n",
            "        type='Albu',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='ShiftScaleRotate',\n",
            "                shift_limit=0.0625,\n",
            "                scale_limit=0.0,\n",
            "                rotate_limit=0,\n",
            "                interpolation=1,\n",
            "                p=0.5),\n",
            "            dict(\n",
            "                type='RandomBrightnessContrast',\n",
            "                brightness_limit=[0.1, 0.3],\n",
            "                contrast_limit=[0.1, 0.3],\n",
            "                p=0.2),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='RGBShift',\n",
            "                        r_shift_limit=10,\n",
            "                        g_shift_limit=10,\n",
            "                        b_shift_limit=10,\n",
            "                        p=1.0),\n",
            "                    dict(\n",
            "                        type='HueSaturationValue',\n",
            "                        hue_shift_limit=20,\n",
            "                        sat_shift_limit=30,\n",
            "                        val_shift_limit=20,\n",
            "                        p=1.0)\n",
            "                ],\n",
            "                p=0.1),\n",
            "            dict(\n",
            "                type='JpegCompression',\n",
            "                quality_lower=85,\n",
            "                quality_upper=95,\n",
            "                p=0.2),\n",
            "            dict(type='ChannelShuffle', p=0.1),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                    dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                ],\n",
            "                p=0.1)\n",
            "        ],\n",
            "        bbox_params=dict(\n",
            "            type='BboxParams',\n",
            "            format='pascal_voc',\n",
            "            label_fields=['gt_labels'],\n",
            "            min_visibility=0.0,\n",
            "            filter_lost_elements=True),\n",
            "        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "        update_pad_shape=False,\n",
            "        skip_img_without_anno=True),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(\n",
            "        type='Collect',\n",
            "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "        meta_keys=('filename', 'ori_shape', 'img_shape', 'img_norm_cfg',\n",
            "                   'pad_shape', 'scale_factor'))\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        transforms=[\n",
            "            dict(type='Resize', multiscale_mode='range', keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=1.0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=1,\n",
            "    workers_per_gpu=1,\n",
            "    train=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/train_80_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                multiscale_mode='range',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(\n",
            "                type='Albu',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='ShiftScaleRotate',\n",
            "                        shift_limit=0.0625,\n",
            "                        scale_limit=0.0,\n",
            "                        rotate_limit=0,\n",
            "                        interpolation=1,\n",
            "                        p=0.5),\n",
            "                    dict(\n",
            "                        type='RandomBrightnessContrast',\n",
            "                        brightness_limit=[0.1, 0.3],\n",
            "                        contrast_limit=[0.1, 0.3],\n",
            "                        p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(\n",
            "                                type='RGBShift',\n",
            "                                r_shift_limit=10,\n",
            "                                g_shift_limit=10,\n",
            "                                b_shift_limit=10,\n",
            "                                p=1.0),\n",
            "                            dict(\n",
            "                                type='HueSaturationValue',\n",
            "                                hue_shift_limit=20,\n",
            "                                sat_shift_limit=30,\n",
            "                                val_shift_limit=20,\n",
            "                                p=1.0)\n",
            "                        ],\n",
            "                        p=0.1),\n",
            "                    dict(\n",
            "                        type='JpegCompression',\n",
            "                        quality_lower=75,\n",
            "                        quality_upper=95,\n",
            "                        p=0.2),\n",
            "                    dict(type='ChannelShuffle', p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                        ],\n",
            "                        p=0.1)\n",
            "                ],\n",
            "                bbox_params=dict(\n",
            "                    type='BboxParams',\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=['gt_labels'],\n",
            "                    min_visibility=0.0,\n",
            "                    filter_lost_elements=True),\n",
            "                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "                update_pad_shape=False,\n",
            "                skip_img_without_anno=True),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "                meta_keys=('filename', 'ori_shape', 'img_shape',\n",
            "                           'img_norm_cfg', 'pad_shape', 'scale_factor'))\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/val_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/test_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 200), (1999, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=1, metric='mAP')\n",
            "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.3333333333333333,\n",
            "    step=[8, 11])\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=64, hooks=[dict(type='TextLoggerHook')])\n",
            "total_epochs = 20\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "work_dir = './work_dirs/cascade_rcnn_x101_32x4d_fpn_1x'\n",
            "load_from = None\n",
            "resume_from = 'work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_19.pth'\n",
            "workflow = [('train', 1)]\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "2020-09-10 14:25:20,553 - mmdet - INFO - load model from: open-mmlab://resnext101_32x4d\n",
            "Downloading: \"https://openmmlab.oss-accelerate.aliyuncs.com/pretrain/third_party/resnext101_32x4d-a5af3160.pth\" to /root/.cache/torch/checkpoints/resnext101_32x4d-a5af3160.pth\n",
            "100% 161M/161M [00:14<00:00, 11.7MB/s]\n",
            "2020-09-10 14:25:36,475 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "2020-09-10 14:25:37,052 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
            "size mismatch for layer1.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.2.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
            "size mismatch for layer2.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.0.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.1.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.1.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.2.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.2.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.2.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.3.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.3.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.3.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
            "size mismatch for layer3.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.2.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.3.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.3.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.3.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.4.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.4.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.4.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.5.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.5.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.5.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.6.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.6.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.6.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.7.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.7.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.7.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.8.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.8.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.8.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.9.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.9.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.9.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.10.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.10.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.10.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.11.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.11.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.11.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.12.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.12.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.12.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.13.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.13.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.13.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.14.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.14.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.14.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.15.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.15.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.15.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.16.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.16.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.16.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.17.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.17.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.17.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.18.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.18.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.18.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.19.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.19.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.19.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.20.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.20.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.20.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.21.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.21.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.21.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.22.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.22.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.22.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
            "size mismatch for layer4.0.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.0.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.1.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.1.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.2.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.2.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.2.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-10 14:25:43,276 - mmdet - INFO - load checkpoint from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_19.pth\n",
            "2020-09-10 14:25:55,725 - mmdet - INFO - resumed epoch 19, iter 101308\n",
            "2020-09-10 14:25:55,733 - mmdet - INFO - Start running, host: root@a541ab032b1f, work_dir: /content/drive/My Drive/mmdetection-master/work_dirs/cascade_rcnn_x101_32x4d_fpn_1x\n",
            "2020-09-10 14:25:55,734 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs\n",
            "2020-09-10 14:28:15,642 - mmdet - INFO - Epoch [20][64/5332]\tlr: 1.000e-05, eta: 3:11:54, time: 2.186, data_time: 0.047, memory: 8119, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0223, s0.acc: 99.1516, s0.loss_bbox_cls: 0.0195, s0.loss_bbox_reg: 0.0440, s1.loss_cls: 0.0138, s1.acc: 98.8647, s1.loss_bbox_cls: 0.0158, s1.loss_bbox_reg: 0.0343, s2.loss_cls: 0.0098, s2.acc: 98.5657, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0213, loss: 0.2010, grad_norm: 5.4933\n",
            "2020-09-10 14:30:33,821 - mmdet - INFO - Epoch [20][128/5332]\tlr: 1.000e-05, eta: 3:08:25, time: 2.159, data_time: 0.005, memory: 8119, loss_rpn_cls: 0.0077, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0247, s0.acc: 99.0417, s0.loss_bbox_cls: 0.0203, s0.loss_bbox_reg: 0.0448, s1.loss_cls: 0.0173, s1.acc: 98.7274, s1.loss_bbox_cls: 0.0161, s1.loss_bbox_reg: 0.0335, s2.loss_cls: 0.0105, s2.acc: 98.4894, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0202, loss: 0.2091, grad_norm: 5.9471\n",
            "2020-09-10 14:32:52,231 - mmdet - INFO - Epoch [20][192/5332]\tlr: 1.000e-05, eta: 3:05:49, time: 2.163, data_time: 0.005, memory: 8119, loss_rpn_cls: 0.0085, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0244, s0.acc: 99.0204, s0.loss_bbox_cls: 0.0239, s0.loss_bbox_reg: 0.0515, s1.loss_cls: 0.0184, s1.acc: 98.4680, s1.loss_bbox_cls: 0.0222, s1.loss_bbox_reg: 0.0422, s2.loss_cls: 0.0128, s2.acc: 97.6227, s2.loss_bbox_cls: 0.0130, s2.loss_bbox_reg: 0.0252, loss: 0.2458, grad_norm: 6.8991\n",
            "2020-09-10 14:35:09,790 - mmdet - INFO - Epoch [20][256/5332]\tlr: 1.000e-05, eta: 3:03:05, time: 2.149, data_time: 0.005, memory: 8119, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0257, s0.acc: 99.0234, s0.loss_bbox_cls: 0.0205, s0.loss_bbox_reg: 0.0436, s1.loss_cls: 0.0164, s1.acc: 98.7488, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0333, s2.loss_cls: 0.0103, s2.acc: 98.3398, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0191, loss: 0.2055, grad_norm: 5.2732\n",
            "2020-09-10 14:37:26,295 - mmdet - INFO - Epoch [20][320/5332]\tlr: 1.000e-05, eta: 3:00:15, time: 2.133, data_time: 0.005, memory: 8119, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0066, s0.loss_cls: 0.0197, s0.acc: 99.2188, s0.loss_bbox_cls: 0.0206, s0.loss_bbox_reg: 0.0436, s1.loss_cls: 0.0145, s1.acc: 98.8342, s1.loss_bbox_cls: 0.0169, s1.loss_bbox_reg: 0.0344, s2.loss_cls: 0.0083, s2.acc: 98.7213, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0210, loss: 0.1994, grad_norm: 5.4595\n",
            "2020-09-10 14:39:44,950 - mmdet - INFO - Epoch [20][384/5332]\tlr: 1.000e-05, eta: 2:58:04, time: 2.166, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0247, s0.acc: 99.1821, s0.loss_bbox_cls: 0.0183, s0.loss_bbox_reg: 0.0397, s1.loss_cls: 0.0161, s1.acc: 98.8708, s1.loss_bbox_cls: 0.0152, s1.loss_bbox_reg: 0.0302, s2.loss_cls: 0.0106, s2.acc: 98.3765, s2.loss_bbox_cls: 0.0073, s2.loss_bbox_reg: 0.0154, loss: 0.1834, grad_norm: 5.3284\n",
            "2020-09-10 14:42:03,065 - mmdet - INFO - Epoch [20][448/5332]\tlr: 1.000e-05, eta: 2:55:45, time: 2.158, data_time: 0.005, memory: 8119, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0280, s0.acc: 98.8770, s0.loss_bbox_cls: 0.0205, s0.loss_bbox_reg: 0.0460, s1.loss_cls: 0.0210, s1.acc: 98.3246, s1.loss_bbox_cls: 0.0156, s1.loss_bbox_reg: 0.0328, s2.loss_cls: 0.0129, s2.acc: 97.6929, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0207, loss: 0.2171, grad_norm: 6.7126\n",
            "2020-09-10 14:44:23,185 - mmdet - INFO - Epoch [20][512/5332]\tlr: 1.000e-05, eta: 2:53:45, time: 2.189, data_time: 0.005, memory: 8119, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0235, s0.acc: 99.0692, s0.loss_bbox_cls: 0.0175, s0.loss_bbox_reg: 0.0375, s1.loss_cls: 0.0176, s1.acc: 98.5107, s1.loss_bbox_cls: 0.0147, s1.loss_bbox_reg: 0.0299, s2.loss_cls: 0.0106, s2.acc: 98.0469, s2.loss_bbox_cls: 0.0085, s2.loss_bbox_reg: 0.0190, loss: 0.1856, grad_norm: 5.2377\n",
            "2020-09-10 14:46:41,183 - mmdet - INFO - Epoch [20][576/5332]\tlr: 1.000e-05, eta: 2:51:23, time: 2.156, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0018, s0.loss_cls: 0.0202, s0.acc: 99.1882, s0.loss_bbox_cls: 0.0179, s0.loss_bbox_reg: 0.0377, s1.loss_cls: 0.0155, s1.acc: 98.7549, s1.loss_bbox_cls: 0.0153, s1.loss_bbox_reg: 0.0288, s2.loss_cls: 0.0095, s2.acc: 98.3429, s2.loss_bbox_cls: 0.0079, s2.loss_bbox_reg: 0.0158, loss: 0.1735, grad_norm: 4.8955\n",
            "2020-09-10 14:48:58,740 - mmdet - INFO - Epoch [20][640/5332]\tlr: 1.000e-05, eta: 2:48:58, time: 2.149, data_time: 0.005, memory: 8119, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0213, s0.acc: 99.1852, s0.loss_bbox_cls: 0.0213, s0.loss_bbox_reg: 0.0485, s1.loss_cls: 0.0149, s1.acc: 98.8464, s1.loss_bbox_cls: 0.0183, s1.loss_bbox_reg: 0.0380, s2.loss_cls: 0.0107, s2.acc: 98.3337, s2.loss_bbox_cls: 0.0117, s2.loss_bbox_reg: 0.0250, loss: 0.2173, grad_norm: 5.9898\n",
            "2020-09-10 14:51:14,952 - mmdet - INFO - Epoch [20][704/5332]\tlr: 1.000e-05, eta: 2:46:26, time: 2.128, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0218, s0.acc: 99.0875, s0.loss_bbox_cls: 0.0203, s0.loss_bbox_reg: 0.0434, s1.loss_cls: 0.0169, s1.acc: 98.4833, s1.loss_bbox_cls: 0.0184, s1.loss_bbox_reg: 0.0360, s2.loss_cls: 0.0110, s2.acc: 97.8394, s2.loss_bbox_cls: 0.0117, s2.loss_bbox_reg: 0.0214, loss: 0.2076, grad_norm: 6.0517\n",
            "2020-09-10 14:53:32,732 - mmdet - INFO - Epoch [20][768/5332]\tlr: 1.000e-05, eta: 2:44:06, time: 2.153, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0219, s0.acc: 99.1608, s0.loss_bbox_cls: 0.0216, s0.loss_bbox_reg: 0.0479, s1.loss_cls: 0.0153, s1.acc: 98.8159, s1.loss_bbox_cls: 0.0191, s1.loss_bbox_reg: 0.0384, s2.loss_cls: 0.0098, s2.acc: 98.3887, s2.loss_bbox_cls: 0.0105, s2.loss_bbox_reg: 0.0228, loss: 0.2126, grad_norm: 6.4071\n",
            "2020-09-10 14:55:51,698 - mmdet - INFO - Epoch [20][832/5332]\tlr: 1.000e-05, eta: 2:41:53, time: 2.171, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0223, s0.acc: 99.1608, s0.loss_bbox_cls: 0.0162, s0.loss_bbox_reg: 0.0351, s1.loss_cls: 0.0180, s1.acc: 98.6542, s1.loss_bbox_cls: 0.0114, s1.loss_bbox_reg: 0.0257, s2.loss_cls: 0.0112, s2.acc: 98.3978, s2.loss_bbox_cls: 0.0076, s2.loss_bbox_reg: 0.0159, loss: 0.1718, grad_norm: 5.5594\n",
            "2020-09-10 14:58:09,006 - mmdet - INFO - Epoch [20][896/5332]\tlr: 1.000e-05, eta: 2:39:31, time: 2.145, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0063, s0.loss_cls: 0.0227, s0.acc: 99.0967, s0.loss_bbox_cls: 0.0182, s0.loss_bbox_reg: 0.0400, s1.loss_cls: 0.0140, s1.acc: 98.8251, s1.loss_bbox_cls: 0.0135, s1.loss_bbox_reg: 0.0302, s2.loss_cls: 0.0093, s2.acc: 98.4619, s2.loss_bbox_cls: 0.0080, s2.loss_bbox_reg: 0.0190, loss: 0.1835, grad_norm: 5.4694\n",
            "2020-09-10 15:00:24,822 - mmdet - INFO - Epoch [20][960/5332]\tlr: 1.000e-05, eta: 2:37:02, time: 2.122, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0239, s0.acc: 99.0906, s0.loss_bbox_cls: 0.0229, s0.loss_bbox_reg: 0.0476, s1.loss_cls: 0.0153, s1.acc: 98.8434, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0356, s2.loss_cls: 0.0111, s2.acc: 98.0164, s2.loss_bbox_cls: 0.0085, s2.loss_bbox_reg: 0.0200, loss: 0.2104, grad_norm: 6.0856\n",
            "2020-09-10 15:02:53,205 - mmdet - INFO - Epoch [20][1024/5332]\tlr: 1.000e-05, eta: 2:35:28, time: 2.318, data_time: 0.192, memory: 8119, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0244, s0.acc: 98.9410, s0.loss_bbox_cls: 0.0202, s0.loss_bbox_reg: 0.0471, s1.loss_cls: 0.0187, s1.acc: 98.6847, s1.loss_bbox_cls: 0.0184, s1.loss_bbox_reg: 0.0384, s2.loss_cls: 0.0118, s2.acc: 97.8760, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0226, loss: 0.2204, grad_norm: 6.7044\n",
            "2020-09-10 15:05:10,206 - mmdet - INFO - Epoch [20][1088/5332]\tlr: 1.000e-05, eta: 2:33:04, time: 2.141, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0211, s0.acc: 99.1760, s0.loss_bbox_cls: 0.0189, s0.loss_bbox_reg: 0.0413, s1.loss_cls: 0.0158, s1.acc: 98.6755, s1.loss_bbox_cls: 0.0153, s1.loss_bbox_reg: 0.0320, s2.loss_cls: 0.0099, s2.acc: 98.3337, s2.loss_bbox_cls: 0.0085, s2.loss_bbox_reg: 0.0192, loss: 0.1881, grad_norm: 5.5432\n",
            "2020-09-10 15:07:28,663 - mmdet - INFO - Epoch [20][1152/5332]\tlr: 1.000e-05, eta: 2:30:45, time: 2.163, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0273, s0.acc: 98.9258, s0.loss_bbox_cls: 0.0225, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0208, s1.acc: 98.3459, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0330, s2.loss_cls: 0.0138, s2.acc: 97.6593, s2.loss_bbox_cls: 0.0083, s2.loss_bbox_reg: 0.0179, loss: 0.2148, grad_norm: 5.7955\n",
            "2020-09-10 15:09:46,566 - mmdet - INFO - Epoch [20][1216/5332]\tlr: 1.000e-05, eta: 2:28:24, time: 2.155, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0263, s0.acc: 98.9441, s0.loss_bbox_cls: 0.0218, s0.loss_bbox_reg: 0.0468, s1.loss_cls: 0.0201, s1.acc: 98.3185, s1.loss_bbox_cls: 0.0190, s1.loss_bbox_reg: 0.0385, s2.loss_cls: 0.0126, s2.acc: 97.9309, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0224, loss: 0.2274, grad_norm: 6.1102\n",
            "2020-09-10 15:12:02,445 - mmdet - INFO - Epoch [20][1280/5332]\tlr: 1.000e-05, eta: 2:25:58, time: 2.123, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0261, s0.acc: 98.9502, s0.loss_bbox_cls: 0.0260, s0.loss_bbox_reg: 0.0538, s1.loss_cls: 0.0168, s1.acc: 98.7061, s1.loss_bbox_cls: 0.0216, s1.loss_bbox_reg: 0.0400, s2.loss_cls: 0.0123, s2.acc: 97.9401, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0217, loss: 0.2359, grad_norm: 6.3159\n",
            "2020-09-10 15:14:19,702 - mmdet - INFO - Epoch [20][1344/5332]\tlr: 1.000e-05, eta: 2:23:36, time: 2.145, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0172, s0.acc: 99.2981, s0.loss_bbox_cls: 0.0178, s0.loss_bbox_reg: 0.0395, s1.loss_cls: 0.0133, s1.acc: 98.9136, s1.loss_bbox_cls: 0.0151, s1.loss_bbox_reg: 0.0312, s2.loss_cls: 0.0085, s2.acc: 98.5901, s2.loss_bbox_cls: 0.0092, s2.loss_bbox_reg: 0.0189, loss: 0.1791, grad_norm: 5.5453\n",
            "2020-09-10 15:16:37,046 - mmdet - INFO - Epoch [20][1408/5332]\tlr: 1.000e-05, eta: 2:21:15, time: 2.146, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0256, s0.acc: 99.0692, s0.loss_bbox_cls: 0.0228, s0.loss_bbox_reg: 0.0466, s1.loss_cls: 0.0176, s1.acc: 98.6542, s1.loss_bbox_cls: 0.0183, s1.loss_bbox_reg: 0.0341, s2.loss_cls: 0.0113, s2.acc: 98.1750, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0220, loss: 0.2173, grad_norm: 6.1680\n",
            "2020-09-10 15:18:53,129 - mmdet - INFO - Epoch [20][1472/5332]\tlr: 1.000e-05, eta: 2:18:51, time: 2.126, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0195, s0.acc: 99.2462, s0.loss_bbox_cls: 0.0197, s0.loss_bbox_reg: 0.0401, s1.loss_cls: 0.0122, s1.acc: 99.1272, s1.loss_bbox_cls: 0.0159, s1.loss_bbox_reg: 0.0329, s2.loss_cls: 0.0079, s2.acc: 98.7488, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0193, loss: 0.1830, grad_norm: 5.1156\n",
            "2020-09-10 15:21:11,427 - mmdet - INFO - Epoch [20][1536/5332]\tlr: 1.000e-05, eta: 2:16:34, time: 2.161, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0291, s0.acc: 98.9380, s0.loss_bbox_cls: 0.0247, s0.loss_bbox_reg: 0.0502, s1.loss_cls: 0.0219, s1.acc: 98.1506, s1.loss_bbox_cls: 0.0215, s1.loss_bbox_reg: 0.0398, s2.loss_cls: 0.0131, s2.acc: 97.7539, s2.loss_bbox_cls: 0.0119, s2.loss_bbox_reg: 0.0214, loss: 0.2453, grad_norm: 6.4839\n",
            "2020-09-10 15:23:27,006 - mmdet - INFO - Epoch [20][1600/5332]\tlr: 1.000e-05, eta: 2:14:10, time: 2.118, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0212, s0.acc: 99.1669, s0.loss_bbox_cls: 0.0188, s0.loss_bbox_reg: 0.0417, s1.loss_cls: 0.0156, s1.acc: 98.7396, s1.loss_bbox_cls: 0.0160, s1.loss_bbox_reg: 0.0342, s2.loss_cls: 0.0101, s2.acc: 98.2330, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0208, loss: 0.1986, grad_norm: 5.9864\n",
            "2020-09-10 15:25:42,093 - mmdet - INFO - Epoch [20][1664/5332]\tlr: 1.000e-05, eta: 2:11:45, time: 2.111, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0246, s0.acc: 99.0204, s0.loss_bbox_cls: 0.0252, s0.loss_bbox_reg: 0.0463, s1.loss_cls: 0.0169, s1.acc: 98.6206, s1.loss_bbox_cls: 0.0194, s1.loss_bbox_reg: 0.0349, s2.loss_cls: 0.0107, s2.acc: 98.1323, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0205, loss: 0.2172, grad_norm: 5.6999\n",
            "2020-09-10 15:27:58,540 - mmdet - INFO - Epoch [20][1728/5332]\tlr: 1.000e-05, eta: 2:09:24, time: 2.132, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0275, s0.acc: 99.0356, s0.loss_bbox_cls: 0.0246, s0.loss_bbox_reg: 0.0498, s1.loss_cls: 0.0199, s1.acc: 98.6786, s1.loss_bbox_cls: 0.0199, s1.loss_bbox_reg: 0.0388, s2.loss_cls: 0.0119, s2.acc: 98.1445, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0225, loss: 0.2340, grad_norm: 5.6903\n",
            "2020-09-10 15:30:17,341 - mmdet - INFO - Epoch [20][1792/5332]\tlr: 1.000e-05, eta: 2:07:08, time: 2.169, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0255, s0.acc: 98.9807, s0.loss_bbox_cls: 0.0225, s0.loss_bbox_reg: 0.0426, s1.loss_cls: 0.0180, s1.acc: 98.5107, s1.loss_bbox_cls: 0.0174, s1.loss_bbox_reg: 0.0315, s2.loss_cls: 0.0113, s2.acc: 98.1415, s2.loss_bbox_cls: 0.0082, s2.loss_bbox_reg: 0.0168, loss: 0.2026, grad_norm: 5.2899\n",
            "2020-09-10 15:32:35,089 - mmdet - INFO - Epoch [20][1856/5332]\tlr: 1.000e-05, eta: 2:04:50, time: 2.152, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0301, s0.acc: 98.8678, s0.loss_bbox_cls: 0.0218, s0.loss_bbox_reg: 0.0474, s1.loss_cls: 0.0211, s1.acc: 98.2819, s1.loss_bbox_cls: 0.0170, s1.loss_bbox_reg: 0.0364, s2.loss_cls: 0.0127, s2.acc: 97.8516, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0206, loss: 0.2263, grad_norm: 6.1198\n",
            "2020-09-10 15:34:53,939 - mmdet - INFO - Epoch [20][1920/5332]\tlr: 1.000e-05, eta: 2:02:33, time: 2.170, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0189, s0.acc: 99.2401, s0.loss_bbox_cls: 0.0207, s0.loss_bbox_reg: 0.0429, s1.loss_cls: 0.0153, s1.acc: 98.7610, s1.loss_bbox_cls: 0.0190, s1.loss_bbox_reg: 0.0357, s2.loss_cls: 0.0093, s2.acc: 98.5626, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0206, loss: 0.1979, grad_norm: 5.3366\n",
            "2020-09-10 15:37:10,641 - mmdet - INFO - Epoch [20][1984/5332]\tlr: 1.000e-05, eta: 2:00:13, time: 2.136, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0214, s0.acc: 99.2004, s0.loss_bbox_cls: 0.0217, s0.loss_bbox_reg: 0.0452, s1.loss_cls: 0.0147, s1.acc: 98.9380, s1.loss_bbox_cls: 0.0169, s1.loss_bbox_reg: 0.0349, s2.loss_cls: 0.0088, s2.acc: 98.5992, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0214, loss: 0.2020, grad_norm: 5.4194\n",
            "2020-09-10 15:39:28,683 - mmdet - INFO - Epoch [20][2048/5332]\tlr: 1.000e-05, eta: 1:57:56, time: 2.157, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0202, s0.acc: 99.2218, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0455, s1.loss_cls: 0.0166, s1.acc: 98.6725, s1.loss_bbox_cls: 0.0193, s1.loss_bbox_reg: 0.0378, s2.loss_cls: 0.0111, s2.acc: 98.4253, s2.loss_bbox_cls: 0.0119, s2.loss_bbox_reg: 0.0230, loss: 0.2124, grad_norm: 5.8687\n",
            "2020-09-10 15:41:44,964 - mmdet - INFO - Epoch [20][2112/5332]\tlr: 1.000e-05, eta: 1:55:35, time: 2.129, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0063, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0265, s0.acc: 98.8953, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0459, s1.loss_cls: 0.0205, s1.acc: 98.3093, s1.loss_bbox_cls: 0.0183, s1.loss_bbox_reg: 0.0368, s2.loss_cls: 0.0136, s2.acc: 97.7264, s2.loss_bbox_cls: 0.0110, s2.loss_bbox_reg: 0.0225, loss: 0.2295, grad_norm: 6.5031\n",
            "2020-09-10 15:44:01,431 - mmdet - INFO - Epoch [20][2176/5332]\tlr: 1.000e-05, eta: 1:53:15, time: 2.132, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0290, s0.acc: 98.8312, s0.loss_bbox_cls: 0.0231, s0.loss_bbox_reg: 0.0448, s1.loss_cls: 0.0220, s1.acc: 98.1781, s1.loss_bbox_cls: 0.0183, s1.loss_bbox_reg: 0.0333, s2.loss_cls: 0.0139, s2.acc: 97.3969, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0183, loss: 0.2211, grad_norm: 6.3381\n",
            "2020-09-10 15:46:18,597 - mmdet - INFO - Epoch [20][2240/5332]\tlr: 1.000e-05, eta: 1:50:57, time: 2.143, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0234, s0.acc: 99.0875, s0.loss_bbox_cls: 0.0230, s0.loss_bbox_reg: 0.0465, s1.loss_cls: 0.0164, s1.acc: 98.7152, s1.loss_bbox_cls: 0.0183, s1.loss_bbox_reg: 0.0371, s2.loss_cls: 0.0096, s2.acc: 98.2819, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0200, loss: 0.2130, grad_norm: 5.6544\n",
            "2020-09-10 15:48:35,753 - mmdet - INFO - Epoch [20][2304/5332]\tlr: 1.000e-05, eta: 1:48:38, time: 2.143, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0238, s0.acc: 99.0601, s0.loss_bbox_cls: 0.0225, s0.loss_bbox_reg: 0.0453, s1.loss_cls: 0.0167, s1.acc: 98.6023, s1.loss_bbox_cls: 0.0189, s1.loss_bbox_reg: 0.0359, s2.loss_cls: 0.0122, s2.acc: 98.0682, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0213, loss: 0.2133, grad_norm: 6.0171\n",
            "2020-09-10 15:50:52,360 - mmdet - INFO - Epoch [20][2368/5332]\tlr: 1.000e-05, eta: 1:46:19, time: 2.134, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0210, s0.acc: 99.1730, s0.loss_bbox_cls: 0.0205, s0.loss_bbox_reg: 0.0471, s1.loss_cls: 0.0145, s1.acc: 98.8586, s1.loss_bbox_cls: 0.0180, s1.loss_bbox_reg: 0.0377, s2.loss_cls: 0.0100, s2.acc: 98.4070, s2.loss_bbox_cls: 0.0109, s2.loss_bbox_reg: 0.0236, loss: 0.2103, grad_norm: 6.0093\n",
            "2020-09-10 15:53:10,133 - mmdet - INFO - Epoch [20][2432/5332]\tlr: 1.000e-05, eta: 1:44:01, time: 2.153, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0217, s0.acc: 99.2096, s0.loss_bbox_cls: 0.0196, s0.loss_bbox_reg: 0.0425, s1.loss_cls: 0.0149, s1.acc: 98.8434, s1.loss_bbox_cls: 0.0161, s1.loss_bbox_reg: 0.0329, s2.loss_cls: 0.0093, s2.acc: 98.6603, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0196, loss: 0.1929, grad_norm: 5.3753\n",
            "2020-09-10 15:55:27,530 - mmdet - INFO - Epoch [20][2496/5332]\tlr: 1.000e-05, eta: 1:41:43, time: 2.147, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0253, s0.acc: 98.9014, s0.loss_bbox_cls: 0.0273, s0.loss_bbox_reg: 0.0494, s1.loss_cls: 0.0178, s1.acc: 98.4985, s1.loss_bbox_cls: 0.0204, s1.loss_bbox_reg: 0.0361, s2.loss_cls: 0.0126, s2.acc: 97.5220, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0195, loss: 0.2280, grad_norm: 6.5716\n",
            "2020-09-10 15:57:44,335 - mmdet - INFO - Epoch [20][2560/5332]\tlr: 1.000e-05, eta: 1:39:24, time: 2.138, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0211, s0.acc: 99.1180, s0.loss_bbox_cls: 0.0190, s0.loss_bbox_reg: 0.0415, s1.loss_cls: 0.0153, s1.acc: 98.7091, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0350, s2.loss_cls: 0.0097, s2.acc: 98.3368, s2.loss_bbox_cls: 0.0106, s2.loss_bbox_reg: 0.0206, loss: 0.1979, grad_norm: 5.6723\n",
            "2020-09-10 16:00:02,250 - mmdet - INFO - Epoch [20][2624/5332]\tlr: 1.000e-05, eta: 1:37:07, time: 2.155, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0247, s0.acc: 98.9502, s0.loss_bbox_cls: 0.0208, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0189, s1.acc: 98.4528, s1.loss_bbox_cls: 0.0161, s1.loss_bbox_reg: 0.0342, s2.loss_cls: 0.0120, s2.acc: 98.0957, s2.loss_bbox_cls: 0.0089, s2.loss_bbox_reg: 0.0199, loss: 0.2081, grad_norm: 6.0284\n",
            "2020-09-10 16:02:20,433 - mmdet - INFO - Epoch [20][2688/5332]\tlr: 1.000e-05, eta: 1:34:49, time: 2.159, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0263, s0.acc: 98.9929, s0.loss_bbox_cls: 0.0214, s0.loss_bbox_reg: 0.0453, s1.loss_cls: 0.0195, s1.acc: 98.5138, s1.loss_bbox_cls: 0.0181, s1.loss_bbox_reg: 0.0344, s2.loss_cls: 0.0126, s2.acc: 97.8912, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0199, loss: 0.2143, grad_norm: 5.4881\n",
            "2020-09-10 16:04:35,221 - mmdet - INFO - Epoch [20][2752/5332]\tlr: 1.000e-05, eta: 1:32:29, time: 2.106, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0233, s0.acc: 99.1211, s0.loss_bbox_cls: 0.0222, s0.loss_bbox_reg: 0.0457, s1.loss_cls: 0.0176, s1.acc: 98.7762, s1.loss_bbox_cls: 0.0197, s1.loss_bbox_reg: 0.0364, s2.loss_cls: 0.0107, s2.acc: 98.4894, s2.loss_bbox_cls: 0.0104, s2.loss_bbox_reg: 0.0205, loss: 0.2115, grad_norm: 5.4314\n",
            "2020-09-10 16:06:51,372 - mmdet - INFO - Epoch [20][2816/5332]\tlr: 1.000e-05, eta: 1:30:10, time: 2.127, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0230, s0.acc: 99.0509, s0.loss_bbox_cls: 0.0216, s0.loss_bbox_reg: 0.0486, s1.loss_cls: 0.0141, s1.acc: 98.9685, s1.loss_bbox_cls: 0.0160, s1.loss_bbox_reg: 0.0350, s2.loss_cls: 0.0085, s2.acc: 98.6633, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0219, loss: 0.2089, grad_norm: 6.0891\n",
            "2020-09-10 16:09:08,464 - mmdet - INFO - Epoch [20][2880/5332]\tlr: 1.000e-05, eta: 1:27:52, time: 2.142, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0231, s0.acc: 99.0387, s0.loss_bbox_cls: 0.0197, s0.loss_bbox_reg: 0.0456, s1.loss_cls: 0.0172, s1.acc: 98.6298, s1.loss_bbox_cls: 0.0167, s1.loss_bbox_reg: 0.0355, s2.loss_cls: 0.0105, s2.acc: 98.2819, s2.loss_bbox_cls: 0.0119, s2.loss_bbox_reg: 0.0236, loss: 0.2109, grad_norm: 6.2443\n",
            "2020-09-10 16:11:23,657 - mmdet - INFO - Epoch [20][2944/5332]\tlr: 1.000e-05, eta: 1:25:32, time: 2.112, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0228, s0.acc: 99.0204, s0.loss_bbox_cls: 0.0181, s0.loss_bbox_reg: 0.0394, s1.loss_cls: 0.0174, s1.acc: 98.4222, s1.loss_bbox_cls: 0.0159, s1.loss_bbox_reg: 0.0315, s2.loss_cls: 0.0111, s2.acc: 98.0957, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0188, loss: 0.1913, grad_norm: 5.8307\n",
            "2020-09-10 16:13:41,097 - mmdet - INFO - Epoch [20][3008/5332]\tlr: 1.000e-05, eta: 1:23:15, time: 2.147, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0301, s0.acc: 98.8068, s0.loss_bbox_cls: 0.0233, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0220, s1.acc: 98.1232, s1.loss_bbox_cls: 0.0185, s1.loss_bbox_reg: 0.0330, s2.loss_cls: 0.0127, s2.acc: 97.8516, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0197, loss: 0.2227, grad_norm: 5.9529\n",
            "2020-09-10 16:15:56,991 - mmdet - INFO - Epoch [20][3072/5332]\tlr: 1.000e-05, eta: 1:20:56, time: 2.123, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0238, s0.acc: 98.9685, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0427, s1.loss_cls: 0.0183, s1.acc: 98.4589, s1.loss_bbox_cls: 0.0179, s1.loss_bbox_reg: 0.0336, s2.loss_cls: 0.0123, s2.acc: 97.6135, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0185, loss: 0.2041, grad_norm: 5.9567\n",
            "2020-09-10 16:18:14,479 - mmdet - INFO - Epoch [20][3136/5332]\tlr: 1.000e-05, eta: 1:18:38, time: 2.148, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0208, s0.acc: 99.1882, s0.loss_bbox_cls: 0.0186, s0.loss_bbox_reg: 0.0443, s1.loss_cls: 0.0157, s1.acc: 98.6542, s1.loss_bbox_cls: 0.0169, s1.loss_bbox_reg: 0.0366, s2.loss_cls: 0.0091, s2.acc: 98.4283, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0227, loss: 0.2032, grad_norm: 6.0964\n",
            "2020-09-10 16:20:32,245 - mmdet - INFO - Epoch [20][3200/5332]\tlr: 1.000e-05, eta: 1:16:21, time: 2.153, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0024, s0.loss_cls: 0.0213, s0.acc: 99.1943, s0.loss_bbox_cls: 0.0203, s0.loss_bbox_reg: 0.0441, s1.loss_cls: 0.0137, s1.acc: 98.9990, s1.loss_bbox_cls: 0.0178, s1.loss_bbox_reg: 0.0370, s2.loss_cls: 0.0083, s2.acc: 98.7610, s2.loss_bbox_cls: 0.0113, s2.loss_bbox_reg: 0.0236, loss: 0.2012, grad_norm: 5.6412\n",
            "2020-09-10 16:22:48,959 - mmdet - INFO - Epoch [20][3264/5332]\tlr: 1.000e-05, eta: 1:14:03, time: 2.136, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0221, s0.acc: 99.2035, s0.loss_bbox_cls: 0.0219, s0.loss_bbox_reg: 0.0425, s1.loss_cls: 0.0155, s1.acc: 98.8312, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0353, s2.loss_cls: 0.0110, s2.acc: 98.3948, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0223, loss: 0.2060, grad_norm: 5.6930\n",
            "2020-09-10 16:25:05,469 - mmdet - INFO - Epoch [20][3328/5332]\tlr: 1.000e-05, eta: 1:11:45, time: 2.133, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0221, s0.acc: 99.1608, s0.loss_bbox_cls: 0.0176, s0.loss_bbox_reg: 0.0374, s1.loss_cls: 0.0153, s1.acc: 98.7244, s1.loss_bbox_cls: 0.0140, s1.loss_bbox_reg: 0.0269, s2.loss_cls: 0.0101, s2.acc: 98.2300, s2.loss_bbox_cls: 0.0087, s2.loss_bbox_reg: 0.0175, loss: 0.1762, grad_norm: 5.5251\n",
            "2020-09-10 16:27:21,742 - mmdet - INFO - Epoch [20][3392/5332]\tlr: 1.000e-05, eta: 1:09:27, time: 2.129, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0276, s0.acc: 98.9441, s0.loss_bbox_cls: 0.0229, s0.loss_bbox_reg: 0.0491, s1.loss_cls: 0.0181, s1.acc: 98.7854, s1.loss_bbox_cls: 0.0191, s1.loss_bbox_reg: 0.0383, s2.loss_cls: 0.0113, s2.acc: 98.2513, s2.loss_bbox_cls: 0.0130, s2.loss_bbox_reg: 0.0242, loss: 0.2307, grad_norm: 6.1598\n",
            "2020-09-10 16:29:38,859 - mmdet - INFO - Epoch [20][3456/5332]\tlr: 1.000e-05, eta: 1:07:09, time: 2.142, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0228, s0.acc: 99.1516, s0.loss_bbox_cls: 0.0185, s0.loss_bbox_reg: 0.0436, s1.loss_cls: 0.0171, s1.acc: 98.7640, s1.loss_bbox_cls: 0.0149, s1.loss_bbox_reg: 0.0342, s2.loss_cls: 0.0102, s2.acc: 98.5107, s2.loss_bbox_cls: 0.0102, s2.loss_bbox_reg: 0.0217, loss: 0.2012, grad_norm: 5.7569\n",
            "2020-09-10 16:31:56,936 - mmdet - INFO - Epoch [20][3520/5332]\tlr: 1.000e-05, eta: 1:04:52, time: 2.157, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0202, s0.acc: 99.1974, s0.loss_bbox_cls: 0.0178, s0.loss_bbox_reg: 0.0381, s1.loss_cls: 0.0150, s1.acc: 98.7518, s1.loss_bbox_cls: 0.0137, s1.loss_bbox_reg: 0.0293, s2.loss_cls: 0.0098, s2.acc: 98.2880, s2.loss_bbox_cls: 0.0079, s2.loss_bbox_reg: 0.0172, loss: 0.1738, grad_norm: 5.1958\n",
            "2020-09-10 16:34:15,023 - mmdet - INFO - Epoch [20][3584/5332]\tlr: 1.000e-05, eta: 1:02:35, time: 2.158, data_time: 0.005, memory: 8119, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0206, s0.acc: 99.1760, s0.loss_bbox_cls: 0.0211, s0.loss_bbox_reg: 0.0435, s1.loss_cls: 0.0130, s1.acc: 98.9838, s1.loss_bbox_cls: 0.0185, s1.loss_bbox_reg: 0.0346, s2.loss_cls: 0.0093, s2.acc: 98.5168, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0196, loss: 0.1967, grad_norm: 5.4597\n",
            "2020-09-10 16:36:34,982 - mmdet - INFO - Epoch [20][3648/5332]\tlr: 1.000e-05, eta: 1:00:18, time: 2.187, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0206, s0.acc: 99.1272, s0.loss_bbox_cls: 0.0202, s0.loss_bbox_reg: 0.0461, s1.loss_cls: 0.0161, s1.acc: 98.5992, s1.loss_bbox_cls: 0.0177, s1.loss_bbox_reg: 0.0371, s2.loss_cls: 0.0112, s2.acc: 97.9553, s2.loss_bbox_cls: 0.0111, s2.loss_bbox_reg: 0.0232, loss: 0.2103, grad_norm: 6.0294\n",
            "2020-09-10 16:38:51,912 - mmdet - INFO - Epoch [20][3712/5332]\tlr: 1.000e-05, eta: 0:58:00, time: 2.140, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0213, s0.acc: 99.1302, s0.loss_bbox_cls: 0.0189, s0.loss_bbox_reg: 0.0451, s1.loss_cls: 0.0142, s1.acc: 99.0814, s1.loss_bbox_cls: 0.0171, s1.loss_bbox_reg: 0.0363, s2.loss_cls: 0.0094, s2.acc: 98.4650, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0230, loss: 0.2016, grad_norm: 5.9670\n",
            "2020-09-10 16:41:09,698 - mmdet - INFO - Epoch [20][3776/5332]\tlr: 1.000e-05, eta: 0:55:43, time: 2.153, data_time: 0.005, memory: 8119, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0276, s0.acc: 98.9563, s0.loss_bbox_cls: 0.0253, s0.loss_bbox_reg: 0.0503, s1.loss_cls: 0.0198, s1.acc: 98.4375, s1.loss_bbox_cls: 0.0197, s1.loss_bbox_reg: 0.0378, s2.loss_cls: 0.0126, s2.acc: 97.9065, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0215, loss: 0.2353, grad_norm: 6.3568\n",
            "2020-09-10 16:43:25,294 - mmdet - INFO - Epoch [20][3840/5332]\tlr: 1.000e-05, eta: 0:53:25, time: 2.119, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0222, s0.acc: 99.1333, s0.loss_bbox_cls: 0.0209, s0.loss_bbox_reg: 0.0408, s1.loss_cls: 0.0176, s1.acc: 98.4650, s1.loss_bbox_cls: 0.0161, s1.loss_bbox_reg: 0.0311, s2.loss_cls: 0.0113, s2.acc: 97.9950, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0189, loss: 0.1953, grad_norm: 5.7288\n",
            "2020-09-10 16:45:44,423 - mmdet - INFO - Epoch [20][3904/5332]\tlr: 1.000e-05, eta: 0:51:08, time: 2.174, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0189, s0.acc: 99.2645, s0.loss_bbox_cls: 0.0170, s0.loss_bbox_reg: 0.0411, s1.loss_cls: 0.0137, s1.acc: 98.9197, s1.loss_bbox_cls: 0.0146, s1.loss_bbox_reg: 0.0320, s2.loss_cls: 0.0085, s2.acc: 98.5901, s2.loss_bbox_cls: 0.0084, s2.loss_bbox_reg: 0.0194, loss: 0.1815, grad_norm: 5.4796\n",
            "2020-09-10 16:48:01,369 - mmdet - INFO - Epoch [20][3968/5332]\tlr: 1.000e-05, eta: 0:48:50, time: 2.140, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0257, s0.acc: 98.9532, s0.loss_bbox_cls: 0.0210, s0.loss_bbox_reg: 0.0445, s1.loss_cls: 0.0200, s1.acc: 98.3673, s1.loss_bbox_cls: 0.0172, s1.loss_bbox_reg: 0.0367, s2.loss_cls: 0.0127, s2.acc: 98.0316, s2.loss_bbox_cls: 0.0108, s2.loss_bbox_reg: 0.0230, loss: 0.2189, grad_norm: 5.9243\n",
            "2020-09-10 16:50:19,774 - mmdet - INFO - Epoch [20][4032/5332]\tlr: 1.000e-05, eta: 0:46:33, time: 2.163, data_time: 0.005, memory: 8119, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0225, s0.acc: 99.1028, s0.loss_bbox_cls: 0.0213, s0.loss_bbox_reg: 0.0459, s1.loss_cls: 0.0159, s1.acc: 98.7091, s1.loss_bbox_cls: 0.0196, s1.loss_bbox_reg: 0.0386, s2.loss_cls: 0.0115, s2.acc: 98.0865, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0222, loss: 0.2146, grad_norm: 5.7683\n",
            "2020-09-10 16:52:37,928 - mmdet - INFO - Epoch [20][4096/5332]\tlr: 1.000e-05, eta: 0:44:16, time: 2.159, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0071, s0.loss_cls: 0.0240, s0.acc: 99.0601, s0.loss_bbox_cls: 0.0221, s0.loss_bbox_reg: 0.0432, s1.loss_cls: 0.0204, s1.acc: 98.4528, s1.loss_bbox_cls: 0.0175, s1.loss_bbox_reg: 0.0343, s2.loss_cls: 0.0136, s2.acc: 97.7753, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0202, loss: 0.2158, grad_norm: 5.8220\n",
            "2020-09-10 16:54:55,860 - mmdet - INFO - Epoch [20][4160/5332]\tlr: 1.000e-05, eta: 0:41:58, time: 2.155, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0235, s0.acc: 98.9990, s0.loss_bbox_cls: 0.0213, s0.loss_bbox_reg: 0.0474, s1.loss_cls: 0.0168, s1.acc: 98.5931, s1.loss_bbox_cls: 0.0181, s1.loss_bbox_reg: 0.0368, s2.loss_cls: 0.0105, s2.acc: 98.0316, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0209, loss: 0.2109, grad_norm: 6.2228\n",
            "2020-09-10 16:57:14,760 - mmdet - INFO - Epoch [20][4224/5332]\tlr: 1.000e-05, eta: 0:39:41, time: 2.170, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0259, s0.acc: 99.0631, s0.loss_bbox_cls: 0.0220, s0.loss_bbox_reg: 0.0449, s1.loss_cls: 0.0167, s1.acc: 98.7213, s1.loss_bbox_cls: 0.0176, s1.loss_bbox_reg: 0.0352, s2.loss_cls: 0.0098, s2.acc: 98.4924, s2.loss_bbox_cls: 0.0097, s2.loss_bbox_reg: 0.0207, loss: 0.2108, grad_norm: 6.0308\n",
            "2020-09-10 16:59:33,580 - mmdet - INFO - Epoch [20][4288/5332]\tlr: 1.000e-05, eta: 0:37:24, time: 2.169, data_time: 0.005, memory: 8119, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0244, s0.acc: 98.9929, s0.loss_bbox_cls: 0.0219, s0.loss_bbox_reg: 0.0453, s1.loss_cls: 0.0193, s1.acc: 98.4589, s1.loss_bbox_cls: 0.0172, s1.loss_bbox_reg: 0.0347, s2.loss_cls: 0.0130, s2.acc: 97.8302, s2.loss_bbox_cls: 0.0100, s2.loss_bbox_reg: 0.0209, loss: 0.2154, grad_norm: 6.2570\n",
            "2020-09-10 17:01:52,207 - mmdet - INFO - Epoch [20][4352/5332]\tlr: 1.000e-05, eta: 0:35:06, time: 2.166, data_time: 0.005, memory: 8119, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0024, s0.loss_cls: 0.0156, s0.acc: 99.4049, s0.loss_bbox_cls: 0.0180, s0.loss_bbox_reg: 0.0380, s1.loss_cls: 0.0102, s1.acc: 99.2554, s1.loss_bbox_cls: 0.0162, s1.loss_bbox_reg: 0.0324, s2.loss_cls: 0.0069, s2.acc: 98.9441, s2.loss_bbox_cls: 0.0092, s2.loss_bbox_reg: 0.0186, loss: 0.1704, grad_norm: 5.1594\n",
            "2020-09-10 17:04:10,425 - mmdet - INFO - Epoch [20][4416/5332]\tlr: 1.000e-05, eta: 0:32:49, time: 2.160, data_time: 0.005, memory: 8119, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0254, s0.acc: 98.9594, s0.loss_bbox_cls: 0.0205, s0.loss_bbox_reg: 0.0453, s1.loss_cls: 0.0188, s1.acc: 98.3612, s1.loss_bbox_cls: 0.0161, s1.loss_bbox_reg: 0.0328, s2.loss_cls: 0.0115, s2.acc: 97.9614, s2.loss_bbox_cls: 0.0093, s2.loss_bbox_reg: 0.0194, loss: 0.2085, grad_norm: 5.8890\n",
            "2020-09-10 17:06:29,452 - mmdet - INFO - Epoch [20][4480/5332]\tlr: 1.000e-05, eta: 0:30:32, time: 2.172, data_time: 0.005, memory: 8119, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0222, s0.acc: 99.1150, s0.loss_bbox_cls: 0.0166, s0.loss_bbox_reg: 0.0390, s1.loss_cls: 0.0174, s1.acc: 98.5809, s1.loss_bbox_cls: 0.0141, s1.loss_bbox_reg: 0.0310, s2.loss_cls: 0.0110, s2.acc: 98.1384, s2.loss_bbox_cls: 0.0080, s2.loss_bbox_reg: 0.0186, loss: 0.1856, grad_norm: 5.5870\n",
            "2020-09-10 17:08:45,328 - mmdet - INFO - Epoch [20][4544/5332]\tlr: 1.000e-05, eta: 0:28:14, time: 2.123, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0209, s0.acc: 99.1730, s0.loss_bbox_cls: 0.0219, s0.loss_bbox_reg: 0.0465, s1.loss_cls: 0.0134, s1.acc: 98.9777, s1.loss_bbox_cls: 0.0188, s1.loss_bbox_reg: 0.0371, s2.loss_cls: 0.0093, s2.acc: 98.3887, s2.loss_bbox_cls: 0.0098, s2.loss_bbox_reg: 0.0204, loss: 0.2055, grad_norm: 5.5638\n",
            "2020-09-10 17:11:03,216 - mmdet - INFO - Epoch [20][4608/5332]\tlr: 1.000e-05, eta: 0:25:56, time: 2.154, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0021, s0.loss_cls: 0.0222, s0.acc: 99.1272, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0474, s1.loss_cls: 0.0165, s1.acc: 98.6023, s1.loss_bbox_cls: 0.0176, s1.loss_bbox_reg: 0.0360, s2.loss_cls: 0.0104, s2.acc: 98.3765, s2.loss_bbox_cls: 0.0110, s2.loss_bbox_reg: 0.0219, loss: 0.2086, grad_norm: 5.9536\n",
            "2020-09-10 17:13:20,138 - mmdet - INFO - Epoch [20][4672/5332]\tlr: 1.000e-05, eta: 0:23:38, time: 2.139, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0253, s0.acc: 99.0448, s0.loss_bbox_cls: 0.0193, s0.loss_bbox_reg: 0.0424, s1.loss_cls: 0.0171, s1.acc: 98.6969, s1.loss_bbox_cls: 0.0153, s1.loss_bbox_reg: 0.0314, s2.loss_cls: 0.0111, s2.acc: 98.1140, s2.loss_bbox_cls: 0.0081, s2.loss_bbox_reg: 0.0179, loss: 0.1955, grad_norm: 5.6555\n",
            "2020-09-10 17:15:36,866 - mmdet - INFO - Epoch [20][4736/5332]\tlr: 1.000e-05, eta: 0:21:21, time: 2.136, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0220, s0.acc: 99.0662, s0.loss_bbox_cls: 0.0217, s0.loss_bbox_reg: 0.0419, s1.loss_cls: 0.0162, s1.acc: 98.6511, s1.loss_bbox_cls: 0.0173, s1.loss_bbox_reg: 0.0324, s2.loss_cls: 0.0100, s2.acc: 98.2391, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0193, loss: 0.1985, grad_norm: 5.4365\n",
            "2020-09-10 17:17:53,289 - mmdet - INFO - Epoch [20][4800/5332]\tlr: 1.000e-05, eta: 0:19:03, time: 2.132, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0203, s0.acc: 99.1730, s0.loss_bbox_cls: 0.0228, s0.loss_bbox_reg: 0.0486, s1.loss_cls: 0.0169, s1.acc: 98.7213, s1.loss_bbox_cls: 0.0182, s1.loss_bbox_reg: 0.0376, s2.loss_cls: 0.0116, s2.acc: 98.2239, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0216, loss: 0.2170, grad_norm: 5.8998\n",
            "2020-09-10 17:20:09,224 - mmdet - INFO - Epoch [20][4864/5332]\tlr: 1.000e-05, eta: 0:16:45, time: 2.124, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0217, s0.acc: 99.1852, s0.loss_bbox_cls: 0.0204, s0.loss_bbox_reg: 0.0445, s1.loss_cls: 0.0155, s1.acc: 98.8831, s1.loss_bbox_cls: 0.0168, s1.loss_bbox_reg: 0.0355, s2.loss_cls: 0.0111, s2.acc: 98.2391, s2.loss_bbox_cls: 0.0095, s2.loss_bbox_reg: 0.0214, loss: 0.2038, grad_norm: 5.7005\n",
            "2020-09-10 17:22:25,876 - mmdet - INFO - Epoch [20][4928/5332]\tlr: 1.000e-05, eta: 0:14:28, time: 2.135, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0195, s0.acc: 99.1791, s0.loss_bbox_cls: 0.0191, s0.loss_bbox_reg: 0.0442, s1.loss_cls: 0.0143, s1.acc: 98.8190, s1.loss_bbox_cls: 0.0161, s1.loss_bbox_reg: 0.0353, s2.loss_cls: 0.0086, s2.acc: 98.5260, s2.loss_bbox_cls: 0.0096, s2.loss_bbox_reg: 0.0213, loss: 0.1941, grad_norm: 5.5690\n",
            "2020-09-10 17:24:42,254 - mmdet - INFO - Epoch [20][4992/5332]\tlr: 1.000e-05, eta: 0:12:10, time: 2.131, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0214, s0.acc: 99.0967, s0.loss_bbox_cls: 0.0187, s0.loss_bbox_reg: 0.0404, s1.loss_cls: 0.0163, s1.acc: 98.6298, s1.loss_bbox_cls: 0.0165, s1.loss_bbox_reg: 0.0333, s2.loss_cls: 0.0106, s2.acc: 98.2483, s2.loss_bbox_cls: 0.0103, s2.loss_bbox_reg: 0.0200, loss: 0.1947, grad_norm: 5.6580\n",
            "2020-09-10 17:26:59,210 - mmdet - INFO - Epoch [20][5056/5332]\tlr: 1.000e-05, eta: 0:09:53, time: 2.140, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0243, s0.acc: 99.0631, s0.loss_bbox_cls: 0.0238, s0.loss_bbox_reg: 0.0465, s1.loss_cls: 0.0188, s1.acc: 98.5199, s1.loss_bbox_cls: 0.0193, s1.loss_bbox_reg: 0.0354, s2.loss_cls: 0.0124, s2.acc: 98.0225, s2.loss_bbox_cls: 0.0099, s2.loss_bbox_reg: 0.0188, loss: 0.2196, grad_norm: 5.8165\n",
            "2020-09-10 17:29:15,054 - mmdet - INFO - Epoch [20][5120/5332]\tlr: 1.000e-05, eta: 0:07:35, time: 2.123, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0025, s0.loss_cls: 0.0203, s0.acc: 99.1333, s0.loss_bbox_cls: 0.0167, s0.loss_bbox_reg: 0.0401, s1.loss_cls: 0.0153, s1.acc: 98.8342, s1.loss_bbox_cls: 0.0144, s1.loss_bbox_reg: 0.0327, s2.loss_cls: 0.0099, s2.acc: 98.3063, s2.loss_bbox_cls: 0.0090, s2.loss_bbox_reg: 0.0208, loss: 0.1853, grad_norm: 5.6971\n",
            "2020-09-10 17:31:31,649 - mmdet - INFO - Epoch [20][5184/5332]\tlr: 1.000e-05, eta: 0:05:17, time: 2.134, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0245, s0.acc: 98.9655, s0.loss_bbox_cls: 0.0215, s0.loss_bbox_reg: 0.0448, s1.loss_cls: 0.0177, s1.acc: 98.5016, s1.loss_bbox_cls: 0.0182, s1.loss_bbox_reg: 0.0341, s2.loss_cls: 0.0114, s2.acc: 98.2819, s2.loss_bbox_cls: 0.0107, s2.loss_bbox_reg: 0.0205, loss: 0.2086, grad_norm: 5.9243\n",
            "2020-09-10 17:33:47,126 - mmdet - INFO - Epoch [20][5248/5332]\tlr: 1.000e-05, eta: 0:03:00, time: 2.117, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0236, s0.acc: 99.0814, s0.loss_bbox_cls: 0.0193, s0.loss_bbox_reg: 0.0398, s1.loss_cls: 0.0177, s1.acc: 98.6511, s1.loss_bbox_cls: 0.0143, s1.loss_bbox_reg: 0.0295, s2.loss_cls: 0.0108, s2.acc: 98.1598, s2.loss_bbox_cls: 0.0080, s2.loss_bbox_reg: 0.0176, loss: 0.1881, grad_norm: 5.2646\n",
            "2020-09-10 17:36:02,542 - mmdet - INFO - Epoch [20][5312/5332]\tlr: 1.000e-05, eta: 0:00:42, time: 2.116, data_time: 0.004, memory: 8119, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0291, s0.acc: 98.9258, s0.loss_bbox_cls: 0.0266, s0.loss_bbox_reg: 0.0471, s1.loss_cls: 0.0230, s1.acc: 98.2910, s1.loss_bbox_cls: 0.0200, s1.loss_bbox_reg: 0.0330, s2.loss_cls: 0.0135, s2.acc: 97.8363, s2.loss_bbox_cls: 0.0101, s2.loss_bbox_reg: 0.0172, loss: 0.2266, grad_norm: 5.7407\n",
            "2020-09-10 17:36:45,270 - mmdet - INFO - Saving checkpoint at 20 epochs\n",
            "[>>] 667/667, 0.5 task/s, elapsed: 1311s, ETA:     0s2020-09-10 17:58:43,445 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 249  | 0.841  | 0.675 |\n",
            "| 3     | 22  | 64   | 0.818  | 0.678 |\n",
            "| 4     | 529 | 1211 | 0.922  | 0.835 |\n",
            "| 5     | 78  | 180  | 0.872  | 0.782 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.743 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-10 17:58:43,449 - mmdet - INFO - Epoch(val) [20][5332]\tmAP: 0.7425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmMqa-TWKfcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "3bfb3f7f-034e-4c86-d0cb-cb6fe5aa3f13"
      },
      "source": [
        "!python tools/test.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_20.pth --eval mAP"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "[>>] 667/667, 0.5 task/s, elapsed: 1334s, ETA:     0s\n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 86  | 289  | 0.826  | 0.681 |\n",
            "| 3     | 20  | 55   | 0.850  | 0.836 |\n",
            "| 4     | 547 | 1331 | 0.918  | 0.815 |\n",
            "| 5     | 64  | 166  | 0.984  | 0.911 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.811 |\n",
            "+-------+-----+------+--------+-------+\n",
            "{'mAP': 0.8109272718429565}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-41k4CuQP7Ao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "6a5c689e-6a8d-459b-d6a0-8429471758dc"
      },
      "source": [
        "!python tools/test.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_19.pth --eval mAP"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "[>>] 667/667, 0.5 task/s, elapsed: 1345s, ETA:     0s\n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 86  | 319  | 0.849  | 0.681 |\n",
            "| 3     | 20  | 61   | 0.850  | 0.839 |\n",
            "| 4     | 547 | 1351 | 0.920  | 0.814 |\n",
            "| 5     | 64  | 170  | 0.984  | 0.909 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.811 |\n",
            "+-------+-----+------+--------+-------+\n",
            "{'mAP': 0.8106603622436523}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDT3Am5aWAH9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "7c4c4249-ae16-41cd-9105-1ddff00c14f8"
      },
      "source": [
        "!python tools/test.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_18.pth --eval mAP"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "[>>] 667/667, 0.5 task/s, elapsed: 1346s, ETA:     0s\n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 86  | 297  | 0.849  | 0.684 |\n",
            "| 3     | 20  | 56   | 0.850  | 0.839 |\n",
            "| 4     | 547 | 1348 | 0.920  | 0.817 |\n",
            "| 5     | 64  | 168  | 0.984  | 0.910 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.812 |\n",
            "+-------+-----+------+--------+-------+\n",
            "{'mAP': 0.8123030662536621}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A18yMVTZbS1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a9701f07-3dea-49ba-9e0e-1b6963b2b88f"
      },
      "source": [
        "!python tools/test.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_17.pth --eval mAP"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "[  ] 259/667, 0.5 task/s, elapsed: 523s, ETA:   824s"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}